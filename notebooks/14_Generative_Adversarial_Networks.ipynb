{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDROnTg5ua9D"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/1.2_machinelearning_imbalanceddata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/1.2_machinelearning_imbalanceddata.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "## Ejemplos de código\n",
        "# Autoencoders y GANs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVRGiFIHua9M"
      },
      "source": [
        "**Name:** Marco Teran\n",
        "**E-mail:** marco.teran@usa.edu.co\n",
        "\n",
        "[Website](http://marcoteran.github.io/),\n",
        "[Github](https://github.com/marcoteran),\n",
        "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpgNPIp3ua9N"
      },
      "source": [
        "### Preparación del entorno y descarga de datos\n",
        "\n",
        "Empezamos con las importaciones estándar para preparar el entorno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B192OSsEua9N"
      },
      "source": [
        "#### Importar TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5RstiiB8V-z",
        "outputId": "58b315dc-27e3-4bd1-cd56-cc5fb9444ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb5L8-H9ua9R"
      },
      "source": [
        "Importar todos los paquetes necesarios para ejecutar el modelo propuesto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfR6wlFWua9S"
      },
      "source": [
        "Defina los tamaños de letra por defecto para que las figuras sean más bonitas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ia_XNya8ua9T"
      },
      "outputs": [],
      "source": [
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ3L_piDua9U"
      },
      "source": [
        "Vamos a crear la carpeta `images/generative` (si no existe ya)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5WlHyzP0ua9V"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"generative\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuWs2UYWua9V"
      },
      "source": [
        "Este código puede ser muy lento sin una GPU, así que asegurémonos de que haya una, o de lo contrario emitamos una advertencia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k4iqM1VUua9V"
      },
      "outputs": [],
      "source": [
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No se ha detectado ninguna GPU. Las redes neuronales pueden ser muy lentas sin una GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Ve a Tiempo de ejecución > Cambiar tiempo de ejecución y selecciona un hardware de GPU \"\n",
        "              \"acelerador.\")\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        print(\"Ve a Configuración > Acelerador y selecciona GPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp7d444Qua9W"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhEvpKdrua9W"
      },
      "source": [
        "## Performing PCA with an Undercomplete Linear Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j7bQ5LJua9W"
      },
      "source": [
        "Construyamos el Autoencoder..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hAc1HYgMua9W"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "\n",
        "encoder = tf.keras.Sequential([tf.keras.layers.Dense(2)])\n",
        "decoder = tf.keras.Sequential([tf.keras.layers.Dense(3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oVPw9-Vpua9X"
      },
      "outputs": [],
      "source": [
        "autoencoder = tf.keras.Sequential([encoder, decoder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VB--7zznua9X"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7s09zv3-ua9Y"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(loss=\"mse\", optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwXEV6Ciua9Y"
      },
      "source": [
        "Ahora vamos a generar el mismo conjunto de datos 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wd3gKOQMua9Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.transform import Rotation\n",
        "\n",
        "m = 60\n",
        "X = np.zeros((m, 3))  # initialize 3D dataset\n",
        "np.random.seed(42)\n",
        "angles = (np.random.rand(m) ** 3 + 0.5) * 2 * np.pi  # uneven distribution\n",
        "X[:, 0], X[:, 1] = np.cos(angles), np.sin(angles) * 0.5  # oval\n",
        "X += 0.28 * np.random.randn(m, 3)  # add more noise\n",
        "X = Rotation.from_rotvec([np.pi / 29, -np.pi / 20, np.pi / 4]).apply(X)\n",
        "X_train = X + [0.2, 0, 0.2]  # shift a bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T4u-Vc9Hua9Z"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=500, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qku3OQAcua9Z",
        "outputId": "5b8fdb3c-bbbb-4c77-b980-596852555c7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "codings = encoder.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Et_KW8cBua9Z",
        "outputId": "10ebf8f7-4766-44e3-bc74-15bc7332b19e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(4,3))\n",
        "plt.plot(codings[:,0], codings[:, 1], \"b.\")\n",
        "plt.xlabel(\"$z_1$\", fontsize=18)\n",
        "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FaZb5lVua9Z"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OawhThaeua9Z"
      },
      "source": [
        "# Stacked Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw2xDx70ua9Z"
      },
      "source": [
        "## Implementación de un Stacked Autoencoder con Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyx6TDMmua9a"
      },
      "source": [
        "Carguemos el conjunto de datos MNIST de moda, escalémoslo y dividámoslo en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E90He65Nua9a",
        "outputId": "bca0b357-f41b-4c0b-f7ed-43239e1db6d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# extra code – loads, scales, and splits the fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pIx8EjGnua9a"
      },
      "outputs": [],
      "source": [
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viNja9aSua9a"
      },
      "source": [
        "Construyamos y entrenemos un Autoencoder apilado con 3 capas ocultas y 1 capa de salida (es decir, 2 Autoencoders apilados)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4HBfVsLAua9a"
      },
      "outputs": [],
      "source": [
        "stacked_encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "])\n",
        "stacked_decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(28 * 28),\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GajXsY1wua9a"
      },
      "outputs": [],
      "source": [
        "stacked_ae = tf.keras.Sequential([stacked_encoder, stacked_decoder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kURYT7-_ua9a"
      },
      "outputs": [],
      "source": [
        "stacked_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6RRM3wR7ua9b",
        "outputId": "e76f8c47-9bb2-4bd2-fb5b-e550ae6174c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1719/1719 [==============================] - 10s 4ms/step - loss: 0.0232 - val_loss: 0.0179\n",
            "Epoch 2/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0167 - val_loss: 0.0161\n",
            "Epoch 3/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0155 - val_loss: 0.0153\n",
            "Epoch 4/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0150 - val_loss: 0.0149\n",
            "Epoch 5/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0147 - val_loss: 0.0146\n",
            "Epoch 6/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0143 - val_loss: 0.0143\n",
            "Epoch 7/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0141 - val_loss: 0.0143\n",
            "Epoch 8/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0140 - val_loss: 0.0142\n",
            "Epoch 9/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0139 - val_loss: 0.0140\n",
            "Epoch 10/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0138 - val_loss: 0.0140\n",
            "Epoch 11/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0137 - val_loss: 0.0138\n",
            "Epoch 12/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0136 - val_loss: 0.0137\n",
            "Epoch 13/20\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0135 - val_loss: 0.0138\n",
            "Epoch 14/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0135 - val_loss: 0.0136\n",
            "Epoch 15/20\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0134 - val_loss: 0.0136\n",
            "Epoch 16/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0134 - val_loss: 0.0135\n",
            "Epoch 17/20\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0133 - val_loss: 0.0135\n",
            "Epoch 18/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0133 - val_loss: 0.0134\n",
            "Epoch 19/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 20/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0132 - val_loss: 0.0134\n"
          ]
        }
      ],
      "source": [
        "history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
        "                         validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rbWlvHIua9b"
      },
      "source": [
        "### Visualización de las reconstrucciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mMDW1QXua9b"
      },
      "source": [
        "Esta función procesa unas cuantas imágenes de validación a través del autocodificador y muestra las imágenes originales y sus reconstrucciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HZaZFe50ua9r"
      },
      "outputs": [],
      "source": [
        "def plot_reconstructions(model, images=X_valid, n_images=5):\n",
        "    reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plt.imshow(images[image_index], cmap=\"binary\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plt.imshow(reconstructions[image_index], cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Hy60tOC1ua9s",
        "outputId": "3f676ae9-6d6e-4977-f7de-39838062a4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x300 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAD2CAYAAADlLZJVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/6UlEQVR4nO2deaxe1XX2N0lIQuxgPGIbT7GNJzDYEIxLDIKk0EAIDbQVRKhqlSptKQ1KlVYNbVBVCSlq0iRUVEJpVVG1tKJqG7UpIikhzCQegg0GY/CAB/CAbQwEQubw/fHp29+zfve+67zv9T33vjbP76+9tc89Z589vefu9ey1jnvzzTffLMYYY4wxZlh522hXwBhjjDHmWMQfWcYYY4wxLeCPLGOMMcaYFvBHljHGGGNMC/gjyxhjjDGmBfyRZYwxxhjTAv7IMsYYY4xpAX9kGWOMMca0gD+yjDHGGGNa4B2jXQHlF7/4Rci/7W3HxjfgsfpexvTC4cOHQ/7aa68N+ddff72mzznnnFC2ePHimn7HO+KytXXr1pB/+umna3r9+vWh7MYbbwz56667rqnaRvjJT34S8l/72tdq+pprrhnp6vTEnXfeGfIrV66s6Tlz5oxwbcxbBf/aG2OMMca0gD+yjDHGGGNa4LijJUD0/v37Q/76668P+Xe+8501ffHFF4ey97znPTVNU8Mbb7wR8mqyULNDKaVs2bIl5D/96U/X9GWXXdap6sYc0/z0pz+t6b//+78PZXfffXdN79mzJ73PiSeeWNPTpk0LZWpi//GPfxzKmP/BD35Q04cOHQplY8aMCfnnnnuupi+//PJQdsMNN9T0smXLsqq/ZeDPxcGDB2t6ypQpI12dRtS8uX379lCmJmhj2sI7WcYYY4wxLeCPLGOMMcaYFugrc+Gtt94a8l/5yldq+oc//GEoY/64447reF99xXHjxoUynpbR+2b3JDNnzgz5hQsX1vSXvvSlUDZr1qyu79sPcIhou9CE+td//dchr6d23v72t4ey448/vqbZD3zmz3/+85rmaU01Ff/sZz8LZTQl6XPUzDXY32b1UfOVmphLGWiSVjPZb/7mb4ayq6++uuMz+5W//Mu/DPmNGzfWNM3v48ePr2mak1566aWQ37FjR01Pnz49lM2YMaOm2U+vvfZayG/evLmmVSpQSimnnnpqyL/88ss1raYvlo0dOzaU/cVf/EXIU6JwrKLzsJQ4v9jW/YDWl/P93e9+90hXx7wF8U6WMcYYY0wL+CPLGGOMMaYF/JFljDHGGNMCo67JuvTSS2v64YcfDmWTJk2q6SZ7v74GtVSqn2nyvq5/y/vQpq/lLPv+97/fsa6f/exnQ/6P/uiPOl7b7/zbv/1byN9yyy0hr1o1apf0qD37gf2keQ5Ztr3CPux2nAz2nG6f8d73vjfkVdszd+7cUEYv1P3In/3Zn4U8tUvqekF1dqXEfqNea+LEiSH/1FNP1TQ9tU+dOrVj/V599dWQf9e73lXTK1asCGXU/p1wwgkd76v6TM5nahFvv/32mn7/+98fyrIx14+oW4tSYh9yDqvOkuOeWjl9d86trI14rdYn01GSAwcOhLyOP/bvvHnzQp7z1phu8U6WMcYYY0wL+CPLGGOMMaYFRjxA9BVXXBHyDzzwQE3rMe1SoomQJqHMvJRtLxOW6fZ3ZoYqJZolyOTJk2ua2+Zf/epXQ74fzYXdmjj+5m/+JuRpAlKTC9t6woQJHcuIlrM+mucRc+YzmswUne7b9HdqRtm9e3fX9RlNtN9+9KMfhTKa7nQucqzrHKEbBM6v5cuX17SaIEspZcOGDTVNk98pp5wS8meccUZNs//5LprPTJ2c6yeddFLI/9M//VNN01zY7yZC9gNNgtoXdLuh7cI2ykyCmRyAa3tWX9aVfah1f/HFF0OZup/Q9bqUKGUwR04v/TtcPPvsszX9yCOPhLLf+Z3fCXl1H8NoE+rqo0luNBjeyTLGGGOMaQF/ZBljjDHGtIA/sowxxhhjWmDENVlf/OIXQ/5DH/pQTWf2TtraiV6bhUBp0kfokWAN1zLY32b30nehTuX6669P6zAa8Ci0hobZuXNnKLvmmmtqesmSJaFs3bp1Ia9tn2k2xowZE8oY8kLbmuMkK8uOeDPMT6bfYl/rfXkf5lX7Qa3HzTffXNOf+9znOj5/pFm9enVNUwPFftS+y3SKhCGPtN00HFMpUSfB9qWmSPNsb44rHS9NukCFLmXocuJogv1APZy+K9tTy/h3GVmoLoalIjr3MhccpUTXDHwm9aNKL+PYNNOLDktdvTz//POhjLo6ze/duzeUrVmzpqYPHToUynR9KyWucSeffHIo+8IXvtBNtTvinSxjjDHGmBbwR5YxxhhjTAv4I8sYY4wxpgVGXJM1a9askM9s6qoVoCaLOgzVafQSKSjTbzX5xNBnUs+TaZFoH+53qI9RXznf/e53Qxn9zag/IWottP3ov4j9omOhF99XGb341GLf67V8L4Z5UQ0J9U1/93d/V9N/+qd/GsqadIht8tBDD9U0xy/bSecidYydritloN8snW9ZWCo+g9fqmsJQL+r/i3Vi/caNG1fTDz74YCjjOFd/Tbfddlsou+6660o/Q00W0X6hdnL69Ok1zTnMftJ50Iv+jdfqfOM6oaHYSinly1/+ck1z7l1wwQU1vWvXrlDGEFDmyMj8ZN13330hr3opXsv81q1ba5paKs2fe+65oYx6PA3pd/nllw98gSPAO1nGGGOMMS3gjyxjjDHGmBYYcXPh4cOHQ15NRtxezlwvZFvRNN9krhaysuxoeCmx7tyKVmj2YSiIfqDp2LRy++231/QnPvGJUMb23LNnT01z21/NMdwGZntq//IYfkYWYqnJnUcWWkjry7oyr9cyHIuGVOLxZIaZGkk0JAXNxS+//HLI6zzgONJ3p+sFomYrzm9tU/YpXQfotTQP0qWH3otjUM2+PEp+zjnndHzmd77znVDW7+ZCQvcUul6xD7W/OS/ZT9pGw2Xyp8mZpu2LLrqophkSKFuHezFnmmYycyHdAL3yyis1zRBeDHmjJkGOW+Wb3/xmyNNEqdAkrjisjjHGGGNMn+CPLGOMMcaYFvBHljHGGGNMC4y4Jot6FdU50aaq1zYdZ9fy7Bg5oW4g0+EQ1SNQG6DQ9t+Px4MzWzNdEpx//vk1/du//duh7NFHHw15tZmz7/XId1OfaVtnIYDYZxw3+kweOaeeI3MLos9hqJHsmXyG6p1GU4N1//33hzy1EArHis5b9rG2BXU47MdM56brBPuCWqBe9IUKNTuqJ+QzqK1TVxFPP/30kJ4/WrBf2L/a9mzbHTt21PSiRYvS52T6lWzdzeYe3U9Q16jam6uvvjqUbd++vabpkqPJrYXpjWxOcq256qqrhvQMjtt//ud/rmn+5vI3bebMmTV99tlnD+n5nfBOljHGGGNMC/gjyxhjjDGmBUbcXEhv57rFx21h3b6fN29eKMuOAHO7WZ/BLUUeSdY6ZMeVeS9uR2bHSblV2Q9kW/nczr3++utr+oYbbghlCxcuDPn58+fXNM2maoZgnzGvpqXMGzz/jt7A1ayTuRsoZeDxf0X7nqYFmgv1SDDNGepp+JJLLun4vLZ54IEHQl5NnDSjHTx4MOS3bNlS07/6q78ayvbv31/TPBrdyzF+7ZvMfQvznIccD/pu+/bt61hGaM587bXXapouLv7jP/6jpn/913+94z1HC7Yf21fnAdtTxw3LGN1D50nmyTtzu1JKnF9N0T3UPcAdd9wRyj70oQ/V9Gia6t/q9OIuI/ud4rfFeeedV9N02cD7fO5zn+vq+UORIngnyxhjjDGmBfyRZYwxxhjTAv7IMsYYY4xpgRHXZKnLfELbrNrbTzjhhFBGXVOmpcrs9k32f4U6DNX/MFyQHtWn/Ze6kH5Ej2YzlMHf/u3f1vR//dd/pfdRbQ9dHaj2I+t7wvbUv6Ve6MYbbwz5m266qaZ55JwaIe1D1dzwmZnrEd6X7/XRj3609APUJGg7rl27NpQ99thjIa8heA4cOBDKdN5mGrdSYpv2otdi3+j8ZygsrhuqE8rm9wUXXBDK2G8f+chHavrMM88MZdOnT+9Y934kWwPp9uSKK66oaWoRqfXS+cRnaH9zfnM91z5j/9JFyu///u/X9Je+9KVQpi46Vq5cGcqoq9Ox0YuLINM72v+Zm5dSSrnnnntqmmNq4sSJNc1QV1/96le7rs+9995b09Qnn3766Y1/750sY4wxxpgW8EeWMcYYY0wL+CPLGGOMMaYFRlyTRe2SalRoX6cWSKHPJbXFZ2EZMj8bpURtAHUhWViQD3zgA6Fs06ZNg9atlIG+kvqRL37xizVNzYvywgsvpPehhkPJtA3UVmkf8p567apVq0LZ7/7u74b8LbfcUtOPPPJIWp/x48fX9Lhx40KZhllh+zAESxYSaufOnTW9YsWKjte1DeuoOqKPfexjoYx5nRf0k7V8+fKapraG8z2bm1rWpP1RHRj7htfqWOKYu/TSS2v69ttv71i3txLU1NIvnkL/cTq/2A86FjhOsnHRFBJI56KG+Col+nfLfK2VYk3WkZLp/LL+bfJLdeedd9Y01wVdi/7kT/4klHGNVh9qu3fvDmX6m3HrrbeGMmuyjDHGGGNGCX9kGWOMMca0wIibC3nEW7cKecT73HPPrWluPW/bti3kTzzxxJrm1qRuObKsF5f+3I7Ud/nMZz4Tyr773e/W9JQpU0JZZn7rFzTcix7TJtza1zA6peRtr1v9NP9ya5/btMrGjRtreunSpaHs05/+dMe8HvEtZWDoJj26y+Pfasqm+YDb32qSoul4uCO+DxWaXbItfJrjORcVbRu6SGBeQx4RbUOuBTTtZGFgaArQ+tG1Cp+ToeZs1kfnANuuH+jFjU3mloFuD7g29LLWZmh92Z50E6PXcnypO4/Mfctg5W9F2H9N0ptONP2dPqfJ/ZGar+mSR6UjX//610PZH//xH4e8/pZzzfjzP//zmr766quzqg+Kd7KMMcYYY1rAH1nGGGOMMS3gjyxjjDHGmBYYcU2WhjIoJdrUeaRb9Sq079PGOmvWrJqmvqfT80rpLXxLdvz74osvDmU33HBDx/tmoYVGCx5fV9cMn//85zv+3dixY0M+O5pNVOPGfmEfqnaGuhrVYTDkC69Vlw6bN28OZTNnzuxYP7rd0PGWhdHhfaj1oPZstOD8UrI5UkopY8aMqWltl1IGtk2GzjfqP3Rc8fg1j3nr2DnllFNC2f79+0NeXRBQEzpp0qRuql1KieM3c9nRj7CtORa0fbkmaj4b98OJtjXHJuugurq5c+eGsv/8z/8c9LpSBr5nto69VRiqButI/zZDw9y8//3vD2W/93u/V9Pr168PZTNmzAj5DRs21DT1v1dddVVNZ3rLTngnyxhjjDGmBfyRZYwxxhjTAiNuLlQvu6XE7bY33ngjlM2ZM6fjfZq2d4eDpuPBEyZMqOnZs2eHMt2C55YizRLq0iE7xt4mNKNoX2RmE7ZRdkSdW/lqbqVpgWa1k046qabXrFkTyi688MKaPvXUU0MZ3+tf//Vfa/qss84KZTwerN58J0+eHMrUfMCxR3OLtgm91etYoOm1X2gyJ2VzT7fXOQ+49a5knrwzk1Upceyy7jqOSonmTLY/+/xYhaawzHTMdVf7lP2ZuWzIXCI0uRNRE2GTmwhdszWKQSm5CwfmezF7H6s0uXDI5uhwwfXzzDPPrOm77rorlKlrmZtvvjmU3XPPPSH/6KOP1jTnvUpFepEQ/D+8k2WMMcYY0wL+yDLGGGOMaQF/ZBljjDHGtMCIa7LWrl0b8hrahHotPV79wAMPhLITTjgh5FUPkGlkeOS3lzAXDJ+S2en1WuoGeJT429/+dk1/7GMf67o+w8mDDz4Y8tqGWdT5Jr2O9lOme2BIDuqjNOQN+/d73/teTf/SL/1SKFu9enXIr1y5sqYvuuiiUMZ+0eP/7GtqxhS2iY456g5feumlmj5aNUD6vlkfc+71Mk+b3Eh0eibbe/z48SGv405dUZRSyqZNmzo+40jWkX4j0zyVEsc+20jXhl7CpTTVoVv4d5yXqrvS4/6EWjOGVjmWoHZO2zDrh6awSN1qspruk/3tHXfcEfLqekHX0lJKWbduXU3v3bs3lN1///0hr79TXIePVF/mnSxjjDHGmBbwR5YxxhhjTAv4I8sYY4wxpgVa12TR/kpNROaWXkOObN26NZQxtIbqMLLQOSyjvTXTkLCuBw4c6Fh3vbYplM/OnTs73mekoA+wcePG1TTt2epfihoI2vs1z/dWG/oll1wSyqiJ0HHEvr/ssstqev78+aHsr/7qr0Jebfi33HJLKPut3/qt0glqADVMA8c42ySrO+97NKLvR59LOr/o44bo+KAvucynVhby5PDhwyFP3Z1qETPtIWnSIvY7us41aWS03zgv9T5N/suUpmdm6Hqa6YtKiT4I6SdL+4z34RzO/HodbWS/uVm/NIWQGS5dnfbFbbfdFsoeeeSRkFdN9913393xGarNK2WgvzwNB0ZfleonS/1ydYt3sowxxhhjWsAfWcYYY4wxLdC6uXD79u0hz6PwNJ8oJ554Yk1v3LgxlPEosW5z9hLqhSasbAuZph01Rbz++uuhTI//Z6aOUuJ25GjBNtJ3ffLJJ0PZ5ZdfXtPaR6UMNH2q2ZFuGnQLni4kaFrS7XsNZ8Q8zUzf/OY3Qz4zLdH8q2OKZm6aoRTWXU0sbOduorj3O5m7EiULw8E858xQzTVN4be0/WkyX7x4ccf7thU2ZKTQdmE/ZOtlZi7k39Hkxr4YKrpmc/3OTPf87dFQXpyHHMfZutHvsE3UtUEpsV/27dsXytTNTSaPKSWa4jMXGE1zR2Uc9957byj7yEc+EvKf+tSn0nt1qg/dPdBl0HBydK8UxhhjjDF9ij+yjDHGGGNawB9ZxhhjjDEt0LoghNoK2u3Vpp/ps3bt2hXyPGaZuWnodF3TtbTTZ3Zm2qtXrFhR0w899FB6316OjrfFBRdcEPJqF1+zZk3Hv2PYEqL2/iw0ze7du0NZpp3J3G5Qk5VpKbLwIaVEDRmfqVo0jiGOeb2W9bnzzjtr+jOf+UzHuo4mTRoKHb+Zdorjntdmz1GNDPUymS6HfapH+kuJfUNdZRY66WgnmxfZkfqlS5eGsn/5l3+p6f/5n/8JZV/72tdCnmu4omOjScOq8D04xnT94W+GjtteQsaMFqyD9lNWRk0t++maa66paeqD1VXN2LFjOz6jlBj6jpqnRYsW1fQ555wTym6//faQv++++2q6Fw1WL+2T/ebyOyT7LukG72QZY4wxxrSAP7KMMcYYY1rAH1nGGGOMMS3QuiaL/qzUN0kp0f5+9tlnhzLV1zz33HOhjNdmfrKo2VAyTVaT1kY1G//93/8dylTj9PDDD4cy6gY0fNBosXLlypD/4Ac/WNOquyDUORDVz2T+yxjmgDZ07UPayFV3Q70Or1UNR5MvpilTptR0phfK/O/wmSxTHUO/arJ6IQspRP9hmd8stqnS5DMr08/QH476ccvGXNMzjrawOpnuiWP0lVde6XjtJz7xiZqmfoZk7ZmF3yLa9k1+slQzyj5SjRH93s2YMSO9b7+R6ZGoj/roRz8a8vo7y7BTf/iHf9jxGVdeeWXIz549u6bXrl0bylTrtXr16lD2jW98I+SXLVtW0936wSqltzWamiz9/cn89w0F72QZY4wxxrSAP7KMMcYYY1qgdXPhpk2bQp5bz2pC0FA0pZSyf//+ms6O//M+3BbuJSSHmrC4Fc37aKgVPepaSikf//jHa3rr1q2hbOrUqSGvJqM/+IM/6LqubXLHHXfU9JYtW0LZ5z//+Zpevnx5KKP5UE1lWcgLHsXOXH8w/Inmm8JjaJ79ybzel9vLPM6scKyqSYr1oeuKoxF9J4aeytxrUEqQoUfxm9yw6DM55jjO1MSQmaHJ0W4u1PUyMzU1cd1119X0qlWrQllmosnmXpO5RtcGzvemNVtRlzxNJkqaukcDronaT1l4LoYEy9Zhmk1vuummmqZ7hy984QshP3PmzJpWuUkppUycOLHj302ePDnkP/vZz5ZODHWsciyyTXSNpqumIw17550sY4wxxpgW8EeWMcYYY0wL+CPLGGOMMaYFWtdk/cqv/ErI33///SGvx0vPPffcUKbaH2p9Mlt7duSyyfau5byW9l+1M/NY6m233VbT99xzTyijfV/twf0Ij+OqDuMf//EfQxl1NmoLz7Qz1Bswr5oXHklWqKvJtArUWfFv9Zm06atei0feMxcOfIZqjdatWxfKGH6iX9F3euGFF0LZ9OnTO/4d55O2BbVTOqebwvMomT6O5Ry7qgk91sjC6rA9tV8OHjwYym699daaZogt6m91Pc10Vk1H5nXccI2mniZzP6HH9qkXbNIAjwa9hF/T35g9e/aEsp07d3b8O84P/dsFCxaEMv2NKyVqj3/t134tlH3yk5+saf4OfOUrXwl5DXVFetELKnwmx7H2fy8heLrBO1nGGGOMMS3gjyxjjDHGmBZo3VzI7b358+eneeWJJ56oaXrg5TZxZgbMtqlJ5gGef6vmhc2bN4cyPeJ/8cUXp8/sR9RkwOPp1157bU3fddddoYzbza+++mpNs21ff/31mm4yuWVmXDVXNbmC0PHI+mTH/emRXre09R2b7pt5HG8yZfcrakqhqUnbn2VNERUUNd80uWTR+ugYG+xvtW9oEsqObnN8Hm1k6xz7Qc2zdF2yY8eOmubY5rXavmqCJDTPZO4eeB/WXc1CvFZd6TS5/cnMqyPFmjVrQv6ZZ56p6QsvvDCUqSsGurw544wzOl5LKYaaC2l6ZZQQNRf/8i//cijbt29fTfM3g9FblCNxL6LQk71KfUqJ7qMWLlw4pGd0wjtZxhhjjDEt4I8sY4wxxpgW8EeWMcYYY0wLtK7JatJPZOEoVOtCW2y3GqwmqE3ItApZHU499dRQ9uyzz9Y0bbw8Hqyah6HanIcb1Tawj1R7kbVXKaVMmTKlpl977bVQppoNurXgcXBtIx7h17ry7zgWVBfC92K/TJs2raYnTZoUylSvo9eVEnUqpZRy6NChjs9QNyUrVqwoRztsi2z+9xL+StuNY4VzRvPU4WRaII4Vuo05lsg0juwH7SdqE3V+HzhwIJTRLYLqmqi70jlMHR3HCcuza3XtpXsHDQHFunONadLyjgRse13rvvzlL4cyXWupk2UoL3UVw7LHHnuspjnvNm7cGPIbNmyoaYaOe/7552s6c6vTxFA1WjfffHPIf+tb3wp5HX+f+tSnQpnWl+4muqE/ftGNMcYYY44x/JFljDHGGNMC/sgyxhhjjGmB1jVZmeaqCdVEUPtDvyXd6rCoN8hsuk1+fDLbMvUICtukX3RY3aI+otgPbF/VXtAfirYvQ5gwPItey76ePHlyTV9wwQWhjDZ8DSnB/qTmQMNE0IfSpk2baprhb6666qqQVz81H/jAB0LZqlWryrEEdXcKQwplfrEyOLc4T3XMcTxSs6d1Yv/3gw6nLfTdshA3pcR1LlvPVZ91JHB+N+k+h8r48eNrmmFW2CbUUo4G1PYO1Z8T/ZnpfOF7q/7t5ZdfDmXUelGHNRwM12/j0qVLQ566WW2DvXv3hrLLLrvsiJ59dP26G2OMMcYcJfgjyxhjjDGmBVo3F5JetoLVhMQt7OwoJ++p291NLiX0b3kt66510tAEpZTy1FNP1fSyZcs6/l0pR2ZSbYusTqeddlpNc4uYZj91X/C9731vWOqm5sFS4tbvlVdeGcpuuummYXnmSDBSZpI24fa+bsPT5Jq5MsmgGwYe6df78Ng+x+fs2bMHretgf3sskbloodlU5QEjsVaN1LjX8chxS5Maw7AczWh/NqFzYLjMwaPBxz/+8TTfJt7JMsYYY4xpAX9kGWOMMca0gD+yjDHGGGNaYMQ1Wb2goWqoY+JR7CeffLKmaV/PdFbZtdQGzJ07N+TVts2j+NRhKf2owSJZHfXos4ZSKGVgWAY9Gq1hkkqJWqpXXnkllPGYvmreGF5CQ7kc6XHb4SAL3ZK5GzgaNVilRLcN6q6ilPhO7H9qtLoNY0PN0L59+0Jej5brWC1lYPgU1XZyjeFYPpbQkDJcA3ft2hXyQz1G30t4s6FyJHNmz549NT1nzpxQRo3t9OnTh/wc89bGO1nGGGOMMS3gjyxjjDHGmBYYcXNhL9u7//AP/9CxjCYZ9c7N47dqwqAZ7Pjjjw95Pf49ZsyYUMYjrEP1cHskUchHiqFuw8+aNSvNvxWgGexYR72m0wu1mu5oAqbJX03GdMugJmLOuwkTJoS8miXpgX7s2LEhr2YzlSeUMnSP2kcDM2fOrOmHHnoolNGz94UXXjikZ/S7+Vv7e926daFs/vz5Id+L2wNjFO9kGWOMMca0gD+yjDHGGGNawB9ZxhhjjDEtcNybI3HO1hhjjDHmLYZ3sowxxhhjWsAfWcYYY4wxLeCPLGOMMcaYFvBHljHGGGNMC/gjyxhjjDGmBfyRZYwxxhjTAv7IMsYYY4xpAX9kGWOMMca0gD+yjDHGGGNawB9ZxhhjjDEt4I8sY4wxxpgW8EeWMcYYY0wL+CPLGGOMMaYF/JFljDHGGNMC/sgyxhhjjGkBf2QZY4wxxrSAP7KMMcYYY1rAH1nGGGOMMS3gjyxjjDHGmBbwR5YxxhhjTAv4I8sYY4wxpgX8kWWMMcYY0wL+yDLGGGOMaQF/ZBljjDHGtIA/sowxxhhjWuAdo12BjJ/97GeDpksp5d3vfncrzzx06FBNH3fccR3rU0op73jH/2++iRMntlKffuTNN9+s6Z///Oeh7Kc//WnIa5vp35US2++EE04IZWz7kYD1O3jwYE0ff/zxoUzfm2Vvf/vbQ17f813velcoG4337BW2C/tc8z/5yU9C2Y9+9KOa3r59eyj7zne+E/I7d+6s6alTp4Yyzb/tbfF/wx//+Mchv2XLlpr+4Q9/GMrOOuuskF++fHlNz5w5M5RpX3G9YR9rnVi/ow329y9+8Yua5vzW8cuxnfH666+HPNfWrD567aRJkzrWlddy3Oq85Rw+lmD7Ee1D9kO37VdKnBPsB/1bPoP31TWklzHFOanvzXWWc1Sfw2uPdI0+ulcDY4wxxpg+xR9ZxhhjjDEtcNybTXuJLaPbzy+88EIo27p1a00/9dRToUzNeqWUcuKJJ9Y0typPOumkmub24w9+8IOQf+yxxzrWhybB+fPn1/RFF10UyhYtWlTTNEMcbbA9dav/5ZdfDmVvvPFGyOtWME2Cei37YcqUKSE/Y8aMmn7nO9/ZTbUHRZ+ze/fujmWlRHMh665twDGlY7GUOP7Gjx/fsexI3mu40T6nCZAmOJ0nDz/8cCjTvJoDm55JE6COI271s35qjqAJ4b3vfW/Iaz8uXbo0lF188cU1vXLlylA2bdq0kNfxwX5Uc/HRYB7O4HzXtj/55JPTv1XTMddWXQvYv5x7+swJEyaEMpqiXn311Zpm28+dO7emezFLHQ1k84W0MSb5m5HVgebCV155peN9OLd0nWAf6jjhmqVzspS4Zo8dO7ZjXYeCd7KMMcYYY1rAH1nGGGOMMS0w4uZCbu1v2LChpu++++5Q9sQTT9Q0t6m///3vh7yaHbm9rCYCbgU+//zzIa/birrVPFheTRFnn312KDv//PNr+uqrrw5lp59+eshnpyBGiuwEGbda1Yy2d+/eUEYzgL4P+2zPnj0dy2hy09Nd3OqlCahTXUuJ44gmKeZfe+21mlbTcCmxfV588cVQRlPnkiVLanrBggWhbNasWTVNcwtNXSOJml047r/1rW+F/De+8Y2apglWzQSTJ08OZdmJUjUtlRLbm+1CE5E+kyegeK2O15deeimU6Zg77bTTQtm1114b8jr/OR7VxHE0njzUNfLZZ58NZdpnnCMcN1m/HDhwoKbZR5wXOm64bvCZuj5RyqAShFWrVnV8RilxfTwa+jA7Ac71s9v79KOpW02LfC+dv+x7jhs1O7/nPe8Zxhp6J8sYY4wxphX8kWWMMcYY0wL+yDLGGGOMaYFh8fhOPY/mWbZ///6Q//a3v13TX//610OZ6meoc8i8r6t9v5SomaGtnVqvcePG1TR1QbT5qp7jwQcfDGWbNm3qWNcbb7wx5Pmc0YD9pNo5emfWPnz88cdDGdtebea7du0KZdov1DmccsopIa96AOrAVHPAPmLds6PaPC6sWpSnn346lKm9n1ouaoa0DfieY8aMqWkeRx9JTVbmVZt9fP/994e8tjFdG2g7NUVp0L7jnNH6sY/Zpqr3oY6E64iWU4uhOs9t27aFsn//938PedUNUZvUT645ukG1iKWUsmbNmpo+fPhwKNP+pqaNa6uO52y8cY5SZ6Xue6g3ohsWXWO4/ui45hz+8Ic/3HX9+kGj1YuX/kyTRc105oKnH9C5Rf0tx4bCcazjZuHChcNUu//L6I8OY4wxxphjEH9kGWOMMca0QOvmQm7D7tu3L+T1SDDNQLot2xQUVvPcDtWtXpqEuAWamZ7o/mH27Nk1zSOiunV+1113hbIrr7wy5FesWFFGG/ahHqGnCVAD/dKMxvZVNxzsXzUfqZl2sGdm5kutO81B3CrXPI+R02yrLgdoQtHtZZpFaKJSM5QeGy8lmkXVA/VIw/7Xd1q7dm0oY5uqywrOgyzIMtH5xvGgfd50BF3Ls2PdrF9mwqIbE7oyWL9+fU0zuPVwHwlvmx07doS8jnXOL303zks1k5cS5xvXc11vaI7L3Hlk6xbh2qT1owlcA4eXEtcGPlN/Q0bLzQGfm0U9INqebL/h9n7eDVofulrgGFPT8TPPPBPK1FTM7wWaC3UNY1vq7/xQIgN4J8sYY4wxpgX8kWWMMcYY0wL+yDLGGGOMaYFh0WTxqKTmaQenLVSPXVL3oPZ+2kmpn1HNDG3QakelbTY7jtukIVGNAY++qnaB2oTVq1eHPEPyKJk7DGqKjgTWX/uJWio9zs5341hQmzn7RY/f8ph7doyb7ZC5wOAzsyhSrPtJJ53U1d/R3QDD7KgOkceMNbQQ9Uzq3qFtqLNS9yQMPUWdk85NzhnVq3C8Ut+TzWFtCx7T59jR/mAZtUBazvrpe1G7yT5et25dTZ977rmhTHUtvE8vIU6OBI7fTDtEVwyqj6NmR8dsdvy/lDjG+HytH+cBf0P0OawP66DlLBs/fnzHZ+7cuTPkly1bVtP8ndL6cfyPVP+yrfW9m1wv6HzqZS4NFfYnddrqIojaXLa9/r48+eSToUy1w3pdKQO/A+bNm1fTGuqslLhOMcRTN+47vJNljDHGGNMC/sgyxhhjjGkBf2QZY4wxxrTAsBiMaWPN7ND0e6H2f+pC1L5NGz7zai/m81Vrwbpm2gTeh/Z/tVfTNqu2Y9rEt27d2vG+I6nDUdj2WieGtVCbOd+b+i3V2fDd9G+pwaHOKfOjo3oO6i6Ivid1KtT66LUcC/ocPpN59TlFLY+Ok9HysVPKQE2H6hmog2A/qr6BuiadlxwrWXgczhnVzLCdOB50zHFcc/5rOcdgNuZYv82bN9e06uxKib7QRkqjQ3oZW7xW60yfcFrG9THTMVLfo+OGfcZ+yULGcKyyvNN9OKapS9P6ZmNqtPqXdcraPvsd49/14hdK1wE+Q/uFvq6oh9Ny9ievVT0XQ/ZpGeujPhBLibor+kTU/h1KCCXvZBljjDHGtIA/sowxxhhjWmDIe5u6rcjtXN0y5fZjtv2XHf/uJdQCt/Kzo9jcftR34dYgTSF6LeujZdwa53apbrOOlrmQ29zZ1q/26cSJE0PZli1bQl7bnuFFtF04Tlgf3Q7n0X89Ik+zF48Ha334DI4xHRvZ0f+mLXatO12YdKrbSEMzmrqayELRlNK9uZDPyFyQsB91PjWtBUrTuMrMy/peXOPoNmT37t2DpkspZeXKlR2f0Q9wTc7Mc3TZousVj8Vz3dPxzTK9D9dA9m82Tzhu9N1oBsrcd9CsT/mCMlomQoXjXNcrtlcm7+Hc6sVtg84ltrX+5rEtub5kLkP4Lvqe/C3Sa9k+p556asjPmTOnphcsWBDKsr7vBu9kGWOMMca0gD+yjDHGGGNawB9ZxhhjjDEtMGRjcqZtUZpCv2g5bfGqe+B9aP/Xv2V9siOqvRxZ5bWqMaKdW23JGr6hlIHHbZvcDnR6/nBqeHhvrSM1ZJMmTarpJtcLqpfKNFDUa1EDNWHChJrOQpOwH/T5vJb1yXRpGmKnlNi/rDvdlGibUGOQad9GErrp0DFJ/RHbX3UvHMs6rjg2utVDlZKPR45BnRfUG7EOmucao2OQWh+uEzrueJT8SDUdbcP25HhWfQ01rNou7IcsNBLHlM4vllEHpvOLYao4plSnw/BQ2t+qAyploKZI35M6JW2vNtfoDD5X257rGtfIzP1RL2Rra6a5Y3tqSCP+VnLtmT59escy7UPOV9VglRJD6TCsjo43uvnpRkPtnSxjjDHGmBbwR5YxxhhjTAu0fvaUJpDMMy239HTbmNuuPGKrW/s0NekzuXVPM4CSmRZKiVvM3K7VbWxuh9I0w+36TozkEf/Mo7m+N806NLmomS+L8J65PSglbslzi1aPALOPWB+9lq4genEbkXl5zlx/0JSo0eG5jT+SsF461mhy5ba8uqXgfNftdZqPOHbUtMd5qfOLf8d5oX3MNs3M2+xHvS//jm2i45xjUOc7j5n3A1yPOGe0D7kWZHOY7altRo/bai6kaZ79rc9kv3BsZr8hOjZoIuV7ZtEplNF0w6JoffkumbnwSMjmy9SpU7u+j44jlaaUMtAFjvYbx7H2Pd+RJmltE12TS4lRDji+5s2bN/AFgHeyjDHGGGNawB9ZxhhjjDEt4I8sY4wxxpgWaF2TRa1HpqfIjlnyqG7mKoB6Dn0GXfgzr7Za2q6pEzr55JNrmm4aduzYUdPUJrB+PBY9GrBO2r483qz2/j179oQy6jmyI66ZnoPofbIwLzxiS32H2vizY8+llPLSSy/VNPtX24BjnO+sf6tjZrA6jBbUnOnc4xF6as5UU0j3BTquOA+yd6eORPs8C3FUSmx/zllqZjTPOaBjhVoM9qO23+zZszvWpx+huwLOA9WksF90fnFt5/qp60gWQi1z2VBKXDfYL5z/qpVjP6i+h+tWL2Hb+oEsXBT7hfMu05c2rcuKthnX3V7Qv6ULFvavvgvntv6Wc7xxXdC1Xsd7KdH1B8eQNVnGGGOMMaOEP7KMMcYYY1rAH1nGGGOMMS3QtSaL9nW1hWZ+Q+gDin4uqAdQTjnllI7X0aaqdchCxGT6Il5L+3Tmk4WanUxvQnu/2oNHC2ot1I6fhRMibE/VytHWrZoX2v6puVPNC23vqmmbMWNGKKPWQv+WWjhqe/RvqQ1QGz/t/byPjhO2nY6pphBUbUKdyeLFi2uaWiXmdU5RM9Gt76tS4tjheNB1hG2YhbjJ9JmlxLnIeXneeefVtK5FpZQyf/78kNc5rDqgUvpfk0U4h1UTxfZU/Qz9FHG91H7jM/Rv2UdZ/3LcZv6QuJ7re2W+7VgnXtsPsL66nvO3m32Y/XZq23NN5n21DkeylmW/qxxj+ntN7Z72E787qCXW9po2bVoo07l9xhlnpHUfjP4bLcYYY4wxxwD+yDLGGGOMaYFWXDjotjtNMjyeq1tx3FbXY9IambuUgeYt3ebktr9uP3ILOzNZNB3/1u1nhsvIwvzwmTSjdaLNCO+8l5oLaSpTEyD7l22m96HpWE17TSFlsi16DdFBcwH/Tt+T70WzhJo3eAxat9y5NZ5Fsue12l5ZiKe2Yb107mXtUkps8/Xr14cyNfMzlEUG+03NUpzf7HMtbzIXqgnkwIEDoUzH54oVK0LZ9OnTQ17DfHGeDlfYkragyY39q23EcEJqzmlyRaP9QtOTrv3s32w+cd1gXscu+15/izjemB/NkFfdwHfT38em358shJbCfuCaOFxm8Uxiwt+XrF+ee+65mqYp8Zlnngl5fZdFixaFMn3vrH064Z0sY4wxxpgW8EeWMcYYY0wL+CPLGGOMMaYFhqzJyvRAWkY7Lm3xqlegrklDe6xduzaU0c6sugLWTY/YZ0e4WZ+muuvfUqOhGpfsyGwpA4+9d4L3ybQKvcL2VC0N66vXUmOX6TKoo9P7sB94reYZAkY1WU0aMR0LtK9Tq6B56sm0L6hNYB10bFIHpu08mroPjiWdB9QUcQ6pCwfqe/S+HEecT5l+Rvvt0KFDoYzzQscV3Wtk44zHvBUeJed9tQ3Y//2u52kKH6Z6Fuq1tH/ZZxwLbLNOz2wK86PzsslVQOZqSHV0XIO5Hmo53QB1el4pw6ub7QWtP+vANuvW3QLHSea6qRd4X607dV6cWzpnOX81HA7D8m3bti3kde2hBnXJkiU1zXWgG7yTZYwxxhjTAv7IMsYYY4xpga7tTdwGzbYKdbuPpgZuDepWJp+h5pymY72Zh3WtD81QrB9NP9kz1f0ETZ26VZ65lCglmqKyrdPhNA8Smly0HVgnbTO2F81h2t6Zx2CWZa4XuL2tW8hNbhky9yKZ1/nsvjweTHOHuh/IzAc0g44kQzUhlBLHDttJ+zjrC96HY13NSdkaUkpcCzJzMcnqw/Uu82beNJZHCm2HbNxxDjOvZrVZs2aFMr1vkyd+nW98hq6JXKOz+d4URUD7lPIAXXe5FtBMxT7tRL+YC3WcN3lqz+aEwn7p9u96Rb26063K1q1bQ/7pp5+uaf6W67pLczDHpkIJzJQpU2qa478bvJNljDHGGNMC/sgyxhhjjGkBf2QZY4wxxrRA1yKfXnQFaifn39EWr3Z82knVns0j9NRsZPXL9Fq0T2caIoYF2bt3b8fnT5gwYdB7ljLQlq06lkyr0CZsB20z1kHz1EvwWm0X6h6ykDtsI3XTwGdmx7SpidD35DN70ed1uudgddBxlI3bbnUfbdCLBovovM20fYTtpPfJ5mxTmBptR9aH40r7jnoy/VtqdDiudB1r0n2OFKpHY3tqfze5qtE24hF27UOu35xfOv95rT6DY4Zrq/ZLU+gz1eLwmaqdpK5S1+/B6tQJ1ifT/rSJtgP7M9Mzd+ua6UigZpVjU90trF69OpStWbMm5FW/tXLlylCmWirq8RiuZ9++fR3LdO4PxW2Fd7KMMcYYY1rAH1nGGGOMMS3gjyxjjDHGmBboWpNFe2zmQybzf0SNhOoVspANtJNSB6O2d/q7UbIy1o/vxbqrJot+OFSbxDL131FKriEZKagl0HaiD7BMZ6U28lKiPoXtqbZ52umpG9D78BnantSBZFoztnXmn4fjT31asYwaEq0D9TnaJpkOqZ/h2FH0nfh+2d+xLzKNCdH25rrFZ2qe/nG0X3vR2gxXuJFeyfxzZTochonheNZ5Qq1S5iON657OGc4DzXPOUi+o1zb5alItFd9Txxg1V/RZ1+263C8hlLS+nHfsFx03fG8d9+ovrZSBoeQUziWdLxxf6m+ylFJ27NhR0w899FAoYx0WL15c05dccknHZ+7ZsyeUZbpZthf1mL3inSxjjDHGmBbwR5YxxhhjTAsMOU5LFg5Hy2g6oalMt3C5Fa3bfU3HPnXrl6aGzL0DzQn6zKbI7FonXjt79uya5lYzXUGMlnlBycLYsP6a53uzPdWEoEdqeR+acZlXEyHLdIue9aGZR9+TZewHrTtNlHqUnX+XmcVoZlKzcj+Mg6Gg/cFxpKadzCQ9WL4TNItl7ZaFWSklN0PqWOqlb0bL7NvkvkRRMz/bJAuVxf5VsxDvk4UiYlvr37LemXmYaz3nvx7NZ7/oukEXDmwDzv9O146mGxZF1xn2CyUV2maUf6iZjaa6559/PuT1N499qONEXTSUUsrOnTtD/n//939rWsPmlFLKWWedFfJXXnllTa9YsaLjM2kGzULU0eRrc6ExxhhjTB/ijyxjjDHGmBbwR5YxxhhjTAt0rcnKjsLT/qo6E4ZZoXt7ddvAssxWzCPA3R6xZV1pp1f7Ou/J+inUmyxatKimeZyVbaL24dFy4UC7veowePQ5C6VB27fa/9nWmc6B/dTttU0uJbTt+QweFc90OHotxwXbUtuI7jCyo+tHI3wHHc/Uq2T6vUxf1BQGRudipskb7F6K9mN2XSlxbDdd2xa9hD3R9uVamoXV4bWqS+XalYXYytY5rimZxpHznXlde7mOaXtR89vkjkJRXdhwhZ45UvR96L5g27ZtIa/152+VatrIwoULQ17/NpsD6vqolFLuvffekN++fXtNn3322aHsk5/8ZMifdtppNc01Q9daDctWysDfKXUFQrcgkyZNKkeCd7KMMcYYY1rAH1nGGGOMMS3gjyxjjDHGmBboWjyQ+Zqi7kH1Kk26F9Vk0Yavep4sLETTM9XGSpt9poPhM3rxs6J2XOoY2AYK/b6MFPQLo/Zt1lev7UXLQH8jqpeiDiPrp0zPwZANmT6qyYeS1o/vpWMzG/+l5GFAtJ2PVk1W5i9OQ2ZQB8E21XHF+Z75zMv0ok2+tzjOFK07r6O+R8dAL/rV0ULHHddd1j8bv9ou9P/H+aXPZDtof/P52ZpCzSX7W6/N/DBmoYRKyUNAqYatKcxPW1BHt2XLlppev359KHvsscdCPtMe6nvTzyG1Vbq+sz46xjZs2BDKNm7cGPJLly6t6WuvvTaULV++POS7nU9NPhG135r8HvaKd7KMMcYYY1rAH1nGGGOMMS0wLGeNM3MJt11pOtNtRB6FP3z4cE3TjJYd285MXyzjfXW7tCnsh74bt5uXLFlS0zQt0Gyi7z1a5oTMjMW21jZsCmPD9lbU5MYtWt5XTQZsI83z77IQS3wvDZVDslAjTaZOLacpMQvrcrSg79tLCKvMVUAWOic70s+/Zf9ndWDddSw1mXL1b3mtPiOTChwpXGsztxJ6Lc1xPMavcKyrTKLJtYY+M5sH7DPOpyyEGtcxzXPdnTZtWk03mZMydy763iPpvkPbkyFutF9oXucaqf3E32e9D+cH+0WlP+wHrcMTTzwRyugi4Yorrqjp8847L5Rl60tGk2RHxzWvZSjAXvFOljHGGGNMC/gjyxhjjDGmBfyRZYwxxhjTAl0bkGn7Vptmt+FHShlof1W7OEOOqO2Yz6D+QG361ER0e7yaeeo3qBnTI8s8SnzyySfX9IwZM0IZj8KqDXi0NFmZ2wu2tWo42J68j9rQM90VbfhZ/2bjjdoK5lVXx2dQq6CawMy9A4+u06afjSm1949WOJbB0LbJ2ruU+E58P223TNfGZ/I+uv5QC5Idt2e/ZeG4uFapHiXTFpaSz4mR6leuZZl+Rcc6NTvquqKUfK3XfuF7ZmtDNvc4LjI9LtcN6l81LEz2W8RnNrmRUPRd2nTDQi3Tww8/3PHagwcP1jQ1dtTV6RrE8DM6l6hNyvSFmSsNPuOss84K+csuu6ymm9aebnnf+96X5nWM0aWJfqMMBe9kGWOMMca0gD+yjDHGGGNaoOt9bG5F6/Zpti1NL7vcptOtTDWxlRK3grlVyS3ubEtbt/+4pc1tTTUJ8ggyPZZnXt1nzZpV0wsWLEjvo8/hVu5IwT7U92FZ1vc0qWp7s0zNEjQJcHten8OxqH9LM0RmdsyOmJcSt8ppEtQ+pMkiM9vQnDF9+vRB69YGTaZdRd+9acte24LzXcs4tnnfzOyYmVyz+U6TRubNmeuPjtemean34bUjJQFoilChqMmVZnJGr9D7ZH3G8cU53a0Jusntj/YLTTtc33X8sT1UnvLMM8+EMppMX3zxxZqm+W2kXK+wX9RTOuu7Y8eOmmY/sJ90vHLsqmsi/gazX7JIINpmM2fODGXqsqGUuPbwvTL3OFx7tL1eeOGFUHbo0KGOeY4plY0MBe9kGWOMMca0gD+yjDHGGGNawB9ZxhhjjDEt0LUmi9oGtW9nmizawdX1fikDtS6K2kKbImFnoQHUTs8j/dm1tF1TK6DPpO1YtTd0TcH7aj4LEcJ2HmqIgcGgRkKP2fK91d7O+tKVhWreNIwOr83atpRo72d4DO1D6iXYRjqOWFfeV9uE91G7PccQNTg6xnl8eerUqTXd9lF/1is7eq7tzfdjW2SaI9WDZMfgS4ljiW2hdchCsvDaJh2a9jHfU/Mcn0TH62i54uC7aR9SN6hzkfOAedVA8T6qg+E6Rw1PpvPTPuVvBHVCGv6Kvwvsb9XG8pmqwXv88cdDGcOkZa5fsrBZw8n8+fND/vLLL6/pzZs3hzKtx3PPPRfKMpcd1H1loaU4znWuc5zoOqf1HiyvWmfqBflMHcdPPfVUKNP67t27N5RxjOt9qMlqWrea8E6WMcYYY0wL+CPLGGOMMaYF/JFljDHGGNMCXYsHMntspkGgjZq+aNQ/Be3rqsnifWinV00E9TyqraCPqsw/U+Y7qpT43qy72qTnzp0byqjfUnt/5meqTdguGgqI7altpPqIUgb6H1HNBvV3qoFqCkeh7Zv50KJegv2iOhW+M8em1ol6F+3TTPdVSmyj2bNnhzINsdSmnqOUge+QjS3VzzRp/1RDwzZVfUOTfqZbP1lsJ45PrTufSV2OvhvnnvZbk68wLR8tX3dsT303tqe2EbWSzOv7sB1Ua0P/R2z7zB+gjhvqPJv8qymZjpb+jnQOU49JdMxx/Ok8atMnGsO7qH+pD3/4w6Fsy5YtNb179+5QxnZQHav6Aysl/jbx79i/2k+sq4bOoQYrg+sJUe0zr9VxQq0udX9LliypaY7jM888s6u6dsI7WcYYY4wxLeCPLGOMMcaYFhhyWJ2hQtf3apai6/tt27bV9LPPPhvKaCLIzE3ZUezsPtyW5nHSXbt21fS8efM6Pl+31EsZaKLMzDYjdTSc26f6PizTo9rsM5pcdPuZ27Bz5sypaZoI2PZZlHStD00LHBdqxm0yF2bhHTQcTlN/qtuG5cuXhzJ9l+GKON8t2jY0CfYy1rTNeXQ7kxVwrKgpN3PTwLWIczoz42dhdngfbROt22CMVOicXuqg/UsTu7YLQ5Uw1Jia+TlntK0ZMmqo4/lIzOYcx1pfrt/6W8S6ZpIE/mYMpyudoUIpy+mnnz5oejB0/aJrA31Xundgm+l4o/mV5sM24O+UtskHP/jBUMZ1WF128HfqSGUcoz86jDHGGGOOQfyRZYwxxhjTAv7IMsYYY4xpgSGH1WkKM9EJ2u2XLVtW03qcvZRS9u3bV9OPPvpoKNu6dWvIM1TAcEA7N8NGLF68uKYvvfTSjvehjkG1SKUMdHugjJQLB/ZvZod+3/veV9O/8Ru/Ecp43FXfjX2vR8WpnaJeR2FoGu0X6kuoyVEdBt+R2jm9l+rvSolt0GSzz47SjyZZXbTO1KdwXqhug8f/NZwFj4CT7Ii/rjfUR2VuGagvon5Gj3bzmLfOvSZNlrYJn9l0DH24yMYh54HqcBhyhPpD1dmxrXXujbSmsBu07tRyan3Zv2wDHZvUYPK+Rxs6drm2Kk26qkzjqVB/y/ZUuEZl3yG9jD+6HtI5OtyudLyTZYwxxhjTAv7IMsYYY4xpgePeHC7fDC3DaqopsZQYaZxHTXX7nuYkbuVr5Hi6m+B2qW4rcvvRDIT9smfPnprmsWiao9WUQ3OVbinTbMytXz2OziO/9EivdaJrArp7OJbJPImXEufU448/HsoeeeSRms48TTPPZ2pfcC1gfTIP5TRDq6mHcoVVq1bV9IoVK0IZx6DWl2NX69APx/1LiWbd9evXhzKaD3VtW7RoUSibNGlSTY+UWbQXdGzS7K0SgPvuuy+U0QXB+eefX9MLFiwIZdq//SQH6Ce4visjJYnJ0DVluPuwP2a8McYYY8wxhj+yjDHGGGNawB9ZxhhjjDEtcNRosowxxhhjjia8k2WMMcYY0wL+yDLGGGOMaQF/ZBljjDHGtIA/sowxxhhjWsAfWcYYY4wxLeCPLGOMMcaYFvBHljHGGGNMC/gjyxhjjDGmBfyRZYwxxhjTAv8Hfi7Ha+Q9zqwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_reconstructions(stacked_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0:5,:,:].shape"
      ],
      "metadata": {
        "id": "zjrEiaXcx4yg",
        "outputId": "7e68e499-426d-4422-abfc-ad92265774b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codings = stacked_encoder.predict(X_test[0:5,:,:])"
      ],
      "metadata": {
        "id": "MVEU5vjoxm9P",
        "outputId": "89e1f1b9-dce7-4a2f-dc7c-d5461f12f175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codings.shape"
      ],
      "metadata": {
        "id": "LIEx8K6ayWRs",
        "outputId": "eee5cbdb-72ce-4b10-e4b7-584d31490fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newimgcoded=codings.reshape(5,5,6)"
      ],
      "metadata": {
        "id": "QX41Anyoyxj7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newimgcoded.shape"
      ],
      "metadata": {
        "id": "6U3XEDvuy95Q",
        "outputId": "0a2f92c7-b246-42ca-b528-249633283eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 5, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newimgcoded[0,:,:]"
      ],
      "metadata": {
        "id": "wAyYWhO9zOe0",
        "outputId": "531f6138-bab2-49a7-a483-8c9f0e17bbab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4405472 , 1.5916638 , 0.6646811 , 1.5677215 , 0.        ,\n",
              "        0.6291149 ],\n",
              "       [0.        , 3.0523615 , 1.0127752 , 0.        , 0.2755741 ,\n",
              "        0.13008687],\n",
              "       [0.        , 1.0589657 , 1.9835979 , 1.0154039 , 1.2415963 ,\n",
              "        0.        ],\n",
              "       [2.5586486 , 1.2939694 , 0.635094  , 1.3814327 , 0.        ,\n",
              "        0.35907036],\n",
              "       [1.0923222 , 0.9201288 , 0.        , 1.4251618 , 0.        ,\n",
              "        1.4104205 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.imshow(newimgcoded[0,:,:], cmap=\"binary\")"
      ],
      "metadata": {
        "id": "rQDubC-7zHdf",
        "outputId": "ba27c709-c662-42b3-a59b-596ebd82e677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b0c311ea2c0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decodings = stacked_decoder.predict(codings)"
      ],
      "metadata": {
        "id": "LCm2jD1HybGm",
        "outputId": "d18610b4-9fcf-49cf-fb8c-474bdff557dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 391ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decodings.shape"
      ],
      "metadata": {
        "id": "AwcVFkEqyjIK",
        "outputId": "2a08fd9f-155e-48b2-e835-d96bf6069d35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.imshow(decodings[0,:,:], cmap=\"binary\")"
      ],
      "metadata": {
        "id": "hlnTsHxczmw-",
        "outputId": "020443fa-4b97-42f6-8308-6cd0bf4d44b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b0bb9762320>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V30AHmdua9t"
      },
      "source": [
        "Las reconstrucciones parecen borrosas, pero hay que recordar que las imágenes se comprimieron a sólo 30 números, en lugar de 784."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNvi7FQTua9t"
      },
      "source": [
        "## Visualización del conjunto de datos MNIST de moda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C9vSMa1ua9t"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVPNPcavua9u"
      },
      "outputs": [],
      "source": [
        "X_valid_compressed = stacked_encoder.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIh3l5Mgua9u"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(init=\"pca\", learning_rate=\"auto\", random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT4fZLtRua9u"
      },
      "outputs": [],
      "source": [
        "X_valid_2D = tsne.fit_transform(X_valid_compressed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzyMyzPXua9u"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YsYcJ3zua9u"
      },
      "source": [
        "Hagamos este diagrama un poco más bonito (adaptado de [este ejemplo de Scikit-Learn](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_TIsJ4iua9v"
      },
      "outputs": [],
      "source": [
        "# Beautifies the previous diagram for the book\n",
        "import matplotlib as mpl\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "cmap = plt.cm.tab10\n",
        "Z = X_valid_2D\n",
        "Z = (Z - Z.min()) / (Z.max() - Z.min())  # normalize to the 0-1 range\n",
        "plt.scatter(Z[:, 0], Z[:, 1], c=y_valid, s=10, cmap=cmap)\n",
        "image_positions = np.array([[1., 1.]])\n",
        "for index, position in enumerate(Z):\n",
        "    dist = ((position - image_positions) ** 2).sum(axis=1)\n",
        "    if dist.min() > 0.02: # if far enough from other images\n",
        "        image_positions = np.r_[image_positions, [position]]\n",
        "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
        "            mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\"),\n",
        "            position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
        "        plt.gca().add_artist(imagebox)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbovH9XIua9v"
      },
      "source": [
        "### Contrapesos de atado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjGSMvcrua9v"
      },
      "source": [
        "Es habitual vincular los pesos del codificador y el decodificador, utilizando simplemente la transposición de los pesos del codificador como pesos del decodificador. Para ello, tenemos que utilizar una capa personalizada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC5P7dI7ua9v"
      },
      "outputs": [],
      "source": [
        "class DenseTranspose(tf.keras.layers.Layer):\n",
        "    def __init__(self, dense, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dense = dense\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.biases = self.add_weight(name=\"bias\",\n",
        "                                      shape=self.dense.input_shape[-1],\n",
        "                                      initializer=\"zeros\")\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n",
        "        return self.activation(Z + self.biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ta_0YBjua9v"
      },
      "outputs": [],
      "source": [
        "dense_1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
        "dense_2 = tf.keras.layers.Dense(30, activation=\"relu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvqFmXwyua9w"
      },
      "outputs": [],
      "source": [
        "tied_encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    dense_1,\n",
        "    dense_2\n",
        "])\n",
        "\n",
        "tied_decoder = tf.keras.Sequential([\n",
        "    DenseTranspose(dense_2, activation=\"relu\"),\n",
        "    DenseTranspose(dense_1),\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QjmAtNhua9w"
      },
      "outputs": [],
      "source": [
        "tied_ae = tf.keras.Sequential([tied_encoder, tied_decoder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS8ixXkQua9w"
      },
      "outputs": [],
      "source": [
        "# Compiles and fits the model\n",
        "tied_ae.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = tied_ae.fit(X_train, X_train, epochs=10,\n",
        "                      validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggGGxWaMua9x"
      },
      "outputs": [],
      "source": [
        "# Plots reconstructions\n",
        "plot_reconstructions(tied_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crReBlK4ua9x"
      },
      "source": [
        "### Entrenar un Autoencoder cada vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOBPVYNEua9x"
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(n_neurons, X_train, X_valid, n_epochs=10,\n",
        "                      output_activation=None):\n",
        "    n_inputs = X_train.shape[-1]\n",
        "    encoder = tf.keras.layers.Dense(n_neurons, activation=\"relu\")\n",
        "    decoder = tf.keras.layers.Dense(n_inputs, activation=output_activation)\n",
        "    autoencoder = tf.keras.Sequential([encoder, decoder])\n",
        "    autoencoder.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "    autoencoder.fit(X_train, X_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid, X_valid))\n",
        "    return encoder, decoder, encoder(X_train), encoder(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6IE9sWtua9y"
      },
      "outputs": [],
      "source": [
        "X_train_flat = tf.keras.layers.Flatten()(X_train)\n",
        "X_valid_flat = tf.keras.layers.Flatten()(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55Jt1Hz2ua9y"
      },
      "outputs": [],
      "source": [
        "enc1, dec1, X_train_enc1, X_valid_enc1 = train_autoencoder(\n",
        "    100, X_train_flat, X_valid_flat)\n",
        "enc2, dec2, _, _ = train_autoencoder(\n",
        "    30, X_train_enc1, X_valid_enc1, output_activation=\"relu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T4Vi_rTua9y"
      },
      "outputs": [],
      "source": [
        "stacked_ae_1_by_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    enc1, enc2, dec2, dec1,\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSKWhAuEua9z"
      },
      "outputs": [],
      "source": [
        "plot_reconstructions(stacked_ae_1_by_1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_JL-V6Dua9z"
      },
      "source": [
        "Si es necesario, podemos seguir entrenando el autocodificador apilado completo durante unas cuantas épocas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soG8iGwPua90"
      },
      "outputs": [],
      "source": [
        "stacked_ae_1_by_1.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = stacked_ae_1_by_1.fit(X_train, X_train, epochs=5,\n",
        "                                validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUQGmKpmua91"
      },
      "outputs": [],
      "source": [
        "plot_reconstructions(stacked_ae_1_by_1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvLQxjI3ua91"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XznLaQzQua92"
      },
      "source": [
        "## Convolutional Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C56qp-adua92"
      },
      "source": [
        "Construyamos un Autoencoder apilado con 3 capas ocultas y 1 capa de salida (es decir, 2 Autoencoders apilados)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hB05fI1ua93"
      },
      "outputs": [],
      "source": [
        "conv_encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape([28, 28, 1]),\n",
        "    tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 14 × 14 x 16\n",
        "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 7 × 7 x 32\n",
        "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 3 × 3 x 64\n",
        "    tf.keras.layers.Conv2D(30, 3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.GlobalAvgPool2D()  # output: 30\n",
        "])\n",
        "conv_decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(3 * 3 * 16),\n",
        "    tf.keras.layers.Reshape((3, 3, 16)),\n",
        "    tf.keras.layers.Conv2DTranspose(32, 3, strides=2, activation=\"relu\"),\n",
        "    tf.keras.layers.Conv2DTranspose(16, 3, strides=2, padding=\"same\",\n",
        "                                    activation=\"relu\"),\n",
        "    tf.keras.layers.Conv2DTranspose(1, 3, strides=2, padding=\"same\"),\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaZI5135ua93"
      },
      "outputs": [],
      "source": [
        "conv_ae = tf.keras.Sequential([conv_encoder, conv_decoder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sPK0oKLua93"
      },
      "outputs": [],
      "source": [
        "# Compiles and fits the model\n",
        "conv_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZTe41RGua94"
      },
      "outputs": [],
      "source": [
        "history = conv_ae.fit(X_train, X_train, epochs=10,\n",
        "                      validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEZU0wSsua94"
      },
      "outputs": [],
      "source": [
        "# Shows the reconstructions\n",
        "plot_reconstructions(conv_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1xVGIM7ua95"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKz1LPOvua95"
      },
      "source": [
        "## Denoising Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWIicL6Wua95"
      },
      "outputs": [],
      "source": [
        "dropout_encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\")\n",
        "])\n",
        "dropout_decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(28 * 28),\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])\n",
        "dropout_ae = tf.keras.Sequential([dropout_encoder, dropout_decoder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZW4lnxuua96"
      },
      "outputs": [],
      "source": [
        "# Compiles and fits the model\n",
        "dropout_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y5VFaYJua96"
      },
      "outputs": [],
      "source": [
        "history = dropout_ae.fit(X_train, X_train, epochs=10,\n",
        "                         validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kDKJpz6ua97"
      },
      "outputs": [],
      "source": [
        "# This cell generates and saves Figure 17–9\n",
        "dropout = tf.keras.layers.Dropout(0.5)\n",
        "plot_reconstructions(dropout_ae, dropout(X_valid, training=True))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMFWKCa8ua97"
      },
      "source": [
        "Si quieres, puedes probar a sustituir la capa `Dropout` por `tf.keras.layers.GaussianNoise(0.2)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A80UMzBQua98"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHIZAateua98"
      },
      "source": [
        "## Sparse Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbc5p31mua98"
      },
      "source": [
        "Utilicemos la función de activación sigmoidea en la capa de codificación. Añadamos también $\\ell_1$ regularización a la misma: para ello, añadimos una capa `ActivityRegularization` después de la capa de codificación. Alternativamente, podríamos añadir `activity_regularizer=tf.keras.regularizers.l1(1e-4)` a la propia capa de codificación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bILT_vbuua98"
      },
      "outputs": [],
      "source": [
        "sparse_l1_encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(300, activation=\"sigmoid\"),\n",
        "    tf.keras.layers.ActivityRegularization(l1=1e-4)\n",
        "])\n",
        "sparse_l1_decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(28 * 28),\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzJdnLCFua98"
      },
      "outputs": [],
      "source": [
        "sparse_l1_ae = tf.keras.Sequential([sparse_l1_encoder, sparse_l1_decoder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxTDbzohua99"
      },
      "outputs": [],
      "source": [
        "# Compiles and fits the model\n",
        "sparse_l1_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35P0T68Eua99"
      },
      "outputs": [],
      "source": [
        "history = sparse_l1_ae.fit(X_train, X_train, epochs=10,\n",
        "                           validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaQEWnIgua99"
      },
      "outputs": [],
      "source": [
        "# extra code – shows the reconstructions\n",
        "plot_reconstructions(sparse_l1_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R34lXqHRua9-"
      },
      "source": [
        "Vamos a trazar la pérdida de Divergencia KL, frente a la MAE y MSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnpsLaz4ua9-"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 17–10\n",
        "p = 0.1\n",
        "q = np.linspace(0.001, 0.999, 500)\n",
        "kl_div = p * np.log(p / q) + (1 - p) * np.log((1 - p) / (1 - q))\n",
        "mse = (p - q) ** 2\n",
        "mae = np.abs(p - q)\n",
        "plt.plot([p, p], [0, 0.3], \"k:\")\n",
        "plt.text(0.05, 0.32, \"Target\\nsparsity\", fontsize=14)\n",
        "plt.plot(q, kl_div, \"b-\", label=\"KL divergence\")\n",
        "plt.plot(q, mae, \"g--\", label=r\"MAE ($\\ell_1$)\")\n",
        "plt.plot(q, mse, \"r--\", linewidth=1, label=r\"MSE ($\\ell_2$)\")\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.xlabel(\"Actual sparsity\")\n",
        "plt.ylabel(\"Cost\", rotation=0)\n",
        "plt.axis([0, 1, 0, 0.95])\n",
        "plt.grid(True)\n",
        "save_fig(\"sparsity_loss_plot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8c4s-_Cua9-"
      },
      "source": [
        "Definamos un regularizador personalizado para la regularización de la Divergencia KL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ee0aWEGua9-"
      },
      "outputs": [],
      "source": [
        "kl_divergence = tf.keras.losses.kullback_leibler_divergence\n",
        "\n",
        "class KLDivergenceRegularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, weight, target):\n",
        "        self.weight = weight\n",
        "        self.target = target\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        mean_activities = tf.reduce_mean(inputs, axis=0)\n",
        "        return self.weight * (\n",
        "            kl_divergence(self.target, mean_activities) +\n",
        "            kl_divergence(1. - self.target, 1. - mean_activities))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cJxnYPCua9_"
      },
      "source": [
        "Ahora vamos a utilizar este regularizador para empujar el modelo a tener un 10% de sparsity en la capa de codificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5hlV4JZua9_"
      },
      "outputs": [],
      "source": [
        "kld_reg = KLDivergenceRegularizer(weight=5e-3, target=0.1)\n",
        "sparse_kl_encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(300, activation=\"sigmoid\",\n",
        "                          activity_regularizer=kld_reg)\n",
        "])\n",
        "sparse_kl_decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(28 * 28),\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkP2Jtekua9_"
      },
      "outputs": [],
      "source": [
        "sparse_kl_ae = tf.keras.Sequential([sparse_kl_encoder, sparse_kl_decoder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD3jxSVvua9_"
      },
      "outputs": [],
      "source": [
        "# Compiles and fits the model\n",
        "sparse_kl_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKRo4W-jua-A"
      },
      "outputs": [],
      "source": [
        "history = sparse_kl_ae.fit(X_train, X_train, epochs=10,\n",
        "                           validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyPBZuA7ua-A"
      },
      "outputs": [],
      "source": [
        "# extra code – shows the reconstructions\n",
        "plot_reconstructions(sparse_kl_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHD2Rfjvua-A"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpi6Ta0Vua-A"
      },
      "source": [
        "# Programando una GAN\n",
        "\n",
        "A continuación se presentarán los pasos para implementar una GAN que permite entrenar un *Generador* que sintetiza dígitos escritos a mano que parecen reales usando *Deep Convolutional Generative Adversarial Networks (DCGAN)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRLFKoSEua-B"
      },
      "source": [
        "Capturas de las imágenes producidas por el Generador en diferentes *epochs* durante su proceso de entrenamiento (se indica en qué número de epoch se ha generado cada imagen)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipVbiaWJua-B"
      },
      "source": [
        "* Se usa el Generador para generar 100 imágenes\n",
        "* Se podrá observar fácilmente que al inicio del entrenamiento las imágenes aparecen como ruido aleatorio\n",
        "* A medida que va avanzando el entrenamiento (va avanzando el número de *epochs*) los dígitos generados se parecen cada vez más a dígitos reales escritos a mano.\n",
        "* El objetivo final en un caso real es que el Generador sintetice imágenes de 28 × 28 que se confundan como datos reales del conjunto MNIST (conjunto de imágenes que hemos considerado como «reales»)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8rG5qzfua-B"
      },
      "source": [
        "#### Descarga de los datos  y preprocesado de los datos\n",
        "\n",
        "Descargar y preparar el conjunto de datos con el que entrenaremos la GAN.\n",
        "Ahora ya podemos descargar las imágenes del conjunto de datos **MNIST** de dígitos escritos a mano, que serán las imágenes que consideraremos *«reales»* para este ejemplo. Podemos hacerlo directamente desde ``keras.datasets`` y preparar las imágenes para ser usadas por las redes con el siguiente código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4fYMGxGhrna"
      },
      "outputs": [],
      "source": [
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJg_ifnvua-C"
      },
      "source": [
        "En este caso solo interesan las imágenes (no se descargan las labels ni los datos de prueba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKqUH8-dua-C"
      },
      "source": [
        "Las imágenes se normalizan en el rango ``[-1, 1]`` para poder usar como función de activación en la capa final del Generador la función ``tanh``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt8S7tzzua-D"
      },
      "outputs": [],
      "source": [
        "train_images = (train_images - 127.5) / 127.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmUnUhQjua-D"
      },
      "source": [
        "Se barajan y preparan los datos en lotes con el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMdPqVjfua-D"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZU3Ilr2gn5y"
      },
      "source": [
        "## Creación de los modelos\n",
        "\n",
        "A continuación, se pasa a crear las redes neuronales que actuarán de Generador y Discriminador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### Generador\n",
        "\n",
        "Siguiendo el esquema que había descrito, el Generador recibe como entrada ruido, que puede obtener por ejemplo con ``tf.random.normal``.\n",
        "De este ruido debe crear una imagen de $28×28$ píxeles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53SxRunmua-E"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsDYOFtzKIHi"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QlXbX2EwMCX"
      },
      "outputs": [],
      "source": [
        "generator = make_generator_model()\n",
        "generator.summary ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhlzuHXUua-G"
      },
      "source": [
        "Descripción del modelo:\n",
        "1. Capa densa que recoge el vector de ruido de entrada y lo transforma en un tensor tridimensional\n",
        "2. En las capas sucesivas se va transformando hasta llegar a una salida de 28 × 28 × 1.\n",
        "3. La red aumenta los tamaños de los mapas de características con la capa Conv2DTranspose.\n",
        "    * La capa convolución transpuesta se usa generalmente para aumentar el mapa de características.\n",
        "    * La convolución transpuesta funciona insertando ceros entre los elementos de los mapas de características de entrada y, después, aplicando una convolución normal.\n",
        "4. La capa ``LeakyReLU`` es una versión modificada de la función de activación ReLU que tiene una pequeña pendiente para valores negativos, en lugar de cero como la ReLU (determinada por el argumento).\n",
        "    * Esta se utiliza en cada capa excepto en la última capa.\n",
        "    * Esta capa es una funciones de activación avanzadas en Keras y solo está disponible como capa y no como funciones de activación.\n",
        "5. En la última capa se ha usado una función de activación ``tanh``:\n",
        "    * ``tanh`` tiende a producir imágenes más nítidas que la sigmoide (rango típico de 0 a1)\n",
        "6. Se usa la capa ``BatchNormalization`` para normalizar las entradas de la capa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhSdj5P5ua-G"
      },
      "source": [
        "Podemos comprobar que la red funciona como se espera con el siguiente código, en el que el Generador genera una instancia de datos fake:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl7jcC7TdPTG"
      },
      "outputs": [],
      "source": [
        "noise_dim = 100\n",
        "noise = tf.random.normal([1, noise_dim])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### Discriminador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGdKHsvoua-H"
      },
      "source": [
        "Por otra parte, el Discriminator recibe imágenes de $28×28×1$ píxeles y saca una probabilidad que indica si esta imagen de entrada la considera real (en lugar de fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mypJk88So23v"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, LeakyReLU, Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9ZMbjUUua-H"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2D(128*2, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2D(128*3, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkA05NE6QMs",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "discriminator = make_discriminator_model()\n",
        "discriminator.summary ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx6-FK_lua-I"
      },
      "source": [
        "Esta red se construye con tres capas convolucionales de 32, 64 y 128 neuronas, con función de activación ``LeakyReLU`` y ``BatchNormalization``. La última capa es una capa densa con una función de activación sigmoide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kz_3yBXua-I"
      },
      "source": [
        "El Discriminador se usará para clasificar las imágenes generadas como reales o fake, generando valores:\n",
        "* Próximos al 1 para imágenes que considera reales\n",
        "* Próximos a 0 para imágenes que considera fake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2eg1l3eua-I"
      },
      "source": [
        "Podemos comprobar que el Discriminador funciona como creemos con el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mp1vF2Aua-J"
      },
      "outputs": [],
      "source": [
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Funciones de *Loss* y optimizadores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWqXHCLAua-J"
      },
      "source": [
        "Una vez los modelos del Generador y Discriminador fueron creados, el siguiente paso para entrenar las redes es establecer la función de pérdida y el optimizador que se usará para el proceso de entrenamiento.\n",
        "* Anteriormente esto se ha indicado con los argumentos del método ``compile()`` que luego se usan cuando se entrena el modelo al ejecutar el método ``fit()``\n",
        "* Ahora se tinen **dos redes neuronales**, se requieren dos funciones de pérdida y dos optimizadores.\n",
        "* Los parámetros de ambas redes están interrelacionados en el cálculo de la función de pérdida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5ZOGKEnua-J"
      },
      "source": [
        "### Funciones de pérdida\n",
        "\n",
        "Para las funciones de pérdida de ambas redes neuronales se utilizá la *binary cross entropy*, que es una medida de la diferencia entre las probabilidades calculadas y las probabilidades reales de predicciones en los casos donde solo hay **dos clases posibles** en las que pueden ser clasificados los datos de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psQfmXxYKU3X"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKY_iPSPNWoj"
      },
      "source": [
        "### Discriminator loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cVrJchIua-L"
      },
      "source": [
        "Con la función auxiliar ``cross_entropy`` se definirá la función ``discriminator_loss()`` para cuantificar una *loss* del Discriminador que nos indicará cómo de bien el Discriminador consigue distinguir imágenes reales de imágenes fake en una iteración\n",
        "* La función recibe en el primer argumento (real_output) la predicción que ha hecho el Discriminador de un batch de imágenes reales\n",
        "* En el segundo argumento (fake_output) la predicción que ha hecho de un batch una imagen fake.\n",
        "\n",
        "Si la predicción fuera la correcta, para una imagen real la predicción debería ser 1 y para una imagen fake debería ser 0.\n",
        "* Esta función compara el batch de imágenes reales predecidas por el Discriminador con un array de unos ``(tf.ones_like(real_output))`` y el batch de imágenes fake con un array de ceros ``(tf.zeros_like(real_output))``.\n",
        "\n",
        "La loss para esta iteración está compuesta tanto por los errores de predicción de imágenes reales como por los errores de las imágenes fake; por tanto, se deben sumar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-3GCUEiKtv"
      },
      "source": [
        "### Generator loss\n",
        "\n",
        "La manera de construir la función ``generator_loss`` para cuantificar una loss del Generador será muy parecida:\n",
        "* La loss del Generador deberá cuantificar cómo de bien fue capaz de engañar al Discriminador\n",
        "* Se comparan las decisiones del Discriminador sobre las imágenes generadas por el Generador con una matriz de unos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90BIcCKcDMxz"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgIc7i0th_Iu"
      },
      "source": [
        "### Optimizadores\n",
        "\n",
        "Los optimizadores del Discriminador y del Generador son diferentes y se requieren dos, ya que se entrenarán las dos redes por separado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-TmP6S0ua-O"
      },
      "outputs": [],
      "source": [
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO6ZGeI7ua-O"
      },
      "source": [
        "Para la optimización de ambas redes, es sescoge el algoritmo *Adam*. *Adam* se ha convertido en el optimizador para la mayoría de las implementaciones de GAN porque se ha demostrado que en la práctica tiene un rendimiento superior a otros métodos de optimización en este tipo de redes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuXySZBahFjt"
      },
      "source": [
        "## Entrenamiento con la API de bajo nivel de TensorFlow\n",
        "\n",
        "Anteriormente se ha utilizado el objeto ``tf.keras.Model``, a través de sus métodos ``fit()`` y ``compile()``, para entrenar a los modelos.\n",
        "* Muy útil, ya que permite ahorrar escribir el código de bucle de entrenamiento\n",
        "* Da suficiente control con *callbacks*, *métricas*, etc.\n",
        "\n",
        "**¿Cómo se puede especificar con el método ``fit()`` que esta red neuronal tiene dos funciones de pérdida y dos optimizadores?** La respuesta es ¡no se puede!\n",
        "\n",
        "En **TensorFlow 2.0** se puede utilizar la API de bajo nivel para escribir bucles de entrenamiento personalizados. Se utilizará el ``GradientTape`` de la API de bajo nivel, que  permite más control para personalizar el bucle de entrenamiento:\n",
        "* Entrenar a la vez las dos redes neuronales que se requieren para una GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg7VOc3zua-P"
      },
      "source": [
        "En general, los códigos utilizarán mayormente las API de alto nivel (especialmente ``tf.keras`` y ``tf.data``), pero cuando se necesita más flexibilidad, se utiliza la API de Python de nivel inferior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "### Entrenamiento de las redes GAN\n",
        "\n",
        "Es necesario crear un bucle de entrenamiento personalizado utilizando la API de bajo nivel de TensorFlow. Se recreará una función ``train()`` a ala cual se le pasarán en los argumentos los datos de entrenamiento y el número de epochs que se quieren ejecutar para entrenar simultaneamente el Generador y el Discriminador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UUD9GVKua-P"
      },
      "source": [
        "La función ``train_step`` llamada dentro de ``train()`` representa un paso del bucle de entrenamiento (en sustitución del método ``fit()`` usando la API de bajo nivel de TensorFlow 2). Se define en 4 pasos:\n",
        "1. Creación de un conjunto de semillas de ruido con el que el Generador pueda generar las imágenes fake correspondientes (recordemos que estamos procesando las imágenes por lotes de tamaño BATCH_SIZE y que, por tanto, genera un vector de semillas, no una sola semilla)\n",
        "```Python\n",
        "noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "```\n",
        "Con este vector de ruido el Generador genera un batch de imágenes fake:\n",
        "```Python\n",
        "generated_images = generator(noise, training=True)\n",
        "```\n",
        "Se usa el Discriminador para clasificar un batch de imágenes reales extraídas del conjunto MNIST (recibidas como argumento) y un batch de imágenes fake acabadas de producir por el Generador:\n",
        "```Python\n",
        "real_output = discriminator(images, training=True)\n",
        "fake_output = discriminator(generated_images, training=True)\n",
        "```\n",
        "2. Cuando ya se tienen los valores obtenidos por el Generador y el Discriminador, se calcula la loss de ambos modelos con las funciones que se han definido anteriormente\n",
        "```Python\n",
        "gen_loss = generator_loss(fake_output)\n",
        "disc_loss = discriminator_loss(real_output, fake_output)\n",
        "```\n",
        "    * Los pasos anteriores se ejecutan dentro del contexto (context) de ``tf.GradientTape`` indicados por ``with``.\n",
        "    * En concreto, se están considerando dos contextos, uno para la información del Generador (``gen_tape``) y otro para la información del Discriminador (``disc_tape``).\n",
        "    * ``tf.GradientTape`` permite que se *«graben»* en un objeto las operaciones ejecutadas en el contexto para permitir obtener los gradientes con respecto a la loss\n",
        "3. Se debe propagar hacia atrás la loss para que llegue a todas las variables que conforman los parámetros (entrenables) para cada una de las dos redes neuronales. Esto es fácil una vez grabadas las operaciones en los respectivos contextos ``gen_tape`` y ``disc_tape``, aplicando el método ``gradient()`` para obtener los gradientes con respecto a la función de pérdida para las dos redes:\n",
        "```Python\n",
        "gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "```\n",
        "4. Utilizar la información de los gradientes propagada para actualizar con el algoritmo de descenso del gradiente las variables correspondientes a los parámetros entrenables de cada una de las redes neuronales. Para ello simplemente hace falta usar el método ``apply_gradients()`` de los optimizadores de ambas redes\n",
        "```Python\n",
        "generator_optimizer.apply_gradients(zip(gradients_of_generator,\n",
        "                                        generator.trainable_variables))\n",
        "discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,\n",
        "                                            discriminator.trainable_variables))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t5ibNo05jCB"
      },
      "outputs": [],
      "source": [
        "@tf.function # Decorador: timizada a nivel interno para poder ser acelerada en el hardware disponible.\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nts43kLUdPG-"
      },
      "source": [
        "#### Training loop\n",
        "\n",
        "Este método ejecuta un doble bucle, como se ve en el siguiente código:\n",
        "* El primer bucle tiene tantas iteraciones como epochs hemos indicado en el argumento, y el segundo itera para todos los batch del dataset.\n",
        "\n",
        "* El cuerpo del bucle simplemente llama al método ``train_step``,que realiza todo el trabajo requerido para calcular las loss y actualizar los parámetros de las dos redes, para todas las imágenes de un batch en una epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M7LmLtGEMQJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "grid_size_x= 10\n",
        "grid_size_y= 10\n",
        "seed = tf.random.normal([grid_size_x*grid_size_y , noise_dim])\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "        train_step(image_batch)\n",
        "\n",
        "    generate_images(generator,seed)\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "    generate_images(generator, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1QvoUcsua-Q"
      },
      "source": [
        "Después de cada epoch se invoca a la función ``generate_images`` que visualiza por pantalla predicciones generadas por el Generador, y para ello usa las variables ``seed``, ``grid_size_x`` y ``grid_size_y``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "#### Visualización de las imagenes\n",
        "Función auxiliar para visualizar las imagenes que genera el Generador para ver que va aprendiendo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "outputs": [],
      "source": [
        "def generate_images(model, test_input):\n",
        "\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(grid_size_x,grid_size_y))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(grid_size_x, grid_size_y, i+1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "### Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly3UN0SLLY2l"
      },
      "outputs": [],
      "source": [
        "## %%time\n",
        "EPOCHS = 12000\n",
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTMCZIF_ua-R"
      },
      "source": [
        "# Detección de fraudes usando autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_LXctgcua-R"
      },
      "source": [
        "Este código fuente muestra cómo detectar transacciones fraudulentas en tarjetas débito y crédito usando un autoencoder.\n",
        "El set de datos (creditcard.csv) se puede descargar de este [enlace](https://drive.google.com/file/d/1Lf4tMOt45IFARFO-dNl4-Df8x-gjUMu5/view).\n",
        "    \n",
        "Contiene $284,315$ registros con transacciones normales y $492$ fraudulentas. Una vez entrenado el autoencoder se logrará un recall igual a 0.92.\n",
        "Este código está basado en el post de David Ellison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm0gRuvMua-S"
      },
      "source": [
        "### LECTURA DEL SET DE DATOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP_497s_ua-S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "datos = pd.read_csv(\"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\")\n",
        "print(datos.head())\n",
        "\n",
        "nr_clases = datos['Class'].value_counts(sort=True)\n",
        "print(nr_clases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkFs7-qfua-S"
      },
      "source": [
        "## ANÁLISIS EXPLORATORIO DE LOS DATOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s71RDxLyua-S"
      },
      "source": [
        "#### Cantidad de registros normales vs. fraudulentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoOCHhFqua-T"
      },
      "outputs": [],
      "source": [
        "nr_clases.plot(kind = 'bar', rot=0)\n",
        "plt.xticks(range(2), ['Normales', 'Fraudulentos'])\n",
        "plt.title(\"Distribución de los datos\")\n",
        "plt.xlabel(\"Clase\")\n",
        "plt.ylabel(\"Cantidad\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZW4g0H0ua-T"
      },
      "source": [
        "##### Monto de las transacciones vs. tiempo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isYz73qlua-T"
      },
      "outputs": [],
      "source": [
        "normales = datos[datos.Class==0]\n",
        "fraudulentos = datos[datos.Class==1]\n",
        "plt.scatter(normales.Time/3600, normales.Amount,\n",
        "            alpha = 0.5, c='#19323C', label='Normales', s=3)\n",
        "plt.scatter(fraudulentos.Time/3600, fraudulentos.Amount,\n",
        "            alpha = 0.5, c='#F2545B', label='Fraudulentos', s=3)\n",
        "plt.xlabel('Tiempo desde la primera transacción (h)')\n",
        "plt.ylabel('Monto (Euros)')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXE9cGiua-T"
      },
      "source": [
        "#### Distribución de las características V1 a V28 en normales y fraudulentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_pqO0Uuua-U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "\n",
        "v_1_28 = datos.iloc[:,1:29].columns\n",
        "gs = gridspec.GridSpec(28, 1)\n",
        "for i, cn in enumerate(datos[v_1_28]):\n",
        "    sns.distplot(datos[cn][datos.Class == 1], bins=50,\n",
        "                 label='Fraudulentos', color='#F2545B')\n",
        "    sns.distplot(datos[cn][datos.Class == 0], bins=50,\n",
        "                 label='Normales', color='#19323C')\n",
        "    plt.xlabel('')\n",
        "    plt.title('Histograma característica: ' + str(cn))\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAvBsroGua-U"
      },
      "source": [
        "## PRE-PROCESAMIENTO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLU7TFTDua-U"
      },
      "source": [
        "#### La variable \"Tiempo\" no aporta información. La eliminaremos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9-15rOAua-U"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "datos.drop(['Time'], axis=1, inplace=True)\n",
        "datos['Amount'] = StandardScaler().fit_transform(datos['Amount'].values.reshape(-1,1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test = train_test_split(datos, test_size=0.2, random_state=42)\n",
        "X_train = X_train[X_train.Class == 0]\n",
        "X_train = X_train.drop(['Class'], axis=1)\n",
        "X_train = X_train.values\n",
        "\n",
        "Y_test = X_test['Class']\n",
        "X_test = X_test.drop(['Class'], axis=1)\n",
        "X_test = X_test.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlV9Aarcua-V"
      },
      "source": [
        "## AUTOENCODER: 29-20-14-20-29, tanh-relu-tanh-relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCZsP2_Yua-V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(5)\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NKbbyFzua-W"
      },
      "outputs": [],
      "source": [
        "dim_entrada = X_train.shape[1]          # 29\n",
        "capa_entrada = Input(shape=(dim_entrada,))\n",
        "\n",
        "encoder = Dense(20, activation='tanh')(capa_entrada)\n",
        "encoder = Dense(14, activation='relu')(encoder)\n",
        "\n",
        "decoder = Dense(20, activation='tanh')(encoder)\n",
        "decoder = Dense(29, activation='relu')(decoder)\n",
        "\n",
        "autoencoder = Model(inputs=capa_entrada, outputs=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6a28-q-ua-X"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import SGD\n",
        "sgd = SGD(lr=0.01)\n",
        "autoencoder.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "nits = 100\n",
        "tam_lote = 32\n",
        "autoencoder.fit(X_train, X_train, epochs=nits, batch_size=tam_lote, shuffle=True, validation_data=(X_test,X_test), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnXvIM_Iua-X"
      },
      "source": [
        "## VALIDACIÓN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjvlcZFIua-Y"
      },
      "source": [
        "#### Predicción X_test -> Autoencoder -> X_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuR6iU3Iua-Y"
      },
      "outputs": [],
      "source": [
        "X_pred = autoencoder.predict(X_test)\n",
        "ecm = np.mean(np.power(X_test-X_pred,2), axis=1)\n",
        "print(X_pred.shape)\n",
        "\n",
        "# Gráfica precision-recall para determinar el umbral\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "precision, recall, umbral = precision_recall_curve(Y_test, ecm)\n",
        "\n",
        "plt.plot(umbral, precision[1:], label=\"Precision\",linewidth=5)\n",
        "plt.plot(umbral, recall[1:], label=\"Recall\",linewidth=5)\n",
        "plt.title('Precision y Recall para diferentes umbrales')\n",
        "plt.xlabel('Umbral')\n",
        "plt.ylabel('Precision/Recall')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCPUMbH8ua-Y"
      },
      "source": [
        "#### Matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wf_mi3oua-Y"
      },
      "outputs": [],
      "source": [
        "umbral_fijo = 0.75\n",
        "Y_pred = [1 if e > umbral_fijo else 0 for e in ecm]\n",
        "\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te7h5LJgua-Z"
      },
      "source": [
        "___\n",
        "¡Todo bien! ¡Es todo por hoy! 😀"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "14-Generative-Adversarial-Networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}