{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/2.2_machinelearning_decisiontreeandrandomforests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/2.2_machinelearning_decisiontreeandrandomforests.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzB4FeQwkq4n"
   },
   "source": [
    "### Ejemplo de código\n",
    "# Sesión 04: Árboles de decisión, Random Forests y exploración aleatorizada\n",
    "## Deep Learning y series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran **E-mail:** marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos primero unas librerías y funciones que vamos a usar a durante la sesión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Para hacer gráficas\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l0PVs_y_kq4n"
   },
   "outputs": [],
   "source": [
    "# Función para visualizar un conjunto de datos en 2D\n",
    "def plot_data(X, y):\n",
    "    y_unique = np.unique(y)\n",
    "    colors = pl.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[y == this_y]\n",
    "        pl.scatter(this_X[:, 0], this_X[:, 1],  c=color,\n",
    "                    alpha=0.5, edgecolor='k',\n",
    "                    label=\"Class %s\" % this_y)\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Data\")\n",
    "    \n",
    "# Función para visualizar de la superficie de decisión de un clasificador\n",
    "def plot_decision_region(X, pred_fun):\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    min_x = min_x - (max_x - min_x) * 0.05\n",
    "    max_x = max_x + (max_x - min_x) * 0.05\n",
    "    min_y = min_y - (max_y - min_y) * 0.05\n",
    "    max_y = max_y + (max_y - min_y) * 0.05\n",
    "    x_vals = np.linspace(min_x, max_x, 100)\n",
    "    y_vals = np.linspace(min_y, max_y, 100)\n",
    "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "    grid_r, grid_c = XX.shape\n",
    "    ZZ = np.zeros((grid_r, grid_c))\n",
    "    for i in range(grid_r):\n",
    "        for j in range(grid_c):\n",
    "            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n",
    "    pl.contourf(XX, YY, ZZ, 100, cmap = pl.cm.coolwarm, vmin= -1, vmax=2)\n",
    "    pl.colorbar()\n",
    "    pl.xlabel(\"x\")\n",
    "    pl.ylabel(\"y\")\n",
    "    \n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "def gen_pred_fun(clf):\n",
    "    def pred_fun(x1, x2):\n",
    "        x = np.array([[x1, x2]])\n",
    "        return clf.predict(x)[0]\n",
    "    return pred_fun\n",
    "\n",
    "def plot_labels(n_folds, n_classes, list_labels):\n",
    "    ind = np.arange(n_folds)\n",
    "    width = 0.15\n",
    "    \n",
    "    countings = []\n",
    "    for labels in list_labels:\n",
    "        labels = np.array(labels)\n",
    "        countings.append([np.count_nonzero(labels == x) for x in range(n_classes)])\n",
    "    \n",
    "    class_bars = []\n",
    "    for cls in range(n_classes):\n",
    "        class_bars.append([l[cls] for l in countings])\n",
    "    \n",
    "    fig, ax = pl.subplots()\n",
    "    i = 0\n",
    "    for class_bar in class_bars:\n",
    "        ax.bar(ind + width*i, class_bar, width, label='Clase '+str(i))\n",
    "        i += 1\n",
    "        \n",
    "    ax.set_xticks(ind + 2*width / 3)\n",
    "    ax.set_xticklabels(['Pliegue {}'.format(k) for k in range(n_folds)])\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Etiquetas\")\n",
    "    \n",
    "# Función para visualizar un conjunto de datos en 2D\n",
    "def plot_data(X, y):\n",
    "    y_unique = np.unique(y)\n",
    "    colors = pl.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[y == this_y]\n",
    "        pl.scatter(this_X[:, 0], this_X[:, 1],  c=color.reshape(1,-1),\n",
    "                    alpha=0.5, edgecolor='k',\n",
    "                    label=\"Class %s\" % this_y)\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Data\")\n",
    "    \n",
    "# Función para visualizar de la superficie de decisión de un clasificador\n",
    "def plot_decision_region(X, pred_fun):\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    min_x = min_x - (max_x - min_x) * 0.05\n",
    "    max_x = max_x + (max_x - min_x) * 0.05\n",
    "    min_y = min_y - (max_y - min_y) * 0.05\n",
    "    max_y = max_y + (max_y - min_y) * 0.05\n",
    "    x_vals = np.linspace(min_x, max_x, 100)\n",
    "    y_vals = np.linspace(min_y, max_y, 100)\n",
    "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "    grid_r, grid_c = XX.shape\n",
    "    ZZ = np.zeros((grid_r, grid_c))\n",
    "    for i in range(grid_r):\n",
    "        for j in range(grid_c):\n",
    "            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n",
    "    pl.contourf(XX, YY, ZZ, 100, cmap = pl.cm.coolwarm, vmin= -1, vmax=2)\n",
    "    pl.colorbar()\n",
    "    pl.xlabel(\"x\")\n",
    "    pl.ylabel(\"y\")\n",
    "    \n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "def gen_pred_fun(clf):\n",
    "    def pred_fun(x1, x2):\n",
    "        x = np.array([[x1, x2]])\n",
    "        return clf.predict(x)[0]\n",
    "    return pred_fun\n",
    "\n",
    "def plot_labels(n_folds, n_classes, list_labels):\n",
    "    ind = np.arange(n_folds)\n",
    "    width = 0.15\n",
    "    \n",
    "    countings = []\n",
    "    for labels in list_labels:\n",
    "        labels = np.array(labels)\n",
    "        countings.append([np.count_nonzero(labels == x) for x in range(n_classes)])\n",
    "    \n",
    "    class_bars = []\n",
    "    for cls in range(n_classes):\n",
    "        class_bars.append([l[cls] for l in countings])\n",
    "    \n",
    "    fig, ax = pl.subplots()\n",
    "    i = 0\n",
    "    for class_bar in class_bars:\n",
    "        ax.bar(ind + width*i, class_bar, width, label='Clase '+str(i))\n",
    "        i += 1\n",
    "        \n",
    "    ax.set_xticks(ind + 2*width / 3)\n",
    "    ax.set_xticklabels(['Pliegue {}'.format(k) for k in range(n_folds)])\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Etiquetas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOPTUzPlkq4q"
   },
   "source": [
    "# Árboles de Decisión\n",
    "\n",
    "A continuación, presentamos otro algoritmo de clasificación no lineal basado en árboles de decisión. Los árboles de decisión son muy intuitivos, puesto que codifican una serie de elecciones \"**si esto**\" o \"**sino entonces**\", de forma muy similar a como una persona tomaría una decisión. La gran ventaja de esta técnica es que estas elecciones se pueden aprender de forma automática desde los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "\n",
    "Considere el siguiente árbol de decisión. Este árbol de decisión describe una serie de elecciones que buscan determinar si espero (**V**) o no (**F**) por una mesa en un restaurante.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/deeplearning/raw/master/notebooks/figures/decisiontree2.png\" width=\"70%\">\n",
    "\n",
    "Con base al anterior árbol de decisión, puedo tomar la decisión de si espero o no, usando unas reglas de clasificación sencillas, por ejemplo:\n",
    "\n",
    "* **Si** Clientes = \"Lleno\" **Y** EsperaEstimada = \"10-30\" **Y** Hambre = \"No\" **Entonces** Esperar=\"SI\"\n",
    "* **Si** Clientes = \"Algunos\" **Entonces** Esperar=\"SI\"\n",
    "* **Si** Clientes = \"Lleno\" **Y** EsperaEstimada = \">60\" **Entonces** Esperar=\"NO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beneficios\n",
    "\n",
    "* Los datos de entrada requieren muy poco preprocesamiento. Los árboles de decisión pueden trabajar con variables de diferente tipo (continuas y variables) y son invariantes al escalamiento de las características. \n",
    "* Los modelos son fáciles de interpretar, los árboles pueden ser visualizados.\n",
    "* El costo computacional del uso del árbol para predecir la categoría de un ejemplo es mínimo comparado con otras técnicas (Tiempo logaritmico).\n",
    "\n",
    "## Contras\n",
    "\n",
    "* Puede ser tan complejo, que se memoriza el conjunto de datos, por lo tanto no generaliza tan bien (**Sobreajuste**).\n",
    "* Son muy sensibles al imbalance de clases (**Sesgo**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se construye el árbol? - Algoritmo básico\n",
    "* El árbol es construido de arriba hacia abajo recursivamente de forma divide y vencerás.\n",
    "* Al comienzo, todos los ejemplos de entrenamiento están en la raíz.\n",
    "* Los atributos son categóricos (en caso de atributos continuos, se discretizan por adelantado)\n",
    "* Los ejemplos son repartidos recursivamente de acuerdo con el atributo seleccionado. \n",
    "* Los atributos de prueba son seleccionados en base a una heurística o medida estadística (ej. **ganancia de información**)\n",
    "* Se detiene hasta que solo hayan ejemplos de una clase en cada nodo hoja o se haya alcanza la profundidad máxima.\n",
    "\n",
    "## ¿Cómo seleccionar un atributo? ¿Cómo medir si una partición es buena?\n",
    "\n",
    "Una partición ideal es aquella que divide en un nodo las muestras de una misma clase. Observemos qué pasa si usamos la variable **Cliente** para particionar nuestro conjunto de datos.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/deeplearning/raw/master/notebooks/figures/split_clients.png\" width=\"50%\">\n",
    "\n",
    "\n",
    "Ahora, observemos qué pasa cuando particionamos el conjunto de datos usando la variable **Tipo de restaurante**.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/deeplearning/raw/master/notebooks/figures/split_type.png\" width=\"50%\">\n",
    "\n",
    "**¿Cuál variable es mejor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación en Scikit-Learn\n",
    "\n",
    "Vamos a construir un árbol que pueda clasificar entre tres tipos diferentes de flores de Iris: **Setosa, Versicolor y Virginica**. El conjunto de datos que utilizaremos es un conjunto de datos clásico utilizado para aprender los fundamentos del Machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos usando IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de los datos\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo utilizaremos las caracteristicas **0** y **2**, columnas corresponden a la **longitud del sépalo** y a la **longitud del pétalo** de las flores de iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.data[:,[0,2]]\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de Scikit-Learn se consigue con la clase `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de construir un árbol de decisión. Scikit-learn proporciona una clase `sklearn.tree.DecisionTreeClassifier`. Vamos a considerar algunos de los siguientes parámetros:\n",
    "\n",
    "Vamos a clasificar los tipos de flores utilizando `scikit-learn`.\n",
    "`DecisionTreeClassifier` soporta varios parámetros como lo son:\n",
    "* `max_depth`: Profundidad máxima del árbol. Cuanto más profundo sea el árbol, más complejas serán las reglas de decisión y más ajustado será el modelo.\n",
    "* `criterion`: Medida para determinar la calidad del particionamiento generado por un atributo. Soporta coeficiente GINI y entropía. Mide la calidad de una división. Los criterios admitidos son Gini y entropía para la ganancia de información.\n",
    "* `splitter`: estrategia para elegir una división en cada nodo. Admite las estrategias \"mejor\" y \"aleatoria\".\n",
    "* `min_samples_split`: Controla el número mínimo de muestras que debe haber en un nodo luego de una partición. Número mínimo de muestras necesarias para dividir un nodo interno.\n",
    "* `min_samples_leaf`: Controla el número mínimo de muestras que debe haber en un nodo hoja. El número mínimo de muestras necesarias para estar en un nodo hoja.\n",
    "* `random_state`: controla la aleatoriedad de la división.\n",
    "* `max_leaf_nodes`: Hacer crecer un árbol con max_leaf_nodes de la mejor manera posible. Los mejores nodos se definen como la reducción relativa de impurezas. Si es None, entonces un número ilimitado de nodos hoja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Los pasos que damos son:**\n",
    "\n",
    "1. Importar la clase DecisionTreeClassifier.\n",
    "2. Instanciar el modelo clasificador.\n",
    "3. Ajustar el modelo.\n",
    "4. Predecir.\n",
    "5. Evaluar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del clasificador\n",
    "classifier = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el 'clasificador' podría tener cualquier nombre, pero debería ser intuitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros del clasificador\n",
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar con el conjunto de dattos usando el método `.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la superficie de decisión del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize = (10, 6))    \n",
    "plot_decision_region(X, gen_pred_fun(classifier))\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo lo que tenemos que hacer ahora es mostrar la precisión de nuestro árbol de decisión. Para ello utilizaremos el método `.score` de `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de clasificación\n",
    "print(classifier.score(X,y))\n",
    "print(1-classifier.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este árbol de decición es bastante básico y no está afinado de ninguna manera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización\n",
    "\n",
    "Una buena  caracteristica de `scikit-learn` es que después del entrenamiento nos permite exportar el arbol de decicion como un archivo `.dot`, que podemos visualizar eon el programa `graphviz`.\n",
    "Este programa está disponible de forma gratuida en el [enlace](http://www.graphviz.org).\n",
    "\n",
    "Es posible utilizar la librería de Python. En Ubuntu, se recomienda instalarlo usando ambas líneas:\n",
    "* `conda install python-graphviz` o `conda install graphviz` o `pip install graphviz`\n",
    "* `sudo apt-get install graphviz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz\n",
    "#!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from pydotplus import graph_from_dot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a usar el **conjunto de datos IRIS completo** (Usando las cuatro características) y entrenamos un árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos todo el conjunto de datos\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del clasificador y realizamos el entrenamiento\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier = classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos `graphviz` para visualizar el árbol generado. `graphviz` soporta como parámetros los nombres de las clases y de las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(classifier, out_file=None,\n",
    "                           feature_names=iris.feature_names,\n",
    "                           class_names=iris.target_names,\n",
    "                           filled=True, rounded=True,\n",
    "                           special_characters=True)\n",
    "                        \n",
    "graph = graphviz.Source(dot_data,\"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol de decisión aprendido puede ser visualizado usando `graphviz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisamos el árbol de decición\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardarla en un archivo de imagen\n",
    "graph.render(\"arboldedecision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de las variables\n",
    "\n",
    "Una de las ventajas de usar árboles de decisión, es que nos permite determinar la importancia de cada características, con base al índice de impureza usado. Scikit-Learn nos permite acceder a la importancia de cada característica llamando `.feature_importances_`. Esta importancia cuantifica qué tanto aporta cada característica a mejorar el desempeño del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las características\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la característica más importante?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de la complejidad usando `DecisionTreeClassifier`\n",
    "\n",
    "Para evaluar la complejidad, vamos a estimar el número subóptimo de profundidad del árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, dividiremos los datos en dos conjuntos: uno de entrenamiento y otro de prueba.\n",
    "* El conjunto de entrenamiento se utilizará para construir el árbol de decisión, mientras que el conjunto de prueba se utilizará para comprobar la precisión del árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en testeo y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1234,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a explorar los siguientes valores de profundidad máxima:\n",
    "* $[1, 2, 3, \\dots, 20]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error=[]\n",
    "generalization_error=[]\n",
    "\n",
    "max_depth_values=list(range(1,21,1))\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    decision_tree=DecisionTreeClassifier(max_depth=depth)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    train_error.append(1-decision_tree.score(X_train, y_train))\n",
    "    generalization_error.append(1-decision_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la curva de error de entrenamiento contra error de generalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize = (10, 6))\n",
    "\n",
    "pl.plot(max_depth_values, train_error, label=\"Entrenamiento\")\n",
    "pl.plot(max_depth_values, generalization_error, label=\"Generalización\")\n",
    "pl.xticks(max_depth_values)\n",
    "pl.xlabel(\"Profundidad máxima\")\n",
    "pl.ylabel(\"Error\")\n",
    "pl.arrow(2.2, 0.07, 0, -0.01, head_width=0.2, head_length=0.01, fc='k', ec='k')\n",
    "pl.text(2, 0.08, 'Punto de balance')\n",
    "pl.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esamble de clasificadores\n",
    "\n",
    "Revisemos el siguiente problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere el siguiente conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue las funciones datos make_circles n_samples=1000, factor=.4 (separación entre circulos), noise=.15\n",
    "np.random.seed(0)\n",
    "X, y = make_circles(n_samples=1000, factor=.4, noise=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iYpb97tSkq4s"
   },
   "outputs": [],
   "source": [
    "# Dividamos el conjunto de datos 60/40\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1526501424629,
     "user": {
      "displayName": "Fabio A. Gonzalez",
      "photoUrl": "//lh5.googleusercontent.com/-jcmRx3yeVv4/AAAAAAAAAAI/AAAAAAAAAic/QZe3kSPTExE/s50-c-k-no/photo.jpg",
      "userId": "112315845334496218213"
     },
     "user_tz": 300
    },
    "id": "Ok6FpGCgkq4u",
    "outputId": "8a90fe95-ee77-491e-c151-5f9f66297b69"
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize = (10, 6))\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6Q127R_kq4z"
   },
   "source": [
    "Vamos a entrenar un modelo de árbol de decisión para resolver este problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bca9iqF-kq41"
   },
   "source": [
    "Entrenamos un árbol de decisión de profundidad máxima $5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1526501432356,
     "user": {
      "displayName": "Fabio A. Gonzalez",
      "photoUrl": "//lh5.googleusercontent.com/-jcmRx3yeVv4/AAAAAAAAAAI/AAAAAAAAAic/QZe3kSPTExE/s50-c-k-no/photo.jpg",
      "userId": "112315845334496218213"
     },
     "user_tz": 300
    },
    "id": "E_Ivdsywkq41",
    "outputId": "74a17014-d7c5-4d08-acb2-af35a66ef15d"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1644,
     "status": "ok",
     "timestamp": 1526501439615,
     "user": {
      "displayName": "Fabio A. Gonzalez",
      "photoUrl": "//lh5.googleusercontent.com/-jcmRx3yeVv4/AAAAAAAAAAI/AAAAAAAAAic/QZe3kSPTExE/s50-c-k-no/photo.jpg",
      "userId": "112315845334496218213"
     },
     "user_tz": 300
    },
    "id": "6Gdda7Nykq44",
    "outputId": "d55847c1-39a3-4d5b-9e97-23c52a90aaa0"
   },
   "outputs": [],
   "source": [
    "print('Error en entrenamiento: {}'.format(1-dt.score(X_train, y_train)))\n",
    "print('Error en prueba: {}'.format(1-dt.score(X_test, y_test)))\n",
    "\n",
    "pl.figure(figsize = (10, 6))\n",
    "plot_decision_region(X_test, gen_pred_fun(dt))\n",
    "plot_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4HSrPGTkq47"
   },
   "source": [
    "El modelo presenta un error de generalización del $6\\%$, además sus predicciones no se ajustan a la naturaleza de los datos\n",
    "\n",
    "Problemas:\n",
    "* En algunos casos, las fronteras de decisión generadas por el árbol de decisión (paralelas a los ejes) no son lo suficientemente flexibles para capturar la no linealidad del conjunto de datos.\n",
    "* Por otro lado, los árboles de clasificación pueden crear reglas decisión muy espcíficas que se ajustan demasiado a los datos de entrenamiento.\n",
    "* Tambien son sensibles a pequeñas variaciones de los datos que pueden resultar en árboles totalmente distintos. Esto es un problema cuando se hace validación cruzada de k-pliegues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo solucionar este problema?**\n",
    "\n",
    "Vamos a utilizar una estrategia conocida como *clasificación por comité* o *ensamble de clasificadores* (ensemble). Un ensamble de clasificadores combina diferentes algoritmos de aprendizaje para obtener un mejor desempeño predictivo.\n",
    "\n",
    "### Bagging\n",
    "\n",
    "Bagging es una técnica de ensamblaje de modelos que se utiliza en Machine Learning y consiste en:\n",
    "- Entrenar múltiples modelos de aprendizaje automático en diferentes subconjuntos de datos de entrenamiento seleccionados al azar.\n",
    "- Combinar las predicciones de todos los modelos en una única predicción mediante una votación ponderada o promedio de las predicciones individuales.\n",
    "- Esta técnica ayuda a reducir el sobreajuste y mejorar la precisión del modelo.\n",
    "- Bagging se puede utilizar con cualquier modelo de aprendizaje automático, aunque se utiliza con mayor frecuencia con árboles de decisión.\n",
    "- Es una técnica útil para mejorar la estabilidad del modelo y puede ser especialmente útil en problemas de clasificación donde las clases están desequilibradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, presentamos una forma de como construír un ensamble de árboles de clasificación. Se entrenan diferentes árboles en diferentes subconjuntos de los datos de entrenamiento. Posteriormente cuando se va hacer una predicción para un nuevo dato, se obtienen las predicciones de todos los árboles y se regresa aquella clase de mayor frecuencia predicha (votación).\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/deeplearning/raw/master/notebooks/figures/ensemble2.svg\" width=\"50%\">\n",
    "\n",
    "A la técnica de la figura se le conoce como *bagging*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo siguiente vamos a utilizar la función `BaggingClassifier`, la cual entrena un modelo usando esta estrategia.\n",
    "\n",
    "Los parámetros recibidos por la función son los siguientes:\n",
    "* `base_estimator`: Consiste en el estimador base que se va a entrenar sobre los diferentes subconjunto del conjunto de datos de entrenamiento.\n",
    "* `n_estimators`: Es el número de estimadores base que se van a usar para la estrategia de *bagging*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11362,
     "status": "ok",
     "timestamp": 1526502024320,
     "user": {
      "displayName": "Fabio A. Gonzalez",
      "photoUrl": "//lh5.googleusercontent.com/-jcmRx3yeVv4/AAAAAAAAAAI/AAAAAAAAAic/QZe3kSPTExE/s50-c-k-no/photo.jpg",
      "userId": "112315845334496218213"
     },
     "user_tz": 300
    },
    "id": "kiWpI7fwk_Rm",
    "outputId": "f12e2a0c-8afa-4cb2-e9e6-7ee034bc56e7"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bc = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), n_estimators=20)\n",
    "bc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Error en entrenamiento: {}'.format(1-bc.score(X_train, y_train)))\n",
    "print('Error en prueba: {}'.format(1-bc.score(X_test, y_test)))\n",
    "\n",
    "pl.figure(figsize = (10, 6))\n",
    "plot_decision_region(X_test, gen_pred_fun(bc))\n",
    "plot_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3bCzfHnkq48"
   },
   "source": [
    "# Random Forests\n",
    "\n",
    "Es un método de ensamble que combina múltiples árboles de decisión.\n",
    "* Cada árbol se entrena con un subconjunto aleatorio de características y datos.\n",
    "* La predicción final se realiza promediando las predicciones de todos los árboles individuales.\n",
    "* Random Forest es efectivo para prevenir el sobreajuste y es útil para clasificación y regresión.\n",
    "\n",
    "Existen varias alternativas para combinar y promediar árboles de decisión, una de las más usadas es **Random Forest**.\n",
    "Vamos a construir un simple bosque aleatorio en Python.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/deeplearning/blob/master/notebooks/figures/randomforest.png?raw=1\" width=\"60%\">\n",
    "\n",
    "Nuestro *forest* será muy similar al *árbol de decisión* que hicimos anteriormente.\n",
    "Esto significa que vamos a construir un *random forest* que pueda clasificar entre tres tipos diferentes de flores \"Iris\": *Setosa, Versicolor y Virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-Learn` provee una implementación a través de `sklearn.ensemble.RandomForestClassifier`. Más adelante se discuten los parámetros más importantes de esta implementación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jlieocf1kq5I"
   },
   "source": [
    "### Algoritmo básico Random Forest\n",
    "\n",
    "A diferencia del árbol común de decisión, los árboles de Random Forest se entrenan de una forma diferente. A continuación, presentamos el algoritmo básico de entrenamiento:\n",
    "\n",
    "1. Para cada árbol se realiza el siguiente procedimiento:\n",
    "    * Se escoge una muestra con reemplazo de tamaño $n$ del conjunto de entrenamiento.\n",
    "    * Se seleccionan $m$ variables al azar de las variables disponibles\n",
    "    * Se entrena un árbol sobre la muestra usando las $m$ variables repitiendo los siguientes pasos:\n",
    "        * Se escoge la variable (y umbral) que genera la mejor partición\n",
    "        * Se divide los datos en dos subconjuntos de acuerdo a la variable y el umbral\n",
    "        * Si no se satisface un criterio de parada se aplica este procedimiento recursivamente sobre los subconjutos\n",
    "2. Una vez cada árbol ha sido entrenado, se genera el ensamble de árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación en Scikit-Learn\n",
    "\n",
    "La implementación en Scikit-Learn nos permite controlar los siguientes parámetros:\n",
    "* `n_estimators`: Número de árboles a entrenar\n",
    "* `max_features`: Número de variables $m$ al azar que se tienen en cuenta para la construcción de cada árbol.\n",
    "\n",
    "Un número grande de árboles resulta en un buen desempeño a costas del costo computacional. Ambos parámetros deben ser explorados usando validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3EzAX-4dkq48"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos una semilla aleatoria `np.random.seed` en cero.\n",
    "La semilla aleatoria es un punto de partida para generar números aleatorios y replicarlos en otras ocasiones los mismos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos scikit-learn para crear un clasificador *random forest* que llamaremos `rf`, pero podría llamarse de cualquier manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "euWnFssWkq4-",
    "outputId": "15ac2d49-284b-4070-8229-09e7ddf3d030"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20, max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenaremos el clasificador utilizando las características que hemos definido antes sobre los datos y las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibujamos la superficie de decisión junto a los datos de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pxmDpMY0kq5A",
    "outputId": "579c60ae-c241-425e-afea-c93287938dc8"
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize = (10, 6))\n",
    "plot_decision_region(X_test, gen_pred_fun(rf))\n",
    "plot_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cl6VI_bmkq5D",
    "outputId": "d34916f9-99be-4e06-a3b3-ad874e47fde2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Error en entrenamiento: {}'.format(1-rf.score(X_train, y_train)))\n",
    "print('Error en prueba: {}'.format(1-rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUb08O0Ekq5G"
   },
   "source": [
    "Mientras baja el error de generalización, observamos tambien que se adapta mejor a la naturaleza de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrdT1db0kq5H"
   },
   "source": [
    "### Intuición detrás de RandomForests\n",
    "\n",
    "Random Forest es una técnica de **ensamble** que combina diferentes árboles de decisión. Estos árboles se entrenan en diferentes muestras del conjunto de datos, estos árboles pueden sobreajustarse, sin embargo la combinación de sus predicciones resulta en un clasificador con menor sobreajuste.\n",
    "\n",
    "Para entender la idea de como se construye este algoritmo, suponga que entrenamos los siguientes árboles para determinar si una persona está enferma o sana:\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/deeplearning/raw/master/notebooks/figures/RF.png\" width=\"70%\">\n",
    "\n",
    "**¿Qué sucede si todos los árboles de clasificación son iguales?**\n",
    "\n",
    "**¿Cómo logro que cada árbol de clasificación sea diferente?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros del esamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el dataset\n",
    "\n",
    "Utilizaremos el conjunto de datos de clasificación de vino.\n",
    "* El conjunto de datos  que contiene los resultados de un análisis químico de vinos cultivados en un área específica de Italia.\n",
    "* Tres tipos de vino están representados en las 178 muestras, con los resultados de 13 análisis químicos registrados para cada muestra.\n",
    "\n",
    "A continuación, usaremos el conjunto de datos `wine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir data\n",
    "#!wget -O data/wine.data.txt https://github.com/marcoteran/deeplearning/raw/master/notebooks/data/wine.data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wine.data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gwRwZAUwkq5K",
    "outputId": "d2c0e8c0-45fb-48d8-b25f-fc4e15f0215d"
   },
   "outputs": [],
   "source": [
    "# Mostremos los primeros 5 datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprobar la frecuencia de los valores únicos en la columna de calidad `quality`\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2lR20yskq5N"
   },
   "source": [
    "En primer lugar, dividamos el conjunto de datos en variables independientes y dependientes. La característica `Class` será la variable objetivo. Generamos la matriz de características y el arreglo de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "982A1h00kq5O"
   },
   "outputs": [],
   "source": [
    "X = df.drop(labels='Class', axis=1).values\n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Cmo63Idkq5b"
   },
   "source": [
    "### Creación de los conjuntos de entrenamiento y prueba\n",
    "Divida el conjunto de datos en un conjunto de entrenamiento y otro de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-sOvzyJUkq5b"
   },
   "outputs": [],
   "source": [
    "# Dividimos los datos estratificados al 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos scikit-learn para crear un clasificador *random forest* que llamaremos `rf`, pero podría llamarse de cualquier manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20, max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenaremos el clasificador utilizando las características que hemos definido antes sobre los datos y las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Error en entrenamiento: {}'.format(1-rf.score(X_train, y_train)))\n",
    "print('Error en prueba: {}'.format(1-rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hacer las prediccciones\n",
    "y_pred = rf.predict(X_test) # Test the prediction accurracy of the model\n",
    "result = pd.DataFrame({'Actual' : y_test, 'Predicted' : y_pred})\n",
    "pd.concat([result.head(), result.tail()]) # display df of acutal and predicted(head and tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Testing Set Evaluation Accuracy: ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred) # generate confusion matrix\n",
    "sns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap='RdYlBu', linewidth=.5, fmt='g', cbar=False)\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informe de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['1', '2', '3']\n",
    "\n",
    "pd.DataFrame(classification_report(y_test, y_pred,target_names=target_names, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos la oportunidad de mejorar el rendimiento del modelo mediante el ajuste de hiperparámetros.\n",
    "* En el ajuste de hiperparámetros, especificamos los posibles parámetros óptimos para optimizar el rendimiento del modelo\n",
    "Dado que es imposible conocer manualmente los parámetros óptimos para nuestro modelo, vamos a automatizarlo utilizando la clase `sklearn.model_selection.GridSearchCV`.\n",
    "\n",
    "Veamos cómo podemos realizar esto en un Clasificador de Árbol de Decisión.\n",
    "Utilizando la clase `GridSearchCV` de sklearn y le pasaremos valores predefinidos para los hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePgLxFrhkq5Q"
   },
   "source": [
    "Definimos la malla de parámetros:\n",
    "* `max_features_params = [np.round(10**-1 * i, decimals=1) for i in range(1, 11, 1)]`\n",
    "* `param_grid = {'n_estimators': [2**i for i in range(2, 12, 1)], 'max_features': max_features_params}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MhIYf5kQkq5Q"
   },
   "outputs": [],
   "source": [
    "max_features_params = [np.round(10**-1 * i, decimals=1) for i in range(1, 11, 1)]\n",
    "param_grid = {'n_estimators': [2**i for i in range(2, 12, 1)], 'max_features': max_features_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CH2ZoZi0kq5S",
    "outputId": "25fc0a1b-8b71-4757-cbf8-7388a1d3b530",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Número de árboles: {}'.format(param_grid['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "M6e2PJ4hkq5Y",
    "outputId": "235a656e-8ea5-44bd-d7c9-fce66338ea59"
   },
   "outputs": [],
   "source": [
    "print('Porcentaje de características a usar: {}'.format(param_grid['max_features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "poQ0c4Yzkq5d"
   },
   "source": [
    "Corremos el modelo `GridSearchCV` usando la retícula de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BZDDmXydkq5e",
    "outputId": "eeb67fbb-9492-4d0b-a2bc-5a1bd73ec10e"
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, verbose=1, n_jobs=-1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"GridSearchCV tomó {} segundos usando {} configuraciones\".format(time() - start,\n",
    "                                                                         len(clf.cv_results_['params'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSUXa4rykq5f"
   },
   "source": [
    "Usando `cv_results_` extraemos el desempeño promedio sobre cada configuración de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6IR_1FmOkq5g"
   },
   "outputs": [],
   "source": [
    "scores = clf.cv_results_['mean_test_score'].reshape(len(param_grid['max_features']),\n",
    "                                                    len(param_grid['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wJru3J98kq5i",
    "outputId": "a75f74e0-0a12-4a18-af55-09f7b917f817"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meAC7Fihkq5l"
   },
   "source": [
    "Visualizamos la mejor combinación de parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4v-S8T1skq5l",
    "outputId": "f9d90e36-0f7e-4d5f-b0d4-cf3138e56802"
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10, 6))\n",
    "pl.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "pl.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.89, midpoint=0.97, vmax=1.))\n",
    "pl.xlabel('n_estimators')\n",
    "pl.ylabel('max_features')\n",
    "pl.colorbar()\n",
    "pl.xticks(np.arange(len(param_grid['n_estimators'])), param_grid['n_estimators'], rotation=45)\n",
    "pl.yticks(np.arange(len(param_grid['max_features'])), param_grid['max_features'])\n",
    "pl.title('Accuracy en validación')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ycbbknODkq5o"
   },
   "source": [
    "La mejor combinación de parámetros está dada por:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "S6dIfCGxkq5o",
    "outputId": "566df69c-72c8-4b3f-86f9-c96848206e3c"
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WSS-sNypkq5s",
    "outputId": "b719fdb1-7e45-411e-fa78-20a977eaa6b2"
   },
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynbzxQ0Akq5u"
   },
   "source": [
    "Finalmente, reportamos en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hyDm4Ns4kq5v",
    "outputId": "dd7cfee3-8331-453b-e053-9c1e4281edec"
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6DFb_PMkq51"
   },
   "source": [
    "## Importancia de características\n",
    "\n",
    "Una ventaja muy significativa de usar Random Forests consiste en la posibilidad de obtener la importancia de las características del conjunto de datos. Esta importancia nos indica qué tanto una característica contribuye al desempeño en los nodos de los diferentes árboles.\n",
    "\n",
    "A continuación, seguimos usando el conjunto de datos `wine` y obtenemos la importancia de las características del mejor modelo usando validación cruzada. Entrenemos de nuevo el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m-rVoGBNkq52"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=64, max_features=.1)\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76TDTF32kq54"
   },
   "source": [
    "Extraemos la importancia de las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i61Udnk7kq54",
    "outputId": "8227e115-3427-4bba-a9e5-638d4cc4bee7"
   },
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gTA1CIekq57"
   },
   "source": [
    "A continuación ordenamos las características por su importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_0JO-w-hkq57",
    "outputId": "5f84d454-b447-4823-fc7f-79029da46d25"
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Importancia de características:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Característica %s (%f)\" % (df.columns[int(1+indices[f])], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hy9BAVGpkq59",
    "outputId": "ad232bb2-6705-4730-f1a4-5ea5c0b2f4b0"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Importancia de las características\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "xticks_labels = [df.columns[1+i] for i in indices]\n",
    "plt.xticks(range(X.shape[1]), xticks_labels, rotation=45)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Pu085Cakq5_"
   },
   "source": [
    "# Optimización aleatoria de parámetros\n",
    "\n",
    "A pesar de las ventajas que ofrece `GridSearchCV` sobre la exploración sistemática de los hiperparámetros de un modelo, puede gastar un tiempo considerable en esta exploración. Scikit-Learn permite hacer también una exploración aleatoria de los parámetros, la cual se ha demostrado empiricamente que es más eficiente que optimizar los parámetros usando una malla con `GridSearchCV` ([Referencia](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)). `RandomizedSearchCV` implementa una búsqueda aleatoria sobre los parámetros. El rango de exploración de los parámetros se puede especificar de la siguiente manera:\n",
    "\n",
    "* Usando una lista:\n",
    "    * `\"criterion\": [\"gini\", \"entropy\"]`\n",
    "* Usando una distribución discreta uniforme:\n",
    "    * `\"n_estimators\": randint(4, 2048)`\n",
    "    * `randint` proviene de `scipy.stats`. Este genera una distribución discreta entre 4 y 2048. \n",
    "* Usando una distribución uniforme:\n",
    "    * `\"max_features\": uniform()`\n",
    "    * `uniform` proviene de `scipy.stats`. Este genera una distribución uniforme entre 0 y 1.\n",
    "    \n",
    "`RandomizedSearchCV` puede recibir tanto listas de elementos como distribuciones de probabilidad, las cuales deben ser especificadas usando `scipy.stats`. A continuación, creamos nuestro estimador y definimos la distribución de parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "h5214wOZkq6A"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform \n",
    "from scipy.stats import randint\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\"n_estimators\": randint(4, 800),\n",
    "              \"max_features\": uniform()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=randint(4, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bmwtozgkq6B"
   },
   "source": [
    "`n_iter_search` nos define el número de configuraciones que vamos a extraer de la distribución de parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cA6cUpd_kq6D"
   },
   "outputs": [],
   "source": [
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, \n",
    "                                   n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hIFOFdzWkq6E"
   },
   "source": [
    "`RandomizedSearchCV` también soporta la ejecución en paralelo usando `n_jobs=-1`. También podemos especificar el número de pliegues a usar usando `cv=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vneDqAwxkq6F",
    "outputId": "1cdeca3a-67ed-409b-9052-93ba03b4bdf6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV tomó {} segundos usando {} configuraciones\".format(time() - start,\n",
    "                                                                               n_iter_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar esta información, `GridSearchCV` nos ofrece una serie de métodos que nos permite consultar:\n",
    "* La lista de resultados por elemento en la malla de parámetros (`cv_results_`)\n",
    "* La configuración con el mejor desempeño (`best_params_`)\n",
    "* El accuracy promediado sobre todos los pliegues de la mejor configuración (`best_score_`)\n",
    "\n",
    "Para encontrar las mejores configuraciones, ordenamos la tabla de resultados de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DC4Dji2wkq6K"
   },
   "source": [
    "Extraemos los resultados con mejor desempeño promedio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "51pbXE-Kkq6L",
    "outputId": "c7d72287-a1f1-4164-b078-2a653440db1a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "cv_results = cv_results[['param_n_estimators','param_max_features','mean_test_score']]\n",
    "cv_results.sort_values(by='mean_test_score',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZI8HibNgkq6N"
   },
   "source": [
    "Verificamos la mejor configuración y su puntaje sobre todas las particiones de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "k14BgiRfkq6O",
    "outputId": "9a6217dc-43c4-4ae8-9c38-8f9dbd41c54f"
   },
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "01ALTrDlkq6Q",
    "outputId": "2d7ec435-d9f0-4389-95f3-623439b251c8"
   },
   "outputs": [],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0pRHnGtkq6T"
   },
   "source": [
    "Reportamos el error de generalización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "048_ucYGkq6U",
    "outputId": "e64a8f5f-fe60-435a-f51f-afbbe93e3e9c"
   },
   "outputs": [],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "¡Todo bien! ¡Es todo por hoy! 😀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlKBrJTDkq6W"
   },
   "source": [
    "# Taller\n",
    "\n",
    "Este taller se va a enfocar en trabajar con el conjunto de datos del censo de 1993 de USA. El conjunto de datos reune una serie de características socioeconómicas tanto categóricas como numéricas. El objetivo es construir un clasificador que determine si la persona tiene una ganancia alta al año (más de 50K USD) o baja (menos de 50K USD al año). A continuación encuentra una descripción de las características:\n",
    "\n",
    "Etiqueta:\n",
    "* income: >50K, <=50K.\n",
    "Características:\n",
    "* age: Variable continua.\n",
    "* workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "* fnlwgt: Variable continua.\n",
    "* education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "* education-num: Variable continua.\n",
    "* marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "* occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "* relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "* race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "* sex: Female, Male.\n",
    "* capital-gain: Variable continua.\n",
    "* capital-loss: Variable continua.\n",
    "* hours-per-week: Variable continua.\n",
    "* native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "\n",
    "## Carga de datos\n",
    "* Cargue el conjunto de datos `adult.csv` en Pandas.\n",
    "* Este conjunto de datos tiene dos problemas:\n",
    "    * Contiene datos faltantes, representados por un interrogante: \"?\"\n",
    "    * Es un conjunto de datos imbalanceado.\n",
    "* Para verificar ambos hechos:\n",
    "    * Verifique qué porcentaje de valores indefinidos hay para las variables `workclass`, `occupation` y `native-country`.\n",
    "    * Luego, puede limpiar aquellas filas que contengan datos indefinidos. Puede usar el siguiente código:\n",
    "    ```python\n",
    "    df = df[df[\"workclass\"] != \"?\"]\n",
    "    df = df[df[\"occupation\"] != \"?\"]\n",
    "    df = df[df[\"native-country\"] != \"?\"]\n",
    "    ```\n",
    "    * Verifique el DataFrame tenga un tamaño de 45222 elementos por 15 características.\n",
    "    * Verifique la distribución de etiquetas en la columna `income`, ¿Cuál clase tiene mayor número de ejemplos?\n",
    "* Use `.describe()` para obtener un análisis de las variables numéricas del conjunto de datos.\n",
    "* Realice un conteo de cada elemento de las variables categóricas:\n",
    "    * ['workclass', 'race', 'education','marital-status', 'occupation','relationship', 'gender', 'native-country', 'income'] \n",
    "* Simplifique la categoría 'marital-status' de la siguiente forma:\n",
    "    * 'Divorced' -> 'not married'\n",
    "    * 'Married-AF-spouse' -> 'married'\n",
    "    * 'Married-civ-spouse' -> 'married'\n",
    "    * 'Married-spouse-absent' -> 'married'\n",
    "    * 'Never-married' -> 'not married'\n",
    "    * 'Separated' -> 'not married'\n",
    "    * 'Widowed' -> 'not married'\n",
    "* Convierta las variables categóricas a numéricas. El enfoque aquí presentado no es el mejor, pero será una primera aproximación. Puede usar el siguiente código:\n",
    "```python\n",
    "for col in category_col:\n",
    "    b, c = np.unique(df[col], return_inverse=True) \n",
    "    df[col] = c\n",
    "```\n",
    "A pesar de que no queremos inducir un orden en las categorías analizadas, es un buen inicio para probar Validación cruzada.\n",
    "* Cree una matriz `X` de características usando:\n",
    "    * ['age','workclass','education','educational-num','marital-status', 'occupation','relationship','race','gender','capital-gain','capital-loss','hours-per-week', 'native-country']\n",
    "* Cree el arreglo `y` usando la columna `income`:\n",
    "* Genere una partición de entrenamiento y prueba $80\\%-20\\%$ estratificada. NO MODIFIQUE EL CONJUNTO DE DATOS ORIGINAL.\n",
    "* Verifique que en efecto la partición haya sido estratificada.\n",
    "\n",
    "## RandomizedSearchCV\n",
    "\n",
    "* Genere la siguiente distribución de parámetros:\n",
    "    * `n_estimators` seguirá una distribución uniforme discreta entre 4 y 512\n",
    "    * `max_features` seguirá una distribución uniforme entre 0 y 1\n",
    "    * `max_depth` será un valor entre 5 o None\n",
    "    * `bootstrap` será un valor entre True o False\n",
    "* ¿Qué hace `max_depth` y `bootstrap`? ¿Qué significa que `max_depth` sea None? Consulte la [documentación](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* Entrene un RandomForestClassifier sobre las siguientes condiciones:\n",
    "    * 20 iteraciones de la distribución de parámetros\n",
    "    * Pliegues de la validación cruzada= 5\n",
    "    * Use `n_jobs=-1` para hacer la búsqueda de parámetros de forma paralela\n",
    "* ¿Cuales son las mejores configuraciones?\n",
    "* ¿Qué desempeño tienen las mejores configuraciones?\n",
    "* Reporte accuracy, precision, recall y matriz de confusión en el conjunto de prueba"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZrdT1db0kq5H"
   ],
   "default_view": {},
   "name": "s5_random_forests.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
