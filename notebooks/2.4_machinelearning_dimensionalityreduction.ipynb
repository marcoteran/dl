{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/2.4_machinelearning_dimensionalityreduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/2.4_machinelearning_dimensionalityreduction.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de código\n",
    "# Sesión 06: Reducción de la dimensionalidad y aprendizaje de la representación\n",
    "## Deep Learning y series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran **E-mail:** marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar librerías importantes\n",
    "\n",
    "Definimos primero unas librerías y funciones que vamos a usar a durante la sesión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf data/\n",
    "#!rm -rf data.z*\n",
    "#!mkdir -p data/\n",
    "#!wget -O data.zip https://github.com/marcoteran/deeplearning/raw/master/notebooks/data.zip\n",
    "#!unzip data.zip\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Componentes Principales (PCA)\n",
    "\n",
    "El **Análisis de Componentes Principales (PCA)** es una técnica de reducción de dimensionalidad lineal que se utiliza para extraer información de un *espacio de alta dimensionalidad* al proyectarlo en un subespacio de menor dimensión.\n",
    "* PCA intenta preservar las partes esenciales que tienen mayor variación en los datos y eliminar las partes no esenciales con menos variación.\n",
    "* Las dimensiones son características que representan los datos\n",
    "    - Ejemplo: en una imagen de 28 X 28 píxeles hay 784 elementos de imagen que son las dimensiones o características que juntas representan esa imagen.\n",
    "* PCA es una técnica de reducción de dimensionalidad no supervisada, lo que significa que se pueden agrupar puntos de datos similares basados en la correlación entre características sin ninguna supervisión o etiquetas.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/deeplearning/raw/master/notebooks/figures/examplepca.png\" width=\"30%\">\n",
    "\n",
    "PCA es un procedimiento estadístico que utiliza una transformación ortogonal para convertir un conjunto de observaciones de variables posiblemente correlacionadas en un conjunto de valores de variables linealmente no correlacionadas llamadas componentes principales.\n",
    "\n",
    "**Nota:** Características, Dimensiones y Variables se refieren a lo mismo. Se utilizan indistintamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicaciones del PCA\n",
    "* **La Visualización de Datos:** El problema en el mundo actual es la gran cantidad de datos y las variables/características que definen esos datos. Para resolver un problema en el que los datos son clave, se necesita una exploración exhaustiva de los datos como encontrar cómo están correlacionadas las variables o entender la distribución de algunas variables. La visualización puede ser un desafío y casi imposible debido a la gran cantidad de variables o dimensiones en las que se distribuyen los datos. PCA puede proyectar los datos en una dimensión más baja, permitiéndote visualizar los datos en un espacio 2D o 3D con el ojo humano.\n",
    "* **Aceleración de un Algoritmo de Machine Learning (ML):** Dado que la idea principal de PCA es la reducción de la dimensionalidad, se puede aprovechar para acelerar el tiempo de entrenamiento y prueba de un algoritmo de ML si los datos tienen muchas características y el aprendizaje del algoritmo de ML es demasiado lento. A nivel abstracto, se toma un conjunto de datos con muchas características y se simplifica seleccionando algunos componentes principales de las características originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta [A Tutorial on Principal Component Analysis](https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf) para una decripción intuitiva y detallada de PCA y SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuición detrás del PCA\n",
    "\n",
    "Tenemos los siguientes datos 2D y nos gustaría encontrar una proyección en 1D que preserve la máxima cantidad de variabilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X = np.dot(np.random.random(size=(2, 2)), np.random.normal(size=(2, 200))).T+10\n",
    "\n",
    "# Centra los datos en 0,0\n",
    "X=X-np.mean(X, axis=0)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La proyección de un vector en otro es la proyección ortogonal de un vector sobre otro en un espacio vectorial, que mide la magnitud de la componente de un vector en la dirección de otro vector.\n",
    "\n",
    "Recuerda que la proyección de un vector $\\vec{x}$ en otro vector $\\vec{v}$ (consulta [aquí](https://matthew-brett.github.io/teaching/vector_projection.html)) viene dada por:\n",
    "\n",
    "$$c = \\frac{\\vec{v}\\times \\vec{x}}{||\\vec{v}||^2}$$\n",
    "\n",
    "\n",
    "$$proj_\\vec{v} \\vec{x} = \\vec{v} c$$\n",
    "\n",
    "\n",
    "donde $c$ es el tamaño de la proyección de  $\\vec{x}$ sobre $\\vec{v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspeccionamos algunas proyecciones\n",
    "\n",
    "El siguiente código de proyección de vectores representa la proyección de un conjunto de datos (X) en una dirección aleatoria, usando la técnica de proyección vectorial.\n",
    "* Se generan tres gráficos que muestran la proyección de los datos en una dirección aleatoria.\n",
    "* Para cada dirección, se calcula el factor de escala de proyección (c) para ajustar la magnitud de la proyección.\n",
    "* Los puntos proyectados se muestran en rojo, mientras que los datos originales se muestran en azul.\n",
    "* La línea negra representa el vector de proyección y la desviación estándar de los factores de escala se muestra en el título."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "\n",
    "unit_vector = lambda angle: np.array([np.cos(angle), np.sin(angle)])\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    angle = np.random.random()*np.pi*2\n",
    "    v = unit_vector(angle)\n",
    "\n",
    "    c = X.dot(v.reshape(-1,1))/(np.linalg.norm(v)**2)\n",
    "    Xp = np.repeat(v.reshape(-1,2),len(X),axis=0)*c\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], color=\"blue\", alpha=.5, label=\"original data\")\n",
    "    plt.scatter(Xp[:,0], Xp[:,1], color=\"red\", alpha=.5, label=\"projected data\")\n",
    "    plt.axvline(0, color=\"gray\")\n",
    "    plt.axhline(0, color=\"gray\")\n",
    "    plt.plot([0,v[0]], [0,v[1]], color=\"black\", lw=3, label=\"projection vector\")\n",
    "    plt.axis('equal')\n",
    "    plt.ylim(-2,2)\n",
    "    plt.title(\"$\\\\alpha$=%.2f rads, proj std=%.3f\"%(angle, np.std(c)))\n",
    "    if i==2:\n",
    "        plt.legend(loc=\"center left\", bbox_to_anchor=(1.01,.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontremos las proyecciones con mayor y menor std por fuerza bruta\n",
    "\n",
    "Se busca obtener las proyecciones de un conjunto de datos en diferentes ángulos para encontrar la dirección con la máxima y mínima variabilidad en los datos. Se muestra gráficamente cómo varía la desviación estándar de las proyecciones a medida que se rota el vector de proyección.\n",
    "* El código calcula la desviación estándar de las proyecciones de un conjunto de datos en diferentes ángulos.\n",
    "* Utiliza esta información para encontrar la dirección con la máxima y mínima variabilidad en los datos.\n",
    "* Muestra gráficamente cómo varía la desviación estándar de las proyecciones a medida que se rota el vector de proyección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxmin_projections(X):\n",
    "    stds = []\n",
    "    angles = np.linspace(0,np.pi*2, 100)\n",
    "    for a in angles:\n",
    "        v = np.array([np.cos(a), np.sin(a)])\n",
    "        c = X.dot(v.reshape(-1,1))/(np.linalg.norm(v)**2)\n",
    "        stds.append(np.std(c))\n",
    "    v2 = unit_vector(angles[np.argmin(stds)])\n",
    "    v1 = unit_vector(angles[np.argmax(stds)])\n",
    "    \n",
    "    return angles, stds, v1, v2\n",
    "angles, stds, v1, v2 = get_maxmin_projections(X)\n",
    "\n",
    "plt.plot(angles, stds)\n",
    "plt.xlabel(\"projection $\\\\alpha$ (in rads)\")\n",
    "plt.ylabel(\"projection std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], color=\"blue\", alpha=.5, label=\"original data\")\n",
    "plt.axvline(0, color=\"gray\")\n",
    "plt.axhline(0, color=\"gray\")\n",
    "plt.plot([0,v1[0]], [0,v1[1]], color=\"black\", lw=5, label=\"max std projection vector\")\n",
    "plt.plot([0,v2[0]], [0,v2[1]], color=\"black\", ls=\"--\", lw=2, label=\"min std projection vector\")\n",
    "plt.axis('equal')\n",
    "plt.ylim(-2,2)\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1.01,.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de PCA en Scikit-Learn\n",
    "\n",
    "PCA en Scikit-Learn se utiliza principalmente para reducir la dimensionalidad de los datos y permitir una visualización más fácil de los datos, pero también puede ayudar a reducir el ruido y mejorar la precisión del modelo de Machine Learning.\n",
    "* PCA en Scikit-Learn se puede utilizar en una variedad de aplicaciones, como la reducción de dimensionalidad de datos, la visualización de datos y la eliminación de características irrelevantes o redundantes.\n",
    "* Scikit-Learn ofrece una implementación eficiente de PCA, que se puede ajustar a diferentes tipos de datos y configuraciones de parámetros.\n",
    "* La función de PCA en Scikit-Learn también proporciona una variedad de opciones para personalizar la salida y la interpretación de los resultados de PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Estos son los componentes principales**\n",
    "* **Observa que su dimensionalidad es la misma que los datos originales**\n",
    "\n",
    "Esto es lo que PCA nos da:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el paquete PCA de scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Creamos una instancia de PCA con dos componentes\n",
    "pca = PCA(n_components=2)\n",
    "# Ajustamos la instancia de PCA con los datos X\n",
    "pca.fit(X)\n",
    "\n",
    "# Imprimimos los componentes calculados por scikit-learn\n",
    "print(\"sklearn PCA components\")\n",
    "print(pca.components_)\n",
    "\n",
    "# Imprimimos los componentes calculados por fuerza bruta\n",
    "print(\"brute force components\")\n",
    "print(v1)\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero de modo mucho más eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit get_maxmin_projections(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos usar el componente mayor para reducir la dimensionalidad de nuestros datos de 2D a 1D\n",
    "\n",
    "A continuación se muestra cómo podemos reducir la dimensionalidad de nuestros datos de 2D a 1D utilizando el componente mayor.\n",
    "* La ecuación que se muestra a continuación representa la transformación que se realiza en los datos originales para obtener los datos transformados:\n",
    "\n",
    "$$\\mathbf{X_t} = \\mathbf{X} \\times \\mathbf{V}$$\n",
    "\n",
    "Donde $\\mathbf{X}$ representa nuestros datos originales, $\\mathbf{V}$ es el vector de componentes seleccionados y $\\mathbf{X_t}$ son los datos transformados.\n",
    "\n",
    "Es importante mencionar que este tipo de transformaciones son lineales, es decir, que se realizan mediante rotaciones y escalados de los datos originales.\n",
    "* Esta restricción nos permite utilizar técnicas de álgebra lineal para encontrar las transformaciones óptimas que mejor representen nuestros datos (rotaciones y escalado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un objeto PCA con 1 componente para reducir la dimensionalidad de los datos de X a 1D\n",
    "pca = PCA(n_components=1)\n",
    "\n",
    "# Ajustamos el modelo PCA a los datos X\n",
    "pca.fit(X)\n",
    "\n",
    "# Transformamos los datos X al espacio reducido con PCA\n",
    "Xt = pca.transform(X)[:,0]\n",
    "\n",
    "# Graficamos los datos originales X en azul y los datos transformados Xt en rojo en el eje horizontal\n",
    "# El eje vertical está fijado en 0 para visualizar mejor la reducción de dimensionalidad\n",
    "plt.scatter(X[:,0], X[:,1], color=\"blue\", alpha=.5, label=\"$\\mathbf{X}$: original data\")\n",
    "plt.scatter(Xt, [0]*len(Xt), color=\"red\", alpha=.5, label=\"$\\mathbf{X_t}$: reduced data\")\n",
    "\n",
    "# Establecemos el mismo rango en ambos ejes para una mejor visualización y agregamos una leyenda\n",
    "plt.axis(\"equal\");\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1.01,.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos también recontruir los datos 2D después de la transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el primer componente principal\n",
    "v0 = pca.components_[0]\n",
    "\n",
    "# Proyectamos nuestros datos sobre el primer componente\n",
    "c = X.dot(v0)\n",
    "\n",
    "# Obtenemos la reconstrucción de los datos proyectados usando únicamente el primer componente\n",
    "Xr = np.r_[[i*v0 for i in c]]\n",
    "\n",
    "# Graficamos los datos originales y los datos reconstruidos\n",
    "plt.scatter(X[:,0], X[:,1], color=\"blue\", alpha=.5, label=\"original data\")\n",
    "plt.scatter(Xr[:,0], Xr[:,1], color=\"red\", alpha=.5, label=\"reconstructed data from largest component\")\n",
    "# Agregamos una leyenda y definimos el tamaño de la figura\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1.01,.5))\n",
    "plt.figure(figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción de dimensionalidad para tareas de clasificación\n",
    "\n",
    "La reducción de dimensionalidad PCA puede mejorar la eficiencia computacional de los modelos de clasificación al reducir el número de características.\n",
    "* La eliminación de características redundantes o irrelevantes mediante PCA puede mejorar la precisión y generalización del modelo.\n",
    "* PCA puede ayudar a visualizar mejor los datos y las relaciones entre las características, lo que puede facilitar la interpretación y comprensión del modelo y de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando el dataset mnist1.5k con pandas\n",
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "\n",
    "# Seleccionando las columnas de imágenes del dataset\n",
    "d = mnist[:, 1:785]\n",
    "\n",
    "# Seleccionando la columna de las clases del dataset\n",
    "c = mnist[:, 0]\n",
    "\n",
    "# Imprimiendo la dimensión de las imágenes y las clases\n",
    "print(\"Dimensión de las imágenes y las clases: \", d.shape, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código selecciona aleatoriamente 50 imágenes y sus correspondientes etiquetas de un conjunto de datos de imágenes y las muestra en una figura con sus etiquetas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(range(d.shape[0]))[0:50]\n",
    "random_imgs   = d[perm]\n",
    "random_labels = c[perm] \n",
    "fig = plt.figure(figsize=(10,6))\n",
    "for i in range(random_imgs.shape[0]):\n",
    "    ax=fig.add_subplot(5,10,i+1)\n",
    "    plt.imshow(random_imgs[i].reshape(28,28), interpolation=\"nearest\", cmap = plt.cm.Greys_r)\n",
    "    ax.set_title(int(random_labels[i]))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de componentes principales\n",
    "\n",
    "El siguiente código carga un conjunto de datos de imágenes MNIST y realiza reducción de dimensionalidad mediante el análisis de componentes principales (PCA). Luego, muestra algunas de las componentes principales (PCs) obtenidas y también visualiza algunas imágenes originales y sus correspondientes reconstrucciones a partir de las PCs. Finalmente, utiliza un clasificador Naive Bayes y valida su desempeño en los datos originales y los datos transformados por PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el conjunto de datos de imágenes MNIST y separa las características (pixeles) de las etiquetas (números escritos a mano).\n",
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "X=mnist[:,1:785]\n",
    "y=mnist[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una instancia de PCA con 60 componentes y ajusta los datos de entrenamiento.\n",
    "pca = PCA(n_components=60)\n",
    "Xp = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenemos los componentes principales\n",
    "Visualiza 60 componentes principales como imágenes de 28x28 píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=20\n",
    "plt.figure(figsize=(15,3))\n",
    "for i in range(len(pca.components_)):\n",
    "    plt.subplot(np.ceil(len(pca.components_)/15.),15,i+1)\n",
    "    plt.imshow((pca.components_[i].reshape(28,28)), cmap = plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificamos la reconstrucción con los componentes principales\n",
    "Visualiza 6 imágenes originales y sus reconstrucciones a partir de las componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in range(6):\n",
    "    plt.subplot(3,6,i+1)\n",
    "    k = np.random.randint(len(X))\n",
    "    plt.imshow((np.sum((pca.components_*Xp[k].reshape(-1,1)), axis=0)).reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.subplot(3,6,6+i+1)\n",
    "    plt.imshow(X[k].reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación en el nuevo espacio de representación\n",
    "\n",
    "Utiliza el clasificador Naive Bayes y calcula el desempeño de la clasificación en los datos originales y los datos transformados por PCA.\n",
    "* El **clasificador de Naive Bayes** es un algoritmo de aprendizaje supervisado que se basa en el teorema de Bayes para predecir la clase de un dato nuevo a partir de sus características. El teorema de Bayes es un principio matemático que describe cómo actualizar la probabilidad de una hipótesis a medida que se obtiene nueva evidencia. Algunas características importantes de este clasificador son:\n",
    "    - Es un método simple y rápido que puede ser utilizado en conjuntos de datos grandes.\n",
    "    - Es especialmente útil cuando se tienen muchas características y se desea evitar el problema de la maldición de la dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "print(np.mean(cross_val_score(GaussianNB(), X, y, cv=5)))\n",
    "print(np.mean(cross_val_score(GaussianNB(), Xp, y, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo modelo, el que utilizó PCA, tiene un mejor rendimiento en términos de precisión que el primero que no utilizó PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observa la nueva representación de la primera imagen\n",
    "Muestra la primera instancia de los datos transformados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando pipelines\n",
    "\n",
    "Debemos de tener cuidado cuando usamos transformaciones en clasificación, ya que tenemos que ajustarlas (de manera no supervisada) sólo con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase Pipeline del módulo sklearn.pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Creamos un pipeline que primero hace reducción de dimensionalidad PCA y luego aplica el clasificador Naive Bayes\n",
    "pip = Pipeline([(\"PCA\", PCA(n_components=60)), (\"gaussian\", GaussianNB())])\n",
    "\n",
    "# Obtenemos el resultado del score de validación cruzada utilizando el pipeline en los datos originales X e y\n",
    "print(np.mean(cross_val_score(pip, X,y, cv=5 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "Singular Value Decomposition (SVD) es una técnica matemática que descompone una matriz de datos en tres matrices más simples y significativas que pueden utilizarse para reducir la dimensionalidad de los datos, extraer patrones y características, y hacer la recomposición de los datos originales.\n",
    "\n",
    "Características de SVD:\n",
    "* Puede ser utilizado para reducción de dimensionalidad, detección de patrones y características, y análisis de correlación.\n",
    "* Es una técnica no supervisada que no requiere de etiquetas o clases de datos para operar.\n",
    "* Es ampliamente utilizado en aplicaciones como procesamiento de señales, reconocimiento de voz, minería de datos y aprendizaje automático.\n",
    "\n",
    "En la fórmula presentada, $\\mathbf{X}$ representa la matriz de datos original que se desea descomponer en tres matrices más simples. $\\mathbf{U}$ y $\\mathbf{V}^*$ representan matrices unitarias que contienen información sobre las direcciones y magnitudes de las variaciones de los datos en cada dimensión. \n",
    "\n",
    "$$\\mathbf{X} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^*$$ \n",
    "\n",
    "donde:\n",
    "\n",
    "- $\\mathbf{X}$ son nuestros datos\n",
    "- $\\mathbf{U}$ es unitaria (sus columnas y filas son ortonormales, forman una base)\n",
    "- $\\mathbf{V}^*$ es unitaria (sus columnas y filas son ortonormales, forman una base)\n",
    "\n",
    "\n",
    "$\\mathbf{\\Sigma}$ es una matriz diagonal que contiene los valores singulares, que representan la importancia relativa de cada dimensión.\n",
    "La matriz $\\mathbf{X}$ puede ser recompuesta como el producto de las tres matrices: $\\mathbf{U}$, $\\mathbf{\\Sigma}$ y $\\mathbf{V}^*$, lo que permite una representación más simple y eficiente de los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la descomposición en valores singulares de los datos de entrada X\n",
    "U, s, V = np.linalg.svd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la forma de las matrices U, s y V\n",
    "# U es una matriz unitaria cuyas columnas y filas son ortonormales (forman una base)\n",
    "# s es un vector que contiene los valores singulares de X\n",
    "# V es una matriz unitaria cuyas columnas y filas son ortonormales (forman una base)\n",
    "U.shape, s.shape, V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruimos la matriz diagonal s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el vector de valores singulares en una matriz diagonal\n",
    "s = np.diag(s)\n",
    "# Añadir filas de ceros a la matriz de valores singulares para que tenga la misma forma que U\n",
    "s = np.vstack([s, np.zeros((U.shape[0]-s.shape[0], s.shape[1]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos las propiedades SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"verificando si U es unitaria: \", np.allclose(U.dot(U.T), np.eye(U.shape[0])))\n",
    "print(\"verificando si las filas de U son unitarias: \", np.allclose(np.linalg.norm(U, axis=1), np.ones(U.shape[0])))\n",
    "print(\"verificando si las columnas de U son unitarias: \", np.allclose(np.linalg.norm(U, axis=0), np.ones(U.shape[1])))\n",
    "print(\"verificando si V es unitaria: \", np.allclose(V.T.dot(V), np.eye(V.shape[0])))\n",
    "print(\"verificando si las filas de V son unitarias: \", np.allclose(np.linalg.norm(V, axis=1), np.ones(V.shape[0])))\n",
    "print(\"verificando si las columnas de V son unitarias: \", np.allclose(np.linalg.norm(V, axis=0), np.ones(V.shape[1])))\n",
    "print(\"verificando la reconstrucción de X: \", np.allclose(U.dot(s).dot(V), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Sigma$ viene ordenada, y cada coeficiente cuantifica cuanto contribuye cada base en $V$ a la variabilidad de los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.diagonal(s))\n",
    "plt.xlabel(\"component index of $\\Sigma$\");\n",
    "plt.ylabel(\"component value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observa que los componentes de PCA y $V^*$ de SVD son los mismos\n",
    "\n",
    "Aunque a veces vengan con signo distinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm = X-np.mean(X, axis=0)\n",
    "U,s,V = np.linalg.svd(Xm)\n",
    "pca = PCA(n_components=60)\n",
    "pca.fit(Xm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(pca.n_components)\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(121)\n",
    "plt.plot(pca.components_[i])\n",
    "plt.title(\"PCA component %d\"%i)\n",
    "plt.subplot(122)\n",
    "plt.title(\"SVD $V^*$ row %d\"%i)\n",
    "plt.plot(V[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo si queremos preservar solamente los vectores base de SVD que contienen el 40% de la variabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = np.argwhere(np.cumsum(s)/np.sum(s)>.4)[0][0]\n",
    "print(\"Keeping %d components\"%n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = V[:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=20\n",
    "plt.figure(figsize=(15,3))\n",
    "for i in range(len(c)):\n",
    "    plt.subplot(np.ceil(len(c)/15.),15,i+1)\n",
    "    plt.imshow((c[i].reshape(28,28)), cmap = plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo cual corresponde a los mismos componentes mencionados arriba para PCA.\n",
    "\n",
    "Los componentes de PCA y las columnas de la matriz $V^*$ de SVD son los mismos porque el proceso de SVD es esencialmente un proceso de PCA. Al aplicar SVD a una matriz de datos, la matriz de $V^*$ devuelve las componentes principales de la matriz original. Por lo tanto, los vectores de la matriz de $V^*$ se pueden utilizar como componentes principales para la reducción de la dimensionalidad, de la misma manera que los componentes principales se obtienen directamente del proceso de PCA.\n",
    "\n",
    "Ambos métodos realizan una descomposición de los datos para identificar las componentes principales y reducir la dimensionalidad, por lo que los componentes resultantes son los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non negative matrix factorization\n",
    "\n",
    "Non-negative matrix factorization (NMF) es un método de factorización de matrices que descompone una matriz no negativa en dos matrices no negativas de menor rango.\n",
    "\n",
    "Características de NMF:\n",
    "* Se utiliza para reducción de dimensionalidad, extracción de características y clustering.\n",
    "* Las matrices resultantes son interpretables y pueden ser utilizadas para identificar patrones y relaciones entre los datos.\n",
    "* Es especialmente útil para datos en los que se espera que los valores sean no negativos, como en imágenes o señales.\n",
    "\n",
    "El objetivo de NMF es descomponer una matriz no negativa $V \\in \\mathbb{R}+^{m\\times n}$ en el producto $W \\times H$, donde $W \\in \\mathbb{R}+^{m\\times r}$ y $H \\in \\mathbb{R}+^{r\\times n}$ con la restricción de que todo sea positivo ($\\in \\mathbb{R}+$). Esto se hace de forma que la aproximación\n",
    "\n",
    "$$V \\approx W \\times H$$\n",
    "\n",
    "tenga un error mínimo.\n",
    "\n",
    "Las filas de $H$ son los _componentes base_ que se utilizan para reconstruir la matriz original., y se soluciona planteándolo como un problema de optimización matemática con restricciones.\n",
    "\n",
    "$$\\begin{split}\n",
    "argmin_{W,H}\\;& ||V-W\\times H||\\\\\n",
    "s.t.&\\;W,H \\in \\mathbb{R}_+\n",
    "\\end{split}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/marcoteran/deeplearning/raw/master/notebooks/figures/nmf.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos la descomposición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la función NMF del módulo sklearn.decomposition\n",
    "from sklearn.decomposition import NMF\n",
    "# Cargar los datos de la base de datos mnist\n",
    "X = mnist[:,1:785]; y = mnist[:,0]\n",
    "\n",
    "#Definir un modelo NMF con 15 componentes y una inicialización aleatoria\n",
    "nmf = NMF(n_components=15, init=\"random\")\n",
    "\n",
    "#Ajustar el modelo y transformar los datos\n",
    "Xn = nmf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el número de columnas para la figura\n",
    "cols = 20\n",
    "#Crear una figura de tamaño 15x3\n",
    "plt.figure(figsize=(15,3))\n",
    "\n",
    "#Recorrer cada componente del modelo NMF\n",
    "for i in range(len(nmf.components_)):\n",
    "    plt.subplot(len(nmf.components_)/15,15,i+1)# Crear un subplot para cada componente\n",
    "    # Mostrar el componente como una imagen de escala de grises\n",
    "    plt.imshow(np.abs(nmf.components_[i].reshape(28,28)), cmap = plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la primera fila de los datos transformados\n",
    "Xn[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificamos la reconstrucción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una figura de tamaño 10x6\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(6):\n",
    "    plt.subplot(3,6,i+1)\n",
    "    # Escoger un índice de ejemplo aleatorio\n",
    "    k = np.random.randint(len(X))\n",
    "    plt.imshow(np.abs(np.sum((nmf.components_*Xn[k].reshape(-1,1)), axis=0)).reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.subplot(3,6,6+i+1)\n",
    "    plt.imshow(X[k].reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificamos en el nuevo espacio de representación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la media de la puntuación de la validación cruzada con un modelo GaussianNB en los datos originales\n",
    "print(np.mean(cross_val_score(GaussianNB(), X,y, cv=5)))\n",
    "# Mostrar la media de la puntuación de la validación cruzada con un modelo GaussianNB en los datos transformados\n",
    "print(np.mean(cross_val_score(GaussianNB(), Xn,y, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La primera imagen en el nuevo espacio de representación\n",
    "Observa que todos los componentes son positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la primera fila de los datos transformados\n",
    "Xn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: NMF para el reconocimiento de rostros\n",
    "\n",
    "El código carga un conjunto de datos de imágenes de caras, muestra algunas de ellas en una figura y luego aplica Non-negative Matrix Factorization (NMF) para reducir la dimensionalidad de las imágenes y extraer características relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa la biblioteca pickle para cargar datos almacenados en formato pickle\n",
    "import pickle\n",
    "faces = pickle.load(open(\"data/faces.pkl\", \"rb\"), encoding='latin1')\n",
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una figura con una dimension de 15x2\n",
    "plt.figure(figsize=(15,2))\n",
    "for i in range(30):\n",
    "    plt.subplot(2,15,i+1)\n",
    "    plt.imshow(faces[np.random.randint(len(faces))].reshape(19,19), cmap=plt.cm.Greys_r)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selección aleatoria de 30 caras de tamaño 19x19. Se utiliza la biblioteca scikit-learn para aplicar NMF en dos versiones diferentes (con diferentes opciones de inicialización) y visualiza las características extraídas en dos figuras diferentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un objeto NMF con 30 componentes y se inicializa aleatoriamente\n",
    "nmf      = NMF(n_components=30, init=\"random\")\n",
    "# Se aplica la reducción de dimensiones al conjunto de datos 'faces'\n",
    "faces_n  = nmf.fit_transform(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados\n",
    "cols=20\n",
    "plt.figure(figsize=(15,2))\n",
    "# Se imprime la suma de las componentes de NMF\n",
    "print(np.sum(nmf.components_))\n",
    "for i in range(len(nmf.components_)):\n",
    "    plt.subplot(np.ceil(len(nmf.components_)/15.),15,i+1)\n",
    "    plt.imshow(np.abs(nmf.components_[i].reshape(19,19)), cmap = plt.cm.Greys)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ecuación que se muestra a continuación es una forma de la factorización de matrices no negativas (NMF) con una restricción de dispersión en los componentes.\n",
    "* La NMF es una técnica de reducción de dimensiones en la que se descompone una matriz de datos en dos matrices más pequeñas, una matriz de componentes base y una matriz de pesos, que combinados pueden aproximarse a la matriz original.\n",
    "* En esta formulación, se utiliza la norma $L_1$ en los componentes base para forzar la dispersión, lo que significa que los componentes base tendrán valores pequeños y dispersos en lugar de valores grandes y densamente distribuidos.\n",
    "* La restricción $W,H \\in \\mathbb{R}_+$ significa que todas las entradas de las matrices $W$ y $H$ deben ser no negativas.\n",
    "\n",
    "Forzamos dispersión en los componentes, y extendemos el problema de optimización con la norma $L_1$ en los componentes base.\n",
    "\n",
    "$$\\begin{split}\n",
    "argmin_{W,H}\\;& ||V-W\\times H|| + ||H||^2_1\\\\\n",
    "s.t.&\\;W,H \\in \\mathbb{R}_+\n",
    "\\end{split}$$\n",
    "\n",
    "Una forma alternativa de la NMF que fuerza la dispersión en la nueva representación, utilizando la norma $L_1$ en la matriz $W$\n",
    "$$\\begin{split}\n",
    "argmin_{W,H}\\;& ||V-W\\times H|| + ||W||^2_1\\\\\n",
    "s.t.&\\;W,H \\in \\mathbb{R}_+\n",
    "\\end{split}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un objeto NMF con 30 componentes, inicializadas por una descomposición en valores singulares no negativos y con una relación L1 de 1\n",
    "nmf      = NMF(n_components=30, init=\"nndsvd\", l1_ratio=1)\n",
    "# Se aplica la reducción de dimensiones al conjunto de datos 'faces'\n",
    "faces_n  = nmf.fit_transform(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados\n",
    "cols=20\n",
    "plt.figure(figsize=(15,2))\n",
    "# Se imprime la suma de las componentes de NMF\n",
    "print(np.sum(nmf.components_))\n",
    "for i in range(len(nmf.components_)):\n",
    "    plt.subplot(np.ceil(len(nmf.components_)/15.),15,i+1)\n",
    "    plt.imshow(np.abs(nmf.components_[i].reshape(19,19)), cmap = plt.cm.Greys)\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "¡Todo bien! ¡Es todo por hoy! 😀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taller\n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "* Cargamos el conjunto de datos de movimientos en la bolsa que está en la ubicación `data/company-stock-movements-2010-2015-incl.csv.gz`\n",
    "* Convertimos todos los valores en 1 si > 0 y -1 en otro caso\n",
    "* Aplicamos PCA con 2 componentes al conjunto de datos recién modificado (con +1/-1)\n",
    "* Usa KMeans con 7 clusters\n",
    "* Visualiza los clusters de KMeans en el plano 2D dado por PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 7\n",
    "\n",
    "X = PCA ... <YOUR CODE HERE>\n",
    "y = KMeans ... <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica tu código. Debe de aparecer aproximadamente como esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"imgs/companies_clustering.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Código de ayuda para imprimir un texto al lado de cada punto en el plano 2D**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.hot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(X[:,0], X[:,1], color=cmap((y*255./(n_clusters-1)).astype(int)), s=100, edgecolor=\"black\", lw=2)\n",
    "for i in range(len(d)):\n",
    "    name = d.index[i]\n",
    "    plt.text(X[i,0]+.1, X[i,1]+.1, d.index[i], fontsize=14)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJercicio 3: Bag of features\n",
    "Construiremos en este conjunto de problemas una implementación del método de _Bag of features_, sobre el dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='imgs/bof.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta las siguientes celdas para cargar MNIST y ver una muestra del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values.astype(float)\n",
    "print(\"Dimensión de los datos originales\", mnist.shape)\n",
    "X=mnist[:,1:785]\n",
    "y=mnist[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(range(X.shape[0]))[0:50]\n",
    "random_imgs   = X[perm]\n",
    "random_labels = y[perm] \n",
    "fig = plt.figure(figsize=(10,6))\n",
    "for i in range(random_imgs.shape[0]):\n",
    "    ax=fig.add_subplot(5,10,i+1)\n",
    "    plt.imshow(random_imgs[i].reshape(28,28), interpolation=\"nearest\", cmap = plt.cm.Greys_r)\n",
    "    ax.set_title(int(random_labels[i]))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4: Extracción de parches\n",
    "\n",
    "Completa la siguiente función para que dada una imagen en escala de grises ($\\in [0,255]^{h\\times w}$), extraiga parches de tamaño cuadrado de la misma, con un tamaño de paso concreto, tendiendo en cuenta que:\n",
    "\n",
    "- los parches cuya suma de valores sean cero sólo deberán de ser incluidos sin `include_empty_patches` es verdadero.\n",
    "- sólo se incluirán parches completos (es decir, de tamaño `patch_size` $\\times$ `patch_size`)\n",
    "\n",
    "Por ejemplo, para la siguiente imagen:\n",
    "\n",
    "           img= [[5 8 2 4 1 4 6 8 0 6 1]\n",
    "                 [3 8 1 4 3 5 6 9 3 1 7]\n",
    "                 [8 7 3 4 2 7 6 0 9 3 8]\n",
    "                 [4 7 3 2 7 2 4 7 5 0 5]\n",
    "                 [9 8 7 6 5 1 8 7 0 6 4]\n",
    "                 [0 3 8 4 7 0 0 3 5 5 2]\n",
    "                 [5 4 3 2 1 0 0 8 8 2 8]\n",
    "                 [8 3 7 8 2 5 0 3 8 2 4]\n",
    "                 [6 7 2 8 0 0 1 7 5 4 8]]\n",
    "         \n",
    "la ejecución de `extract_patches(img, 2,5)` da tres parches (el parche con cuatro 0's se excluye por `include_empty_patches=False`):\n",
    "\n",
    "        [[5 8]   [[4 6]   [[0 3]\n",
    "         [3 8]]   [5 6]]   [5 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(img, patch_size, step_size, include_empty_patches=False):\n",
    "    patches = []\n",
    "    for y in range(0, img.shape[0]-patch_size+1, step_size):\n",
    "        for x in ...:\n",
    "            patch = ...\n",
    "    return patches\n",
    "\n",
    "import urllib, inspect\n",
    "src1 = urllib.quote_plus(inspect.getsource(extract_patches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba tu código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([[5, 8, 2, 4, 1, 4, 6, 8, 0, 6, 1],\n",
    "       [3, 8, 1, 4, 3, 5, 6, 9, 3, 1, 7],\n",
    "       [8, 7, 3, 4, 2, 7, 6, 0, 9, 3, 8],\n",
    "       [4, 7, 3, 2, 7, 2, 4, 7, 5, 0, 5],\n",
    "       [9, 8, 7, 6, 5, 1, 8, 7, 0, 6, 4],\n",
    "       [0, 3, 8, 4, 7, 0, 0, 3, 5, 5, 2],\n",
    "       [5, 4, 3, 2, 1, 0, 0, 8, 8, 2, 8],\n",
    "       [8, 3, 7, 8, 2, 5, 0, 3, 8, 2, 4],\n",
    "       [6, 7, 2, 8, 0, 0, 1, 7, 5, 4, 8]])\n",
    "for i in extract_patches(img, 2,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa los parches extraídos de una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size, step_size = 7, 2\n",
    "\n",
    "p = extract_patches(X[1307].reshape(28,28), patch_size, step_size, include_empty_patches=True)\n",
    "print \"patch extraction with empty patches\", len(p)\n",
    "pe = extract_patches(X[1307].reshape(28,28), patch_size, step_size)\n",
    "print \"without empty patches\", len(pe)\n",
    "plt.figure(figsize=(5,5))\n",
    "s = np.sqrt(len(p))\n",
    "for i in range(len(p)):\n",
    "    plt.subplot(s,s,i+1)\n",
    "    plt.imshow(p[i], cmap = plt.cm.Greys_r, interpolation=\"nearest\")\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5: Diccionario visual\n",
    "\n",
    "Fíjate cómo funciona KMeans. Trata de entender el código y ejecútalo varias veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "Xp, _ = make_blobs(n_samples=200,n_features=2, centers=4, cluster_std=2)\n",
    "cols = [\"red\", \"blue\", \"green\", \"gray\"]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(Xp[:,0], Xp[:,1], color=\"gray\")\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.scatter(Xp[:,0], Xp[:,1])\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=3)\n",
    "km.fit(Xp)\n",
    "y = km.predict(Xp)\n",
    "for i in np.unique(y):\n",
    "    plt.scatter(Xp[y==i][:,0], Xp[y==i][:,1], color=cols[i])\n",
    "    plt.xticks([]); plt.yticks([]);\n",
    "for i,p in enumerate(km.cluster_centers_):\n",
    "    plt.scatter(p[0], p[1], s=100, c=\"black\", marker=\"x\", lw=5)\n",
    "    plt.xticks([]); plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un KMeans con los parches extraídos de las imágenes y consideraremos los centroides como palabras visuales. Para ello, completa la función siguiente de forma que:\n",
    "\n",
    "- tendrás que usar la función `extract_patches` del ejercicio anterior.\n",
    "- construye una lista con todos parches de las imágenes de la matriz `X`. Observa que en cada file de la matriz hay una imagen linearizada y tendrás que hacer un `.reshape(28,28)` para convertirla en una matriz antes de llamar a `extract_patches`.\n",
    "- devuelve la lista de centroides del `KMeans`. Consulta la documentación de [KMeans en sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "Esta lista de centroides será nuestro **diccionario visual** y, como cada centroide tiene el mismo tamaño que los parches, los podremos visualizar. A continuación, completa el código de tal forma que se pueda visualizar el diccionario de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_dictionary(X, patch_size, step_size, dict_size):\n",
    "    from sklearn.cluster import KMeans\n",
    "    patches = []\n",
    "    for img in X:\n",
    "        patches_in_this_image = ...\n",
    "        patches.append(...)\n",
    "\n",
    "    cinit = np.zeros((dict_size, patch_size**2))\n",
    "    km = KMeans(n_clusters=..., init=cinit, n_init=1)#, n_jobs=24)\n",
    "    km.fit(...)\n",
    "    return ...\n",
    "\n",
    "import urllib, inspect\n",
    "src2 = urllib.parse.quote_plus(inspect.getsource(get_visual_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba tu código. la siguiente configuración te debería de dar un conjunto de palabras visuales como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='imgs/vwords.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size, step_size, dict_size = 7, 7, 30\n",
    "vwords = get_visual_dictionary(X[:100], patch_size, step_size, dict_size)\n",
    "plt.figure(figsize=(15,1.5))\n",
    "vwords = vwords[np.argsort([np.sum(vwords[i]) for i in range(len(vwords))])]\n",
    "print(np.sum([np.sum(vwords[i]) for i in range(len(vwords))]))\n",
    "n = len(vwords)\n",
    "for i in range(n):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(vwords[i].reshape(patch_size,patch_size),cmap = plt.cm.Greys_r,interpolation=\"nearest\")\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6: Histograma de palabras visuales\n",
    "\n",
    "Vamos ahora a calcular de qué palabras visuales consta cada imagen. Esta será la representación _Bag of Features_ ya que, para cada palabra visual, contaremos cuantas veces aparece en cada imagen. Esto es análogo a contar, en un documento, cuantas veces aparece cada palabra.\n",
    "\n",
    "Para ello haremos dos funciones:\n",
    "\n",
    "- `get_closest`: en la que dado un parche y un diccionario visual como el devuelto en el ejercicio anterior nos de la palabara visual más parecida. Esta similitud estará medida en términos de la norma L2 (`np.linalg.norm`)\n",
    "\n",
    "- `get_histogram`:  que, dada una imagen y un diccionario, (1) extrae todos los parches de la imagen, (2) para cada parche obtiene cual es su palabra visual más similar y (3) devuelve un vector con tantos elementos como palabras visuales, con la frecuencia relativa de aparición de cada palabra visual en la imagen. La frecuencia relativa de una palabra visual $w$ viene dada por el número de parches de la imagen cuya palabra visual más similar es $w$, dividido por el número total de parches.\n",
    "\n",
    "Completa el código de ambas funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(patch, dictionary):\n",
    "    r = ...\n",
    "    return r\n",
    "\n",
    "def get_histogram(img, patch_size, step_size, dictionary):\n",
    "\n",
    "    histogram = ...\n",
    "    return histogram\n",
    "\n",
    "import urllib, inspect\n",
    "src3 = urllib.parse.quote_plus(inspect.getsource(get_closest)+inspect.getsource(get_histogram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba tu código. La celda siguiente selecciona un parche al azar de una imagen al azar y muestra su palabra visual más cercana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size, step_size = 7, 2\n",
    "\n",
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values.astype(float)\n",
    "X=mnist[:,1:785]\n",
    "y=mnist[:,0]\n",
    "img = X[np.random.randint(len(X))].reshape(28,28)\n",
    "patches = extract_patches(img, patch_size, step_size)\n",
    "patch   = patches[np.random.randint(len(patches))].reshape(patch_size**2)\n",
    "vword = vwords[get_closest(patch, vwords)]\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(patch.reshape(patch_size, patch_size),  cmap = plt.cm.Greys_r, interpolation=\"nearest\")\n",
    "plt.title(\"patch\")\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.title(\"visual word\")\n",
    "plt.imshow(vword.reshape(patch_size, patch_size),  cmap = plt.cm.Greys_r, interpolation=\"nearest\")\n",
    "plt.xticks([]); plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda selecciona una imagen al azar y obtiene su histograma de palabras visuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.random.randint(len(X))\n",
    "print k\n",
    "img = X[k].reshape(28,28)\n",
    "h = get_histogram(img, patch_size, step_size, vwords)\n",
    "plt.imshow(img, cmap = plt.cm.Greys_r, interpolation=\"nearest\")\n",
    "\n",
    "plt.figure(figsize=(17,3))\n",
    "n = len(vwords)\n",
    "for i in range(n):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(vwords[i].reshape(patch_size,patch_size),cmap = plt.cm.Greys_r)\n",
    "    plt.title(\"%.2f\"%h[i])\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenta con la nueva representación\n",
    "\n",
    "Observa cómo aumenta el porcentaje de acierto representando las imágenes con un histograma de palabras visuales. Este proceso puede demorarse varios minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size, step_size = 7,2\n",
    "#vdict = get_visual_dictionary(X, patch_size, step_size, 60)\n",
    "Xh = []\n",
    "for i, img in enumerate(X):\n",
    "    print(\"\\r\",i,)\n",
    "    Xh.append(get_histogram(img.reshape(28,28), patch_size, step_size, vdict))\n",
    "    \n",
    "Xh = np.array(Xh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "estimator = GaussianNB()\n",
    "sc = cross_val_score(estimator, X, y, cv=5)\n",
    "print(\"Original pixels                %.3f +/- %.3f\"%(np.mean(sc), np.std(sc)))\n",
    "sc = cross_val_score(estimator, Xh, y, cv=5)\n",
    "print(\"Bag of features representation %.3f +/- %.3f\"%(np.mean(sc), np.std(sc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
