{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/3.1_deepleaningintroduction_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/3.1_deepleaningintroduction_dnn.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de código\n",
    "# Sesión 07: Introducción al Aprendizaje profundo\n",
    "## Deep Learning y series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran **E-mail:** marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar librerías importantes\n",
    "\n",
    "Definimos primero unas librerías y funciones que vamos a usar a durante la sesión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set()  # for plot styling\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN\n",
    "from IPython.display import HTML\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurona artificial\n",
    "\n",
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/ArtificialNeuronModel_english.png/600px-ArtificialNeuronModel_english.png\" width=\"60%\">\n",
    "\n",
    "* El perceptrón es un algoritmo de clasificación que genera una predicción para una entrada $(x)$ de la siguiente manera:\n",
    "$$\\textrm{Predicción}(x)=\\begin{cases}\n",
    "C_{1} & \\mbox{si }f(x)\\ge \\theta\\\\\n",
    "C_{2} & \\mbox{si }f(x)<\\theta\n",
    "\\end{cases}$$\n",
    "\n",
    "* De igual forma, $f(x)$ está definida como una suma ponderada sobre los elementos de la entrada:\n",
    "$$\n",
    "f(x) = w_0 + \\sum_{i=1}^{n} {w_i x_i}\n",
    "$$\n",
    "dónde $x$ corresponde a la entrada, $w$ corresponde a los pesos que se multiplican por la entrada $x$ y $w_0$ al sesgo.\n",
    "\n",
    "* Para poder generar $\\textrm{Predicción}(x)$, se toma la salida de $f(x)$ y se le aplica una **función de activación** $\\varphi$. Así la salida del perceptrón es de la siguiente forma:\n",
    "$$\n",
    "y = varphi(w_0 + \\sum_{i=1}^{n} {w_i x_i})\n",
    "$$\n",
    "\n",
    "* Es común encontrar en la literatura que se mencione que una neurona se activó, si su valor de la salida $y$ superó el umbral $\\theta$ definido para la neurona.\n",
    "\n",
    "**¿Cómo escoger $\\varphi$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de activación de paso\n",
    "\n",
    "El caso más sencillo se conoce como la función de activación de paso. La función de activación de paso se define de la siguiente manera:\n",
    "\n",
    "$$\\textrm{H}(x)=\\begin{cases}\n",
    "0 & \\mbox{si }x\\ge \\theta\\\\\n",
    "1 & \\mbox{si }x<\\theta\n",
    "\\end{cases}$$\n",
    "\n",
    "La cual observamos a continuación\n",
    "\n",
    "<img src=\"https://c.mql5.com/2/4/act1.png\" align=\"middle\"  width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de activación logística\n",
    "\n",
    "La función de activación logística está basada en la función sigmoide $\\sigma$. La función sigmoíde para cualquier valor $z$ se define de la siguiente manera:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "<img width= 300 src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/SigmoidFunction.png/400px-SigmoidFunction.png\" align=\"middle\"  width=\"15%\">\n",
    "\n",
    "Cómo se puede observar en la imagen, la función sigmoide genera valores entre $0$ y $1$. A diferencia de la función de activación de paso, la sigmoide genera una transición entre $0$ y $1$. La salida del perceptrón queda definida de la siguiente manera:\n",
    "\n",
    "$$\n",
    "y = \\sigma(w_0 + \\sum_{i=1}^{n} {w_i x_i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1: El \"Hello World\" del *Deep Learning* con Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la primera aplicación de cualquier proyecto, se recomienda comenzar con algo muy simple que permita entender el funcionamiento general del código. En el caso de la creación de redes neuronales, una muestra útil es aprender la relación entre dos números.\n",
    "\n",
    "Si se está escribiendo código para una función como la siguiente si ya se conocen las reglas:\n",
    "\n",
    "```\n",
    "float hw_function(float x){\n",
    "    float y = (2 * x) - 1;\n",
    "    return y;\n",
    "}\n",
    "```\n",
    "¿Cómo se entrenaría una red neuronal para hacer la misma tarea? Pues utilizando datos. Al alimentar la red con un conjunto de valores $X$ y otro conjunto de valores $Y$, debería ser capaz de aprender la relación entre ellos.\n",
    "\n",
    "Este enfoque es muy diferente al que se suele utilizar en programación tradicional, por lo que es necesario repasarlo detalladamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Tensorflow y Keras\n",
    "Para utilizar TensorFlow y Keras en Python, es necesario importar sus librerías correspondientes. Para ello, se puede utilizar el siguiente código en una celda de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto importará la librería de TensorFlow, imprimirá la versión actual instalada y luego importará la librería de Keras dentro de TensorFlow. Con esto, ya se puede comenzar a trabajar con redes neuronales y deep learning en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir y compilar la red neuronal\n",
    "\n",
    "Este modelo es la red neuronal más simple posible, ya que tiene una sola capa y una neurona, y la forma de entrada es solo un valor. En otras palabras, la capa es completamente conectada y la entrada es una dimensión. La capa densa es una de las capas más comunes en una red neuronal, y en este caso tiene solo una unidad.\n",
    "\n",
    "Aunque es un modelo muy básico, es útil para entender cómo se construye una red neuronal en TensorFlow y Keras. Además, se puede entrenar este modelo con datos y luego utilizarlo para hacer predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear un modelo de red neuronal en TensorFlow y Keras en Python, se puede utilizar el siguiente código en una celda de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential:** se utiliza para definir una secuencia de capas en la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código creará un modelo de red neuronal secuencial utilizando la librería de Keras dentro de TensorFlow\n",
    "* En este caso, el modelo tendrá una capa densa con una unidad y una entrada de una dimensión\n",
    "* Esta estructura básica es útil para comenzar a trabajar con redes neuronales simples, aunque es importante tener en cuenta que los modelos más complejos requerirán una estructura más sofisticada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se compila la Red Neural. Al compilarla, se deben especificar dos funciones: **una función de pérdida** y un **optimizador**.\n",
    "\n",
    "Aunque normalmente se utilizan muchas matemáticas para el aprendizaje de la máquina, en este caso están encapsuladas en funciones para facilitar el proceso.\n",
    "\n",
    "* La **función de pérdida** mide las respuestas estimadas contra las respuestas correctas conocidas y determina qué tan bien o qué tan mal se desempeñó la red neuronal.\n",
    "\n",
    "* Luego, se utiliza la **función de optimización** para hacer otra suposición. Basándose en cómo fue la función de pérdida, se intentará minimizar la pérdida. En ese punto, la red neuronal puede proponer algo como $y = 5x + 5$, que, aunque sigue siendo bastante malo, está más cerca del resultado correcto (es decir, la pérdida es menor).\n",
    "\n",
    "Este proceso se repetirá durante el número de épocas, *ephocs*, especificadas. Para la función de pérdida se utiliza *\"error cuadrado medio\"* y para el optimizador se utiliza *\"descenso gradiente estocástico\"*. Aunque no es necesario entender las matemáticas detrás de estas funciones por ahora, es importante saber que funcionan.\n",
    "\n",
    "Con el tiempo, se aprenderán las diferentes funciones de pérdida y optimizador apropiadas para diferentes escenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los datos\n",
    "\n",
    "A continuación se presentan algunos datos que se alimentarán en la red neuronal:\n",
    "- Se generan 6 valores para $x$ y 6 valores para $y$, cuya relación entre ellos sea de la forma $y=2x-1$. Por ejemplo, si $x = -1$, entonces $y = -3$, y así sucesivamente.\n",
    "\n",
    "Para manejar estos datos, se utiliza la biblioteca de Python llamada `'Numpy'`, la cual proporciona estructuras de datos de tipo matriz que son una forma estándar de hacerlo. Los valores se especifican como un `np.array[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando la Red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el proceso de entrenamiento de la red neuronal, la cual *\"aprende\"* la relación entre los $X$ y los $Y$, se utiliza la función `model.fit()`.\n",
    "\n",
    "Aquí, la red neuronal pasará por un bucle en el que hará una suposición, medirá la calidad de la suposición (también conocido como la *pérdida*), usará el optimizador para hacer otra suposición y repetirá el proceso durante el número de épocas especificado.\n",
    "Al ejecutar este código, se puede ver la pérdida en el lado derecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro `epochs` especifica cuántas veces el modelo pasará por el bucle de suposición, medición y optimización mencionado anteriormente. En este caso, se establece en $500$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se ha entrenado un modelo para aprender la relación entre $X$ e $Y$, se puede utilizar el método `model.predict` para determinar el valor de $y$ correspondiente a un valor de $x$ desconocido previamente (*generalización*).\n",
    "Por ejemplo, si se proporciona un valor de $x$ igual a $10$, ¿cuál sería el valor de $y$ correspondiente?\n",
    "- Se sugiere que se realice una predicción antes de ejecutar el código correspondiente para comprobar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una posible respuesta sería que se podría haber esperado un valor de $19$ para $y$ cuando $x$ es igual a $10$. Sin embargo, el resultado real es ligeramente menor.\n",
    "\n",
    "Es importante tener en cuenta que las redes neuronales trabajan con probabilidades y, por lo tanto, basan sus cálculos en los datos que se les han proporcionado para entrenar el modelo. En este caso, la red neuronal calculó que existe una alta probabilidad de que la relación entre $x$ e $y$ sea $y = 2x-1$, pero con sólo seis puntos de datos, no se puede estar seguro de que esta sea la relación correcta. Como resultado, el valor obtenido para $x = 10$ es muy cercano a $19$, pero no necesariamente igual a $19$.\n",
    "\n",
    "Es importante tener en cuenta que este patrón es común en las redes neuronales. Las probabilidades son una parte integral del proceso y, a menudo, se utilizan técnicas de codificación para determinar el resultado final basándose en esas probabilidades, especialmente en problemas de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Clasificador de digitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente código se presenta una introducción a la clasificación de dígitos de la base de datos MNIST utilizando redes neuronales. La base de datos MNIST consta de 70.000 imágenes de dígitos escritos a mano, en escala de grises de 28x28 píxeles, que deben ser clasificadas en su respectivo dígito.\n",
    "\n",
    "Este código utiliza la biblioteca TensorFlow, una de las herramientas más populares para la creación de redes neuronales, para construir y entrenar una red neuronal capaz de clasificar los dígitos de MNIST con alta precisión. Además, se discuten las técnicas de preprocesamiento de datos necesarias para preparar la base de datos MNIST para el entrenamiento de la red neuronal.\n",
    "\n",
    "El objetivo de este código es proporcionar una guía paso a paso sobre cómo construir una red neuronal para clasificar los dígitos de MNIST utilizando técnicas de aprendizaje automático. Con este conocimiento, los usuarios podrán aplicar estas técnicas a otras bases de datos de imágenes y desarrollar soluciones personalizadas para problemas similares de clasificación de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos del MNIST están disponibles directamente en el API de los conjuntos de datos de tf.keras. Se carga la base de datos MNIST utilizando Keras, que es una biblioteca de redes neuronales de código abierto en Python. Esta base de datos contiene un conjunto de imágenes de dígitos escritos a mano, junto con sus etiquetas correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de entrenamiento y prueba se dividen en dos grupos, cada uno consistente en un conjunto de imágenes y un conjunto de etiquetas.\n",
    "La tupla (x_train, y_train) contiene los datos de entrenamiento, mientras que la tupla (x_test, y_test) contiene los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra una imagen del conjunto de entrenamiento. La imagen se selecciona utilizando la notación de corchetes, donde 8 es el índice de la imagen.\n",
    "El parámetro `cmap` indica que la imagen se mostrará en blanco y negro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[8], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprime la etiqueta correspondiente a la imagen seleccionada anteriormente, es decir, la etiqueta del dígito que representa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver la etiqueta\n",
    "print(y_train[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas líneas de código imprimen el número de dimensiones de los datos de entrenamiento, su forma y su tipo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de dimensiones de x_train:\", x_train.ndim)\n",
    "print(\"Tamaño de x_train:\", x_train.shape)\n",
    "print(\"Tipo de datos de x_train:\", x_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una nueva matriz llamada my_slice que contiene las primeras 100 imágenes del conjunto de entrenamiento. Esta nueva matriz se selecciona utilizando la notación de corchetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = x_train[0:100,:]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una nueva matriz llamada my_slice que contiene una sección de 14x14 píxeles de cada imagen del conjunto de entrenamiento. La nueva matriz se selecciona utilizando la notación de corchetes con la sintaxis \"inicio:final\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = x_train[:,7:-7,7:-7]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado de datos de entrada en una red neuronal\n",
    "\n",
    "Acontinuación, se muestra cómo se preprocesan los datos de entrenamiento y prueba para la clasificación de dígitos utilizando redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se convierten los datos de entrenamiento y prueba a 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se normalizan los valores de los pixeles a un rango entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train/=255\n",
    "x_test/=255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se remodelan los datos de entrenamiento y prueba para tener un tamaño de (número de muestras, número de pixeles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rs = x_train.reshape(60000,784)\n",
    "x_test_rs = x_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los tamaños de los datos de entrenamiento y prueba remodelados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_rs.shape)\n",
    "print(x_test_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa la función `to_categorical` de `keras.utils` para convertir las etiquetas a una codificación **one-hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la etiqueta del primer dato de prueba antes de la codificación 'one-hot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de las etiquetas\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se convierten las etiquetas de entrenamiento y prueba a una codificación **one-hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra el tamaño de las etiquetas de entrenamiento después de la codificación 'one-hot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de las etiquetas\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un modelo secuencial vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agrega una capa densa al modelo con 10 neuronas, función de activación *sigmoide* y tamaño de entrada (`input_shape`) de 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation='sigmoid', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dense:** añade una capa de neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agrega una segunda capa densa al modelo con 10 neuronas, función de activación `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La función de activación `softmax`\n",
    "\n",
    "La función de activación `softmax` es una función que se utiliza comúnmente en la capa de salida de una red neuronal para generar una distribución de probabilidad sobre múltiples clases.\n",
    "* Toma una entrada de un vector de cualquier tamaño y produce una salida que representa una distribución de probabilidad discreta sobre las clases.\n",
    "\n",
    "La salida se calcula como la exponencial de cada elemento del vector de entrada dividido por la suma de todas las exponenciales de los elementos del vector de entrada.\n",
    "La fórmula matemática de la función softmax es:\n",
    "\n",
    "$$ \\mbox{softmax}(x_i) = \\frac{e^{x_i}}{\\sum e^{x_j}}\\;\\text{para}\\;j= 1, 2, \\ldots, n;\\;i = 1, 2,\\ldots, n$$\n",
    "\n",
    "`softmax` toma un conjunto de valores y elige el mayor, es decir, convierte una lista como [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05] en [0,0,0,0,1,0,0,0,0,0]. Esto permite evitar la necesidad de buscar manualmente el valor más grande y ayuda a ahorrar tiempo en la codificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra un resumen del modelo creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración del proceso de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compila el modelo utilizando la función de pérdida de *entropía cruzada categorica*, el optimizador *SGD* y se utiliza la precisión (*accuracy*) como métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La función de activación `categorical_crossentropy`\n",
    "La función de activación `categorical_crossentropy` es una medida de distancia que se utiliza para comparar la salida del modelo de clasificación multiclase con las etiquetas reales.\n",
    "- Se utiliza comúnmente en problemas de clasificación con varias clases.\n",
    "\n",
    "Se calcula sumando la pérdida de cada clase para todas las muestras y se define como:\n",
    "\n",
    "$$Categorical Crossentropy = - \\sum_{c=1}^{M} y_{i,c} \\log(p_{o,c})$$\n",
    "\n",
    "donde $y_{i,c}$ es una variable indicadora que toma el valor $1$ si la muestra $i$ pertenece a la clase $c$ y $0$ en caso contrario. $p_{o,c}$ es la probabilidad predicha por el modelo para la muestra $o$ y la clase $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo\n",
    "\n",
    "Se ajusta el modelo utilizando el conjunto de entrenamiento, 5 épocas y se especifica el conjunto de etiquetas para la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_rs, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa el modelo utilizando el conjunto de prueba y se almacenan la pérdida y la precisión (accuracy) en las variables `test_loss` y `test_acc`, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "test_loss, test_acc = model.evaluate(x_test_rs, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la precisión obtenida por el modelo en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión de testeo: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra una imagen del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[11], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizan los datos de prueba para realizar predicciones utilizando el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentra el índice de la predicción más probable para la imagen en la posición 11 del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran las probabilidades de cada clase para la imagen en la posición 11 del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se suma las probabilidades predichas para la imagen en la posición 11 del conjunto de prueba, la cual debe ser 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(predictions[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 3: Redes neuronales en Keras: Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión, se explorará un escenario en el que se desea reconocer diferentes prendas de vestir, entrenando una red neuronal a partir del conjunto de datos Fashion MNIST.\n",
    "Este conjunto de datos contiene 70,000 imágenes de ropa en escala de grises, distribuidas en 10 categorías diferentes, cada una con 7,000 imágenes.\n",
    "\n",
    "**Objetivo:** Utilizar una red neuronal para clasificar correctamente cada imagen en su categoría correspondiente, sin perder la información relevante contenida en cada imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los datos\n",
    "\n",
    "Los datos del MNIST de la moda están disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a `load_data` en este objeto le dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una lista de nombres de clases para las diferentes categorías de ropa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la calidad de los valores de las imágenes y las etiquetas de entrenamiento, es importante visualizarlos. Una forma sencilla de hacer esto es imprimir una imagen de entrenamiento y su etiqueta correspondiente. También se puede experimentar con diferentes índices de la matriz de imágenes para comparar los resultados. Por ejemplo, el índice 42 muestra una imagen diferente de la bota que el índice 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se establecen opciones de impresión para que los arrays sean mostrados con una longitud de línea máxima de 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra la primera imagen del conjunto de datos de entrenamiento y su etiqueta correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_images[0])\n",
    "print('Etiqueta correspondiente: ', training_labels[0])\n",
    "print('Imprime los valores: ', training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para **normalizar** una lista de valores en Python, se puede dividir cada elemento de la lista por el valor máximo de la lista. En este caso, el valor máximo es 255, por lo que se puede normalizar la lista de imágenes de entrenamiento y prueba dividiendo cada elemento por 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte los datos de entrenamiento y prueba en tipo `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.astype('float32')\n",
    "test_images = test_images.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza los valores de píxel de los datos de entrenamiento y prueba para que estén en un rango de 0 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la programación de una red neuronal, se divide el conjunto de datos en dos grupos: el conjunto de entrenamiento y el conjunto de prueba. La razón detrás de esto es tener un conjunto de datos para entrenar el modelo y otro conjunto de datos que el modelo aún no ha visto para evaluar su desempeño en clasificar valores que no ha visto antes. Al finalizar el proceso, se probará el modelo con datos de prueba que no ha visto antes para verificar su capacidad de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime los tamaños de los datos de entrenamiento y prueba, así como la longitud de las etiquetas de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tamaño de train_images: \", training_images.shape)\n",
    "print(\"Cantidad de train_labels: \", len(training_labels))\n",
    "print(\"Tamaño de test_images: \", test_images.shape)\n",
    "print(\"Cantidad de test_labels: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra las etiquetas de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se crea un arreglo de figuras de tamaño 12x12 para mostrar 50 imágenes de entrenamiento y sus etiquetas correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i in range(50):\n",
    "    plt.subplot(10, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(training_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[training_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un modelo secuencial de Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrega una capa de aplanamiento (`Flatten`) y una capa de 10 neuronas con activación sigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten:** esta capa se encarga de convertir una imagen en formato cuadrado en un conjunto de una sola dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrega una capa de 10 neuronas con activación softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime un resumen del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa bibliotecas adicionales para mostrar el diagrama del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydot\n",
    "#!pip install graphviz\n",
    "#!conda install -c anaconda pydot=1.2.3\n",
    "#!conda install -c anaconda pyparsing=2.2.0\n",
    "#!conda install GraphViz\n",
    "\n",
    "import errno\n",
    "import pydot\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra el diagrama del modelo en un archivo PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar el modelo\n",
    "\n",
    "Después de definir el modelo, el siguiente paso es construirlo realmente. Esto se hace compilándolo con una función de optimización y pérdida, como se hizo anteriormente. Luego, se entrena el modelo llamando a `model.fit`, que ajusta los datos de entrenamiento a sus etiquetas de entrenamiento. En otras palabras, el modelo aprende la relación entre los datos de entrenamiento y sus etiquetas reales, para que en el futuro, cuando se le presenten datos similares a los de entrenamiento, pueda hacer una predicción de cómo se verían esos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compila el modelo con el optimizador `sgd`, la pérdida `sparse_categorical_crossentropy` y la métrica `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=[('accuracy')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de activación `sparse_categorical_crossentropy` es una medida de la pérdida que se utiliza en el entrenamiento de modelos de aprendizaje automático para clasificación de múltiples clases.\n",
    "- Se utiliza cuando las etiquetas de clase no están codificadas como vectores one-hot, sino que se proporcionan como enteros.\n",
    "- Se calcula tomando la media del logaritmo de las probabilidades de clase verdadera dada la salida del modelo.\n",
    "- La diferencia con categorical_crossentropy es que esta última espera las etiquetas de clase como vectores one-hot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena el modelo con los datos de entrenamiento durante 5 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que finalice el entrenamiento, se mostrará un valor de precisión al final de la última época. Este valor podría ser algo así como 0.9098, lo que indica que la red neuronal tiene una precisión del 91% en la clasificación de los datos de entrenamiento. En otras palabras, logró encontrar una coincidencia de patrón entre la imagen y las etiquetas el 91% de las veces. Aunque no es excelente, es aceptable considerando que solo se entrenó durante 5 épocas y se hizo bastante rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el rendimiento del modelo en datos no vistos, se utilizan las imágenes de prueba. Se llama a la función `model.evaluate` y se le pasan los dos conjuntos de datos para obtener la pérdida de cada uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "Evalúa el modelo en los datos de prueba y captura los resultados para imprimirlos más tarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra la precisión del modelo en los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión de testeo: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión de la red neuronal que se entrenó fue de aproximadamente 0,8838 al evaluarla con imágenes de prueba, lo que indica que tuvo una precisión del 88%. Como es común en el aprendizaje automático, es probable que no tenga el mismo rendimiento con datos no vistos como con los datos en los que se entrenó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de predicciones\n",
    "\n",
    "Se realiza una predicción utilizando el modelo entrenado en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprime la predicción correspondiente a la imagen en la posición 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprime la etiqueta verdadera correspondiente a la imagen en la posición 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación una función que muestra una imagen con su etiqueta verdadera y su predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    # Se obtienen los valores necesarios para mostrar la imagen y su información\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    # Se configura el gráfico\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # Se muestra la imagen en escala de grises\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    # Se obtiene el índice de la predicción con mayor probabilidad\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    # Si la predicción es correcta, el texto aparecerá en azul, de lo contrario en rojo\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    # Se agrega el texto a la imagen, incluyendo la etiqueta predicha y la probabilidad\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]),\n",
    "                                         color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que muestra la gráfica de barras de las predicciones para una imagen dada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    # Se obtienen los valores necesarios para mostrar la gráfica\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    # Se configura el gráfico\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    # Se muestra la gráfica de barras con las probabilidades para cada etiqueta\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#007700\")\n",
    "    plt.ylim([0, 1])\n",
    "    # Se colorea de rojo la barra correspondiente a la predicción con mayor probabilidad\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    # Se colorea de negro la barra correspondiente a la etiqueta verdadera\n",
    "    thisplot[true_label].set_color('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la imagen y su gráfica de barras para la imagen en la posición 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la imagen y su gráfica de barras para la imagen en la posición 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra una grilla con varias imágenes y sus gráficas de barras correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traza las primeras X imágenes de prueba, su etiqueta predicha y la etiqueta verdadera.\n",
    "# Colorea las predicciones correctas en azul, las incorrectas en rojo\n",
    "num_rows = 7\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejorar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se ha mejorado la red neuronal secuencial.\n",
    "La mejora de la red neuronal incluye tres capas:\n",
    "1. Una capa de aplanamiento (`Flatten`)\n",
    "2. Una capa densa (`Dense`) con una función de activación `sigmoidal`\n",
    "3. Una capa de salida densa con una función de activación `softmax`.\n",
    "\n",
    "La red neuronal se compila utilizando el optimizador `Adam`, una función de pérdida de entropía cruzada categórica dispersa y la métrica de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo secuencial de keras\n",
    "model = tf.keras.Sequential()\n",
    "# Agregar capa de aplanamiento y especificar forma de entrada\n",
    "# Agregar capa densa con 10 unidades y activación sigmoidal\n",
    "# Agregar capa densa con 10 unidades y activación softmax\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compilar el modelo, especificando el optimizador, la función de pérdida y la métrica\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=[('accuracy')])\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento durante 5 épocas\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba y obtener la pérdida y precisión\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels);\n",
    "# Imprimir la precisión en los datos de prueba\n",
    "print('\\nPrecisión en los datos de prueba: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias generales\n",
    "\n",
    "- [Deep Learning en Wikipedia](https://es.wikipedia.org/wiki/Aprendizaje_profundo)\n",
    "- [Perceptrón](hhttps://es.wikipedia.org/wiki/Perceptr%C3%B3n)\n",
    "- [MLP](https://es.wikipedia.org/wiki/Perceptr%C3%B3n_multicapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "¡Todo bien! ¡Es todo por hoy! 😀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
