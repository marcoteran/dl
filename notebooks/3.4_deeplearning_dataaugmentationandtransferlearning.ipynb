{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/3.4_deeplearning_dataaugmentationandtransferlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/3.4_deeplearning_dataaugmentationandtransferlearning.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Upj99k3gOKrQ"
   },
   "source": [
    "### Ejemplo de código\n",
    "# Sesión 10: *Data Augmentation* y *Transfer Learning*\n",
    "## Deep Learning y series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran **E-mail:** marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías importantes\n",
    "\n",
    "Empezamos con las importaciones estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QsdNz2pwOMIK",
    "outputId": "5511537e-d305-49b3-b5d3-c6577a6700b5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "* **Data Augmentation:** una técnica popular para mitigar el sobreajuste en modelos de redes neuronales. Mejorará el modelo del capítulo anterior, aumentando su precisión del 73.9% al 80.1%.\n",
    "* **Transfer Learning:** permitirá mejorar aún más el modelo.\n",
    "\n",
    "\n",
    "Técnicas específicas para mejorar modelos de redes neuronales\n",
    "- Feature Extraction: utilizando una red preentrenada, se logra una precisión del 90.4%.\n",
    "- Fine-Tuning: utilizando una red preentrenada, se logra una precisión del 93.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "La cantidad de datos disponibles para entrenar el modelo tiene un impacto directo en su capacidad para hacer predicciones precisas.\n",
    "**Data Augmentation es una técnica que genera más datos de entrenamiento a partir de los datos disponibles.**\n",
    "\n",
    "- En el caso de imágenes, se aplican transformaciones aleatorias que producen nuevas imágenes de aspecto creíble.\n",
    "- Data Augmentation ayuda a exponer el modelo a más aspectos de los datos y a generalizar mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones de imágenes\n",
    "\n",
    "La técnica de Data Augmentation es muy poderosa para datos de tipo imagen.\n",
    "* Esta técnica consiste en aplicar transformaciones sencillas (rotar, voltear, etc.) a las imágenes para obtener nuevas imágenes plausibles.\n",
    "* Esto ayuda a exponer el modelo a más aspectos de los datos y a generalizar mejor.\n",
    "\n",
    "Es importante tener cuidado al elegir las técnicas de aumento de datos utilizadas.\n",
    "- Se debe tener en cuenta el contexto del conjunto de datos de entrenamiento y el conocimiento del dominio del problema.\n",
    "- De esta manera, se evita generar imágenes que nunca podrían encontrarse en realidad, lo que empeoraría el entrenamiento.\n",
    "\n",
    "En **Keras**, se puede realizar fácilmente mediante la configuración de una serie de transformaciones que se realizarán en las imágenes leídas por la instancia de `ImageDataGenerator`.\n",
    "- Para obtener información detallada sobre las transformaciones disponibles, se puede consultar la API preprocessing de Keras.\n",
    "\n",
    "Es importante destacar que la transformación se realiza de manera online durante el procesamiento. Esto permite hacer el proceso automático durante el entrenamiento sin necesidad de modificar los datos almacenados en disco. De esta manera, el modelo ve una imagen generada aleatoriamente una sola vez. Sin embargo, también se pueden realizar las transformaciones previamente y añadirlas al conjunto de datos de entrenamiento. Esto aceleraría el preprocesado, pero aumentaría el espacio de almacenamiento y el tiempo de carga de los datos en memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuración de ImageGenerator\n",
    "\n",
    "Para aplicar la técnica de Data Augmentation, se deben pasar nuevos argumentos al objeto ImageGenerator de los datos de entrenamiento basándose en el modelo presentado en el capítulo anterior. Algunos de los parámetros que se pueden utilizar son:\n",
    "\n",
    "```Python\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `rotation_range` es un valor en grados (0-180) que indica el rango dentrodel cual se pueden rotar imágenes al azar.\n",
    "* `width_shift` y height_shift son rangos (como una fracción del ancho y la altura total) dentro de los cuales se pueden trasladar las imágenes alazar verticalmente u horizontalmente.\n",
    "* `shear_range` sirve para aplicar transformaciones de corte al azar.\n",
    "* `zoom_range` sirve para aplicar zoom aleatorio dentro de las imágenes\n",
    "* `horizontal_flip` sirve para voltear aleatoriamente la mitad de las imágenes horizontalmente (en nuestro caso de estudio no tiene sentido voltear verticalmente las imágenes).\n",
    "* `fill_mode` es la estrategia utilizada para rellenar los píxeles reciéncreados que pueden aparecer después de una de las transformaciones anteriores.\n",
    "\n",
    "Estas son solo algunas de las opciones disponibles de transformación. Todas las restantes se pueden consultar en la página web de la API preprocessing de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    " \n",
    "uploaded=files.upload()\n",
    "for fn in uploaded.keys():\n",
    "    path='/content/' + fn\n",
    "    img=image.load_img(path)\n",
    "    data = img_to_array(img)\n",
    "    samples = expand_dims(data, 0)\n",
    "  \n",
    "    # example of \"rotation_range\"\n",
    "    datagen = ImageDataGenerator(rotation_range=45)\n",
    "\n",
    "    it = datagen.flow(samples, batch_size=1)\n",
    "    for i in range(6):\n",
    "        pyplot.subplot(230 + 1 + i)\n",
    "        batch = it.next()\n",
    "        image = batch[0].astype('uint8')\n",
    "        pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar cómo se han generado varias imágenes de manera aleatoria a partir de la imagen original utilizando el argumento `rotation_range`.\n",
    "Se sugiere probar con otros argumentos utilizando este código como referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7j8fvlLyachD"
   },
   "source": [
    "## Carga de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6t5CmAYSvj-5"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget -O cats_and_dogs_small.zip https://github.com/marcoteran/deeplearning/raw/master/notebooks/cats_and_dogs_small.zip\n",
    "!unzip cats_and_dogs_small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtsbWwXcBscw"
   },
   "outputs": [],
   "source": [
    "base_dir = 'cats_and_dogs_small'\n",
    "\n",
    "train_dir =      os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir =       os.path.join(base_dir, 'test')\n",
    "\n",
    "# Directorio con las imagenes de training \n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directorio con las imagenes de validation\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Directorio con las imagenes de test\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se imprimen en la consola el número total de imágenes que hay en los directorios correspondientes a los conjuntos de entrenamiento, validación y prueba, tanto de gatos como de perros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "W9r7wCYmBsix",
    "outputId": "4edbf2ea-df14-446a-dff7-eb0e78e34478"
   },
   "outputs": [],
   "source": [
    "print('total training cat images :', len(os.listdir(train_cats_dir ) ))\n",
    "print('total training dog images :', len(os.listdir(train_dogs_dir ) ))\n",
    "\n",
    "print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\n",
    "print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))\n",
    "\n",
    "print('total test cat images :', len(os.listdir( test_cats_dir ) ))\n",
    "print('total test dog images :', len(os.listdir( test_dogs_dir ) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aumentación de los datos\n",
    "\n",
    "* El aumento de datos de imagen se aplica generalmente solo al conjunto de datos de entrenamiento, y no al conjunto de datos de validación o prueba.\n",
    "* Esto difiere de la preparación de datos, como el cambio de tamaño de la imagen y la escala de píxeles, que se aplica a todos los conjuntos de datos.\n",
    "\n",
    "Para nuestro caso de estudio, los generadores se pueden especificar de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La línea de código importa la clase ImageDataGenerator del módulo tensorflow.keras.preprocessing.image de TensorFlow, que permite crear generadores de datos de imagen para su uso en el entrenamiento de modelos de Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define un objeto ImageDataGenerator que se utiliza para realizar un aumento de datos en las imágenes de entrenamiento para el modelo de Deep Learning, especificando diversas técnicas de transformación de imágenes.\n",
    "\n",
    "Los valores de los argumentos especifican:\n",
    "- El rango de rotación permitido (40 grados)\n",
    "- El rango de desplazamiento horizontal y vertical (0.2)\n",
    "- La intensidad de la deformación de la imagen (0.2)\n",
    "- El rango de zoom (0.2), si se aplica o no un volteo horizontal\n",
    "- El modo de llenado para los píxeles que se añaden después de la rotación o el desplazamiento. \n",
    "- El rescale=1./255 normaliza los valores de los píxeles en el rango \\[0,1\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas líneas de código generan tres grupos de datos de imágenes (entrenamiento, validación y prueba) y los cargan utilizando diferentes transformaciones y configuraciones de procesamiento de imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elvc8kFYKj0Y"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n",
    "\n",
    "\n",
    "test_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RgKnvsfKkr8"
   },
   "source": [
    "## Creación del modelo CNN con DA: Modelo CNN con *Data Augmentation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas líneas de código importan módulos y clases específicas de la biblioteca Keras de TensorFlow para construir y entrenar modelos de redes neuronales convolucionales mediante el uso de capas de convolución, agrupamiento, aplanamiento y densas, así como el optimizador RMSprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de una red convolucional de más capas\n",
    "\n",
    "Se define un modelo de red neuronal convolucional (CNN) usando la API Sequential de Keras.\n",
    "- La red consiste en varias capas convolucionales, capas de pooling, capas completamente conectadas y una capa de salida que utiliza la función de activación sigmoid para clasificar imágenes como pertenecientes a una de dos clases.\n",
    "- La entrada del modelo es una imagen RGB de 150x150 píxeles y la salida es una probabilidad de pertenencia a la clase positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaBxETn7Kjwj"
   },
   "outputs": [],
   "source": [
    "modelDA = Sequential()\n",
    "modelDA.add(Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "modelDA.add(MaxPooling2D(2, 2))\n",
    "modelDA.add(Conv2D(64, (3,3), activation='relu'))\n",
    "modelDA.add(MaxPooling2D(2,2))\n",
    "modelDA.add(Conv2D(128, (3,3), activation='relu'))\n",
    "modelDA.add(MaxPooling2D(2,2))\n",
    "modelDA.add(Conv2D(128, (3,3), activation='relu'))\n",
    "modelDA.add(MaxPooling2D(2,2))\n",
    "modelDA.add(Flatten())\n",
    "modelDA.add(Dense(512, activation='relu'))\n",
    "modelDA.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar la estructura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación del modelo\n",
    "\n",
    "Se compila el modelo de deep learning `modelDA` para entrenar una tarea de clasificación binaria utilizando la función de pérdida `binary_crossentropy`, el optimizador `RMSprop` con una tasa de aprendizaje de $10^{-4}$ y como métrica de evaluación se utiliza la precisión (`acc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDA.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red\n",
    "\n",
    "Ahora que ya se ha definido la estructura de red, el optimizador, learning rate y metricas ya se puede entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xU48fLeFKj3I",
    "outputId": "82c9d71d-2b37-4ffb-e1c9-adf7b02f9ed1"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "historyDA = modelDA.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch= steps_per_epoch,\n",
    "    epochs= 100,\n",
    "    validation_data= validation_generator,\n",
    "    validation_steps= validation_steps,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la red\n",
    "\n",
    "Para ver si la red ha aprendido a clasificar bien los números manuscritos hay que comprobar la precisión que obtiene en el conjunto de datos de test. Para este conjunto no ha sido entrenada la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "zkmHqrzCKj8g",
    "outputId": "1b91ca94-1eda-4a1f-e962-d3a3f0369d73"
   },
   "outputs": [],
   "source": [
    "print (steps_per_epoch)\n",
    "print (validation_steps)\n",
    "test_lost, test_acc= modelDA.evaluate(test_generator)\n",
    "print (\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "colab_type": "code",
    "id": "GP2sz8eoKj_T",
    "outputId": "09a9ad92-2b5b-4f3e-a9de-83986a5b1001"
   },
   "outputs": [],
   "source": [
    "acc      = historyDA.history['acc' ]\n",
    "val_acc  = historyDA.history['val_acc']\n",
    "loss     = historyDA.history['loss' ]\n",
    "val_loss = historyDA.history['val_loss']\n",
    "\n",
    "epochs    = range(1,len(acc)+1,1) # obtener número de epochs\n",
    "\n",
    "plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
    "plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     loss, 'r--' )\n",
    "plt.plot  ( epochs, val_loss ,  'b' )\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La técnica se basa en mezclar información existente, lo que puede no ser suficiente para eliminar por completo el sobreajuste en algunos casos.\n",
    "* Para mitigar el sobreentrenamiento, se pueden añadir técnicas como la regularización o Dropout.\n",
    "* Sin embargo, en algunos casos, aún no es suficiente obtener mejores modelos debido a la falta de datos.\n",
    "* Por lo tanto, se presenta otra oportunidad en la siguiente sección: usar modelos preentrenados\n",
    "\n",
    "En resumen, se observó cómo **Data Augmentation** es una técnica útil para reducir el overfitting en modelos de imágenes. Sin embargo, hay *limitaciones* en la capacidad de descubrir nuevas características de los datos.\n",
    "Esto se debe a que, al tener un conjunto de datos de entrenamiento pequeño, la técnica de **Data Augmentation** solo puede mezclar la información existente y no generar información nueva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "**Transfer Learning** es una técnica central en Deep Learning que permite entrenar una red neuronal a partir de una red preentrenada en lugar de entrenarla desde cero.\n",
    "- Esta técnica se utiliza para reducir el tiempo y el costo requeridos para entrenar una red neuronal desde cero, ya que utiliza los parámetros de una red preentrenada como punto de partida para entrenar el modelo.\n",
    "\n",
    "Las **características aprendidas** por la red preentrenada pueden ser útiles para muchos problemas diferentes de visión por computadora, a pesar de que estos nuevos problemas pueden involucrar clases completamente diferentes a las de la tarea original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen dos formas de utilizar una red preentrenada:\n",
    "\n",
    "- **Feature Extraction:** se utiliza la red preentrenada como un extractor de características para un nuevo conjunto de datos.\n",
    "- **Fine-Tuning:** se ajustan los parámetros de la red preentrenada para que se adapte a un nuevo conjunto de datos.\n",
    "\n",
    "En una red neuronal convolucional, las primeras capas son las encargadas de aprender características más genéricas, y estas características aprendidas pueden ser fácilmente reutilizadas en otros problemas.\n",
    "\n",
    "La portabilidad de las características aprendidas a través de diferentes problemas es una de las virtudes clave del Transfer Learning en Deep Learning, y su utilización puede crear modelos de visión potentes con muy pocos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "El **Feature Extraction** es una técnica utilizada para extraer características relevantes de nuevos datos, utilizando los parámetros aprendidos por una red preentrenada. Estas características se procesan a través de un nuevo clasificador que se entrena desde cero.\n",
    "\n",
    "Las **ConvNet* utilizadas para clasificar imágenes se componen de dos partes:\n",
    "1. Una serie de capas de convoluciones y pooling\n",
    "2. Un clasificador formado habitualmente por una o varias capas densas.\n",
    "\n",
    "La primera parte se llama base convolucional del modelo.\n",
    "La extracción de características consiste en tomar la base convolucional de una red previamente entrenada, ejecutar los nuevos datos a través de ella y entrenar a un nuevo clasificador en la parte de la salida.\n",
    "\n",
    "La **reutilización de la base convolucional** es útil ya que las características aprendidas por la red preentrenada son portables a otros problemas del mismo ámbito.\n",
    "\n",
    "Las representaciones encontradas en capas densamente conectadas ya no mantienen información sobre dónde se encuentran los objetos en la imagen de entrada, a diferencia de las capas convolucionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **API de Keras** permite aplicar esta técnica de manera fácil y con pocas líneas de código.\n",
    "* **Keras** permite descargar un modelo y luego configurar cómo este debe ser entrenado, indicando qué capas son entrenables (**Trainable layers**) y qué capas no (**Frozen layers**).\n",
    "* En el caso de visión por computador, muchos modelos preentrenados con **ImageNet** están disponibles en la mayoría de librerías de desarrollo de Deep Learning, como es el caso de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En concreto en la página de modelos preentrenados ``tf.keras.applications`` podemos encontrar disponibles los siguientes modelos para clasificación de imágenes entrenados con **ImageNet**:\n",
    "* Xception\n",
    "* VGG16\n",
    "* VGG19\n",
    "* ResNet50\n",
    "* InceptionV3\n",
    "* InceptionResNetV2\n",
    "* MobileNet\n",
    "* MobileNetV2\n",
    "* DenseNet\n",
    "* NASNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccc5u4fembNS"
   },
   "source": [
    "###  VGG16: Modelo con *Feature Extraction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará la red neuronal **VGG16** con arquitectura convolucional para resolver el problema de clasificación de perros contra gatos. Algunas características de esta red neuronal son:\n",
    "\n",
    "* **VGG16** ha sido entrenada previamente en el conjunto de datos **ImageNet**, que contiene 1.4 millones de imágenes en 1000 clases diferentes.\n",
    "* **ImageNet** incluye diversas clases de animales, incluyendo diferentes especies de gatos y perros, lo que sugiere que VGG16 debería tener un buen rendimiento en este problema de clasificación.\n",
    "* La red neuronal VGG16 fue propuesta por *Karen Simonyan* y *Andrew Zisserman* en su artículo *\"Very Deep Convolutional Networks for Large-Scale Image Recognition\"*.\n",
    "* VGG16 es una red neuronal de **16 capas** que utiliza convoluciones para extraer características de las imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo VGG16 podemos importarlo desde el módulo ``keras.applications``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A este constructor de la red VGG16 se le pasan tres argumentos.\n",
    "1. La forma de los tensores de imágenes que alimentarán a la red (es un argumento opcional).\n",
    "2. El argumento `include_top` indica si se debe incluir (o no) el clasificador en la última capa de la red. \n",
    "    * Este caso, esta capa corresponde a la capa que clasifica las 1000 clases de ImageNet. Debido a que tenemos la intención de usar nuestro propio clasificador (que clasifica solo dos clases: gato y perro) no necesitamos incluirla.\n",
    "3. El último argumento, `weights`, indica de dónde se obtiene la información para iniciar los pesos de los parámetros de la red (en nuestro caso usaremos ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "V2uilIo5hY4y",
    "outputId": "f24bf48c-9e28-404f-c322-41a8d6dcf4b3"
   },
   "outputs": [],
   "source": [
    "pre_trained_model = VGG16(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método ``summary()`` podemos saber el detalle de la arquitectura de la base convolucional VGG16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red neuronal **VGG16** no incluye las dos capas finales fully-connected de 4096 neuronas ni la de 1000 neuronas (cada una representa una categoría de imágenes de ImageNet) si se establece el valor **`False`** del argumento `include_top`.\n",
    "* No se requieren estas capas porque se crearán unas propias para construir un clasificador.\n",
    "* El clasificador se usará para predecir si las imágenes son un perro o un gato.\n",
    "* El último feature map de forma y tamaño (4, 4, 512) que devuelve la base convolucional VGG16 será la entrada para el clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante:** Antes de entrenar el modelo es necesario indicar cual de las capas de la base convolucional **no deben ser entrenadas**, lo que se denomina «congelar» capas (Freeze layers).\n",
    "\n",
    "Congelar una capa o un conjunto de capas significa evitar que sus pesos se actualicen durante el entrenamiento.\n",
    "* Si no se hiciera esto, los valores que fueron previamente aprendidos por la base convolucional serían modificados durante el entrenamiento, efecto que no se busca.\n",
    "* En Keras, congelar una capa se realiza estableciendo su atributo trainable a False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se recorren todas las capas de la red pre-entrenada (pre_trained_model) y se establece el atributo `trainable` de cada capa en **`False`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al establecer este atributo en False, se evita que los pesos de las capas se actualicen durante el entrenamiento del modelo en el nuevo conjunto de datos. En cambio, se conservan los pesos previamente aprendidos por la red pre-entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Keras los modelos los podemos considerar como capas y, por tanto, podemos agregar un modelo (como `pre_trained_model`) a un modelo secuencial al igual que agregaríamos una capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSbSk4CKd4ev"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una red neuronal llamada `modelFE` que utiliza transferencia de aprendizaje para extraer características útiles de las imágenes de entrada utilizando una red neuronal pre-entrenada `pre_trained_model` y luego entrena una capa clasificadora adicional en la parte superior para clasificar las imágenes en dos clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFE = Sequential()\n",
    "modelFE.add(pre_trained_model)\n",
    "modelFE.add(Flatten())\n",
    "modelFE.add(Dense(256, activation='relu'))\n",
    "modelFE.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `modelFE.add(Dense(256, activation='relu'))` agrega una capa densa de 256 neuronas con función de activación ReLU, que tiene la tarea de aprender a clasificar las características extraídas de la imagen de entrada en clases.\n",
    "\n",
    "- `modelFE.add(Dense(1, activation='sigmoid'))` agrega una capa densa de una sola neurona con función de activación sigmoidal que se encarga de generar la salida de la red. La salida es un número entre 0 y 1 que representa la probabilidad de que la imagen de entrada pertenezca a la clase positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así es como el método `summary()` presenta la red neuronal que se acaba de construir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "p1KRETLXuHpZ",
    "outputId": "22ba0523-964b-446d-b92d-a6e71348524c"
   },
   "outputs": [],
   "source": [
    "modelFE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el preprocesado de **Data Augmentation**. El siguiente código genera tres objetos `ImageDataGenerator` para aumentar y escalar las imágenes de entrenamiento, validación y prueba, respectivamente.\n",
    "\n",
    "Luego, utiliza el método `flow_from_directory` para cargar las imágenes de cada conjunto y aplicar las transformaciones definidas en los ImageDataGenerators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "InQuF32GiBRP",
    "outputId": "281d6e22-3a80-40ad-b00a-7c8b9c14a604"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n",
    "\n",
    "test_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compila red utilizando los mismos parametros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DCSzluJsiBXA",
    "outputId": "144b618b-3155-47d4-d24c-0cc0364246ee"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "modelFE.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comienza a entrenar el modelo con el método ``fit()``, con la misma configuración de Data Augmentation que utilizamos en la sección anterior.\n",
    "\n",
    "Pero no es necesariamente siempre la mejor opción; la mejor combinación de técnicas depende del tipo y cantidad de datos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "historyFE = modelFE.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = steps_per_epoch,\n",
    "            epochs = 100,\n",
    "            validation_steps = validation_steps,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar la precisión con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcMMuw_oSRAq"
   },
   "outputs": [],
   "source": [
    "test_lost, test_acc= modelFE.evaluate(test_generator)\n",
    "print (\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KxNfD7QiJpU"
   },
   "outputs": [],
   "source": [
    "acc      = historyFE.history['acc']\n",
    "val_acc  = historyFE.history[ 'val_acc']\n",
    "loss     = historyFE.history['loss']\n",
    "val_loss = historyFE.history['val_loss']\n",
    "\n",
    "epochs    = range(1,len(acc)+1,1) # obtener número de epochs\n",
    "\n",
    "plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
    "plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "#plt.ylim(0,1)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     loss, 'r--' )\n",
    "plt.plot  ( epochs, val_loss ,  'b' )\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "#plt.ylim(0,1)\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La técnica de **Fine-Tuning** es complementaria a la **Feature Extraction** y se utiliza ampliamente en la reutilización de modelos.\n",
    "Consiste en hacer un *ajuste más fino* y entrenar algunas de las capas finales de la *base convolucional* del modelo usado para la extracción de características, junto con la parte agregada del clasificador.\n",
    "\n",
    "El *ajuste fino* de las representaciones más abstractas del modelo se realiza en **Fine-Tuning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nivel de generalización y, por lo tanto, de reutilización de las representaciones extraídas por capas de convolución específicas depende de la posición de la capa en el modelo.\n",
    "* Las primeras capas aprenden características generales y, después, gradualmente en capas sucesivas se van aprendiendo características más concretas del dominio de problema que estamos tratando.\n",
    "* Las capas del modelo que están más próximas a la capa de entrada de datos extraen mapas de características locales altamente genéricas, mientras que las capas que están más cerca del clasificador final extraen conceptos más abstractos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base convolucional VGG16 se compone de 5 bloques: *block1, block2, block3, block4, block5.*\n",
    "\n",
    "Para mostrar la técnica de Fine-Tuning se entrenará el *block5* de VGG16 compuesto por tres capas convolucionales y una de pooling *(block5_conv1, block5_conv2 y block5_conv3 serán ahora entrenables)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1ISi6Wdl4_x"
   },
   "source": [
    "### VGG16 : Modelo con *Fine Tuning*\n",
    "\n",
    "El código en Keras que permite especificar este comportamiento en la fase de entrenamiento que acabamos de describir puede ser el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZfhhNnptlH0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "pre_trained_model = VGG16(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = 'imagenet')\n",
    "\n",
    "pre_trained_model.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable: \n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos igual que antes la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xN8OOenogf3N"
   },
   "outputs": [],
   "source": [
    "modelFT = Sequential()\n",
    "modelFT.add(pre_trained_model)\n",
    "modelFT.add(Flatten())\n",
    "modelFT.add(Dense(256, activation='relu'))\n",
    "modelFT.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el pre_trained_model tendrá más capas a entrenar, como podemos ver con la salida del método summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilación y entrenamiento de la red\n",
    "\n",
    "Se usarán los mismos hiperparámetros (optimizador RMSProp con learning rate de 1e-4), pero es importante dejar claro, para aquellos que quieran profundizar más en el tema, que estos hiperparámetros juegan un papel fundamental.\n",
    "* En general es una buena práctica usar un learning rate muy pequeño para limitar la magnitud de las modificaciones que se realizan en las tres capas del *block5* que está ajustando.\n",
    "* Los **learning rate** que son demasiado grandes pueden dañar los pesos previos que venían de la red preentrenada, ya que mantenían información importante para representar a las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YuZLpjNFghlD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "modelFT.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación del conjunto de datos aumentados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnRIx8pDR_wq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n",
    "\n",
    "\n",
    "test_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fSK81y-tlLa"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "historyFT = modelFT.fit(\n",
    "    train_generator,\n",
    "    validation_data = validation_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs = 100,\n",
    "    validation_steps = validation_steps,\n",
    "    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que en los anteriores modelos, se verifica gráficamente cómo evoluciona el entrenamiento en las gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnJPyi2KtlW5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc      = historyFT.history['acc']\n",
    "val_acc  = historyFT.history['val_acc']\n",
    "loss     = historyFT.history['loss']\n",
    "val_loss = historyFT.history['val_loss']\n",
    "\n",
    "epochs    = range(1,len(acc)+1,1) # obtener número de epochs\n",
    "\n",
    "plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
    "plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "#plt.ylim(0,1)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     loss, 'r--' )\n",
    "plt.plot  ( epochs, val_loss ,  'b' )\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos de pruebapara confirmar la mejora observada ya en el historial de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_0-Nfkrtlc0"
   },
   "outputs": [],
   "source": [
    "test_lost, test_acc= modelFT.evaluate(test_generator)\n",
    "print (\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jk6mBLCiHr2M"
   },
   "outputs": [],
   "source": [
    "accDA      = historyDA.history['acc']\n",
    "val_accDA  = historyDA.history['val_acc']\n",
    "\n",
    "accFE      = historyFE.history['acc']\n",
    "val_accFE  = historyFE.history['val_acc']\n",
    "\n",
    "accFT      = historyFT.history['acc']\n",
    "val_accFT  = historyFT.history['val_acc']\n",
    "\n",
    "epochs    = range(1,len(accDA)+1,1) \n",
    "\n",
    "plt.figure(figsize=(10,18))\n",
    "\n",
    "plt.plot(epochs, accFT,'k', label='Fine Tuning - Training acc')\n",
    "plt.plot(epochs, val_accFT,'b', label='Fine Tuning - Validation acc')\n",
    "\n",
    "plt.plot(epochs, accFE, 'r--', label='Feature Extraction - Training acc')\n",
    "plt.plot(epochs, val_accFE,  'm--', label='Feature Extraction - Validation acc')\n",
    "\n",
    "plt.plot(epochs, accDA, 'g:', label='Data Augmentation - Training acc')\n",
    "plt.plot(epochs, val_accDA,  'c:', label='Data Augmentation - Validation acc')\n",
    "\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.ylim(0.5,1)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con fotografías propias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEr3A3-e3bKZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "uploaded=files.upload()\n",
    "file=list(uploaded.keys())[0]\n",
    "\n",
    "path='/content/' + file\n",
    "img=image.load_img(path, target_size=(150, 150))\n",
    "\n",
    "x=image.img_to_array(img)\n",
    "image=np.expand_dims(x, axis=0)  \n",
    "\n",
    "classes = modelFT.predict(image)\n",
    "print(classes)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "if classes>0: print( fn + \" es un PERRO\")\n",
    "else: print( fn + \" es un GATO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "¡Todo bien! ¡Es todo por hoy! 😀"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "06_dataaugmentationandtransferlearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
