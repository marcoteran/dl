{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/1.2_machinelearning_imbalanceddata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/1.2_machinelearning_imbalanceddata.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "## Ejemplos de código\n",
    "# Autoencoders y GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran\n",
    "**E-mail:** marco.teran@usa.edu.co\n",
    "\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación del entorno y descarga de datos\n",
    "\n",
    "Empezamos con las importaciones estándar para preparar el entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "g5RstiiB8V-z",
    "outputId": "4312279c-7fcc-45b7-cc86-ab15150b1e81"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar todos los paquetes necesarios para ejecutar el modelo propuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina los tamaños de letra por defecto para que las figuras sean más bonitas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear la carpeta `images/generative` (si no existe ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"generative\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código puede ser muy lento sin una GPU, así que asegurémonos de que haya una, o de lo contrario emitamos una advertencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No se ha detectado ninguna GPU. Las redes neuronales pueden ser muy lentas sin una GPU.\")\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        print(\"Ve a Tiempo de ejecución > Cambiar tiempo de ejecución y selecciona un hardware de GPU \"\n",
    "              \"acelerador.\")\n",
    "    if \"kaggle_secrets\" in sys.modules:\n",
    "        print(\"Ve a Configuración > Acelerador y selecciona GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA with an Undercomplete Linear Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyamos el Autoencoder..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "\n",
    "encoder = tf.keras.Sequential([tf.keras.layers.Dense(2)])\n",
    "decoder = tf.keras.Sequential([tf.keras.layers.Dense(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = tf.keras.Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a generar el mismo conjunto de datos 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "m = 60\n",
    "X = np.zeros((m, 3))  # initialize 3D dataset\n",
    "np.random.seed(42)\n",
    "angles = (np.random.rand(m) ** 3 + 0.5) * 2 * np.pi  # uneven distribution\n",
    "X[:, 0], X[:, 1] = np.cos(angles), np.sin(angles) * 0.5  # oval\n",
    "X += 0.28 * np.random.randn(m, 3)  # add more noise\n",
    "X = Rotation.from_rotvec([np.pi / 29, -np.pi / 20, np.pi / 4]).apply(X)\n",
    "X_train = X + [0.2, 0, 0.2]  # shift a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=500, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings = encoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,3))\n",
    "plt.plot(codings[:,0], codings[:, 1], \"b.\")\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de un Stacked Autoencoder con Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos el conjunto de datos MNIST de moda, escalémoslo y dividámoslo en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – loads, scales, and splits the fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyamos y entrenemos un Autoencoder apilado con 3 capas ocultas y 1 capa de salida (es decir, 2 Autoencoders apilados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "])\n",
    "stacked_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(28 * 28),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae = tf.keras.Sequential([stacked_encoder, stacked_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de las reconstrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función procesa unas cuantas imágenes de validación a través del autocodificador y muestra las imágenes originales y sus reconstrucciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plt.imshow(images[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plt.imshow(reconstructions[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructions(stacked_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las reconstrucciones parecen borrosas, pero hay que recordar que las imágenes se comprimieron a sólo 30 números, en lugar de 784."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización del conjunto de datos MNIST de moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_compressed = stacked_encoder.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(init=\"pca\", learning_rate=\"auto\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_2D = tsne.fit_transform(X_valid_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos este diagrama un poco más bonito (adaptado de [este ejemplo de Scikit-Learn](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautifies the previous diagram for the book\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "Z = X_valid_2D\n",
    "Z = (Z - Z.min()) / (Z.max() - Z.min())  # normalize to the 0-1 range\n",
    "plt.scatter(Z[:, 0], Z[:, 1], c=y_valid, s=10, cmap=cmap)\n",
    "image_positions = np.array([[1., 1.]])\n",
    "for index, position in enumerate(Z):\n",
    "    dist = ((position - image_positions) ** 2).sum(axis=1)\n",
    "    if dist.min() > 0.02: # if far enough from other images\n",
    "        image_positions = np.r_[image_positions, [position]]\n",
    "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
    "            mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\"),\n",
    "            position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
    "        plt.gca().add_artist(imagebox)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrapesos de atado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es habitual vincular los pesos del codificador y el decodificador, utilizando simplemente la transposición de los pesos del codificador como pesos del decodificador. Para ello, tenemos que utilizar una capa personalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, dense, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense = dense\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.biases = self.add_weight(name=\"bias\",\n",
    "                                      shape=self.dense.input_shape[-1],\n",
    "                                      initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n",
    "        return self.activation(Z + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "dense_2 = tf.keras.layers.Dense(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tied_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    dense_1,\n",
    "    dense_2\n",
    "])\n",
    "\n",
    "tied_decoder = tf.keras.Sequential([\n",
    "    DenseTranspose(dense_2, activation=\"relu\"),\n",
    "    DenseTranspose(dense_1),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tied_ae = tf.keras.Sequential([tied_encoder, tied_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles and fits the model\n",
    "tied_ae.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = tied_ae.fit(X_train, X_train, epochs=10,\n",
    "                      validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots reconstructions\n",
    "plot_reconstructions(tied_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar un Autoencoder cada vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(n_neurons, X_train, X_valid, n_epochs=10,\n",
    "                      output_activation=None):\n",
    "    n_inputs = X_train.shape[-1]\n",
    "    encoder = tf.keras.layers.Dense(n_neurons, activation=\"relu\")\n",
    "    decoder = tf.keras.layers.Dense(n_inputs, activation=output_activation)\n",
    "    autoencoder = tf.keras.Sequential([encoder, decoder])\n",
    "    autoencoder.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "    autoencoder.fit(X_train, X_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid, X_valid))\n",
    "    return encoder, decoder, encoder(X_train), encoder(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = tf.keras.layers.Flatten()(X_train)\n",
    "X_valid_flat = tf.keras.layers.Flatten()(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc1, dec1, X_train_enc1, X_valid_enc1 = train_autoencoder(\n",
    "    100, X_train_flat, X_valid_flat)\n",
    "enc2, dec2, _, _ = train_autoencoder(\n",
    "    30, X_train_enc1, X_valid_enc1, output_activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae_1_by_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    enc1, enc2, dec2, dec1,\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructions(stacked_ae_1_by_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si es necesario, podemos seguir entrenando el autocodificador apilado completo durante unas cuantas épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae_1_by_1.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = stacked_ae_1_by_1.fit(X_train, X_train, epochs=5,\n",
    "                                validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructions(stacked_ae_1_by_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyamos un Autoencoder apilado con 3 capas ocultas y 1 capa de salida (es decir, 2 Autoencoders apilados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape([28, 28, 1]),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 14 × 14 x 16\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 7 × 7 x 32\n",
    "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 3 × 3 x 64\n",
    "    tf.keras.layers.Conv2D(30, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAvgPool2D()  # output: 30\n",
    "])\n",
    "conv_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3 * 3 * 16),\n",
    "    tf.keras.layers.Reshape((3, 3, 16)),\n",
    "    tf.keras.layers.Conv2DTranspose(32, 3, strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(16, 3, strides=2, padding=\"same\",\n",
    "                                    activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(1, 3, strides=2, padding=\"same\"),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ae = tf.keras.Sequential([conv_encoder, conv_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles and fits the model\n",
    "conv_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = conv_ae.fit(X_train, X_train, epochs=10,\n",
    "                      validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the reconstructions\n",
    "plot_reconstructions(conv_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "])\n",
    "dropout_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(28 * 28),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])\n",
    "dropout_ae = tf.keras.Sequential([dropout_encoder, dropout_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles and fits the model\n",
    "dropout_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dropout_ae.fit(X_train, X_train, epochs=10,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell generates and saves Figure 17–9\n",
    "dropout = tf.keras.layers.Dropout(0.5)\n",
    "plot_reconstructions(dropout_ae, dropout(X_valid, training=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres, puedes probar a sustituir la capa `Dropout` por `tf.keras.layers.GaussianNoise(0.2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilicemos la función de activación sigmoidea en la capa de codificación. Añadamos también $\\ell_1$ regularización a la misma: para ello, añadimos una capa `ActivityRegularization` después de la capa de codificación. Alternativamente, podríamos añadir `activity_regularizer=tf.keras.regularizers.l1(1e-4)` a la propia capa de codificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_l1_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(300, activation=\"sigmoid\"),\n",
    "    tf.keras.layers.ActivityRegularization(l1=1e-4)\n",
    "])\n",
    "sparse_l1_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(28 * 28),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_l1_ae = tf.keras.Sequential([sparse_l1_encoder, sparse_l1_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles and fits the model\n",
    "sparse_l1_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sparse_l1_ae.fit(X_train, X_train, epochs=10,\n",
    "                           validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows the reconstructions\n",
    "plot_reconstructions(sparse_l1_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trazar la pérdida de Divergencia KL, frente a la MAE y MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – this cell generates and saves Figure 17–10\n",
    "p = 0.1\n",
    "q = np.linspace(0.001, 0.999, 500)\n",
    "kl_div = p * np.log(p / q) + (1 - p) * np.log((1 - p) / (1 - q))\n",
    "mse = (p - q) ** 2\n",
    "mae = np.abs(p - q)\n",
    "plt.plot([p, p], [0, 0.3], \"k:\")\n",
    "plt.text(0.05, 0.32, \"Target\\nsparsity\", fontsize=14)\n",
    "plt.plot(q, kl_div, \"b-\", label=\"KL divergence\")\n",
    "plt.plot(q, mae, \"g--\", label=r\"MAE ($\\ell_1$)\")\n",
    "plt.plot(q, mse, \"r--\", linewidth=1, label=r\"MSE ($\\ell_2$)\")\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.xlabel(\"Actual sparsity\")\n",
    "plt.ylabel(\"Cost\", rotation=0)\n",
    "plt.axis([0, 1, 0, 0.95])\n",
    "plt.grid(True)\n",
    "save_fig(\"sparsity_loss_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos un regularizador personalizado para la regularización de la Divergencia KL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence = tf.keras.losses.kullback_leibler_divergence\n",
    "\n",
    "class KLDivergenceRegularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, weight, target):\n",
    "        self.weight = weight\n",
    "        self.target = target\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        mean_activities = tf.reduce_mean(inputs, axis=0)\n",
    "        return self.weight * (\n",
    "            kl_divergence(self.target, mean_activities) +\n",
    "            kl_divergence(1. - self.target, 1. - mean_activities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar este regularizador para empujar el modelo a tener un 10% de sparsity en la capa de codificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kld_reg = KLDivergenceRegularizer(weight=5e-3, target=0.1)\n",
    "sparse_kl_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(300, activation=\"sigmoid\",\n",
    "                          activity_regularizer=kld_reg)\n",
    "])\n",
    "sparse_kl_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(28 * 28),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_kl_ae = tf.keras.Sequential([sparse_kl_encoder, sparse_kl_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles and fits the model\n",
    "sparse_kl_ae.compile(loss=\"mse\", optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sparse_kl_ae.fit(X_train, X_train, epochs=10,\n",
    "                           validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows the reconstructions\n",
    "plot_reconstructions(sparse_kl_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programando una GAN\n",
    "\n",
    "A continuación se presentarán los pasos para implementar una GAN que permite entrenar un *Generador* que sintetiza dígitos escritos a mano que parecen reales usando *Deep Convolutional Generative Adversarial Networks (DCGAN)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturas de las imágenes producidas por el Generador en diferentes *epochs* durante su proceso de entrenamiento (se indica en qué número de epoch se ha generado cada imagen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se usa el Generador para generar 100 imágenes\n",
    "* Se podrá observar fácilmente que al inicio del entrenamiento las imágenes aparecen como ruido aleatorio\n",
    "* A medida que va avanzando el entrenamiento (va avanzando el número de *epochs*) los dígitos generados se parecen cada vez más a dígitos reales escritos a mano.\n",
    "* El objetivo final en un caso real es que el Generador sintetice imágenes de 28 × 28 que se confundan como datos reales del conjunto MNIST (conjunto de imágenes que hemos considerado como «reales»)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga de los datos  y preprocesado de los datos\n",
    "\n",
    "Descargar y preparar el conjunto de datos con el que entrenaremos la GAN.\n",
    "Ahora ya podemos descargar las imágenes del conjunto de datos **MNIST** de dígitos escritos a mano, que serán las imágenes que consideraremos *«reales»* para este ejemplo. Podemos hacerlo directamente desde ``keras.datasets`` y preparar las imágenes para ser usadas por las redes con el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4fYMGxGhrna"
   },
   "outputs": [],
   "source": [
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso solo interesan las imágenes (no se descargan las labels ni los datos de prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes se normalizan en el rango ``[-1, 1]`` para poder usar como función de activación en la capa final del Generador la función ``tanh``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se barajan y preparan los datos en lotes con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZU3Ilr2gn5y"
   },
   "source": [
    "## Creación de los modelos\n",
    "\n",
    "A continuación, se pasa a crear las redes neuronales que actuarán de Generador y Discriminador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### Generador\n",
    "\n",
    "Siguiendo el esquema que había descrito, el Generador recibe como entrada ruido, que puede obtener por ejemplo con ``tf.random.normal``.\n",
    "De este ruido debe crear una imagen de $28×28$ píxeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QsDYOFtzKIHi"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "-QlXbX2EwMCX",
    "outputId": "71eaa51f-4d33-45aa-9e31-d31d218795db"
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción del modelo:\n",
    "1. Capa densa que recoge el vector de ruido de entrada y lo transforma en un tensor tridimensional\n",
    "2. En las capas sucesivas se va transformando hasta llegar a una salida de 28 × 28 × 1.\n",
    "3. La red aumenta los tamaños de los mapas de características con la capa Conv2DTranspose.\n",
    "    * La capa convolución transpuesta se usa generalmente para aumentar el mapa de características.\n",
    "    * La convolución transpuesta funciona insertando ceros entre los elementos de los mapas de características de entrada y, después, aplicando una convolución normal.\n",
    "4. La capa ``LeakyReLU`` es una versión modificada de la función de activación ReLU que tiene una pequeña pendiente para valores negativos, en lugar de cero como la ReLU (determinada por el argumento).\n",
    "    * Esta se utiliza en cada capa excepto en la última capa.\n",
    "    * Esta capa es una funciones de activación avanzadas en Keras y solo está disponible como capa y no como funciones de activación.\n",
    "5. En la última capa se ha usado una función de activación ``tanh``:\n",
    "    * ``tanh`` tiende a producir imágenes más nítidas que la sigmoide (rango típico de 0 a1)\n",
    "6. Se usa la capa ``BatchNormalization`` para normalizar las entradas de la capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que la red funciona como se espera con el siguiente código, en el que el Generador genera una instancia de datos fake: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "gl7jcC7TdPTG",
    "outputId": "671d8fed-7478-4ad6-daa9-b8032a415169"
   },
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "noise = tf.random.normal([1, noise_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, el Discriminator recibe imágenes de $28×28×1$ píxeles y saca una probabilidad que indica si esta imagen de entrada la considera real (en lugar de fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mypJk88So23v"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, LeakyReLU, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(128*2, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(128*3, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "colab_type": "code",
    "id": "gDkA05NE6QMs",
    "outputId": "886ce5e9-f21e-4928-b0ec-94ecb7dcf5ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta red se construye con tres capas convolucionales de 32, 64 y 128 neuronas, con función de activación ``LeakyReLU`` y ``BatchNormalization``. La última capa es una capa densa con una función de activación sigmoide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Discriminador se usará para clasificar las imágenes generadas como reales o fake, generando valores:\n",
    "* Próximos al 1 para imágenes que considera reales\n",
    "* Próximos a 0 para imágenes que considera fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que el Discriminador funciona como creemos con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Funciones de *Loss* y optimizadores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez los modelos del Generador y Discriminador fueron creados, el siguiente paso para entrenar las redes es establecer la función de pérdida y el optimizador que se usará para el proceso de entrenamiento.\n",
    "* Anteriormente esto se ha indicado con los argumentos del método ``compile()`` que luego se usan cuando se entrena el modelo al ejecutar el método ``fit()`` \n",
    "* Ahora se tinen **dos redes neuronales**, se requieren dos funciones de pérdida y dos optimizadores.\n",
    "* Los parámetros de ambas redes están interrelacionados en el cálculo de la función de pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de pérdida\n",
    "\n",
    "Para las funciones de pérdida de ambas redes neuronales se utilizá la *binary cross entropy*, que es una medida de la diferencia entre las probabilidades calculadas y las probabilidades reales de predicciones en los casos donde solo hay **dos clases posibles** en las que pueden ser clasificados los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "### Discriminator loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función auxiliar ``cross_entropy`` se definirá la función ``discriminator_loss()`` para cuantificar una *loss* del Discriminador que nos indicará cómo de bien el Discriminador consigue distinguir imágenes reales de imágenes fake en una iteración\n",
    "* La función recibe en el primer argumento (real_output) la predicción que ha hecho el Discriminador de un batch de imágenes reales\n",
    "* En el segundo argumento (fake_output) la predicción que ha hecho de un batch una imagen fake.\n",
    "\n",
    "Si la predicción fuera la correcta, para una imagen real la predicción debería ser 1 y para una imagen fake debería ser 0.\n",
    "* Esta función compara el batch de imágenes reales predecidas por el Discriminador con un array de unos ``(tf.ones_like(real_output))`` y el batch de imágenes fake con un array de ceros ``(tf.zeros_like(real_output))``.\n",
    "\n",
    "La loss para esta iteración está compuesta tanto por los errores de predicción de imágenes reales como por los errores de las imágenes fake; por tanto, se deben sumar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "### Generator loss\n",
    "\n",
    "La manera de construir la función ``generator_loss`` para cuantificar una loss del Generador será muy parecida:\n",
    "* La loss del Generador deberá cuantificar cómo de bien fue capaz de engañar al Discriminador\n",
    "* Se comparan las decisiones del Discriminador sobre las imágenes generadas por el Generador con una matriz de unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgIc7i0th_Iu"
   },
   "source": [
    "### Optimizadores\n",
    "\n",
    "Los optimizadores del Discriminador y del Generador son diferentes y se requieren dos, ya que se entrenarán las dos redes por separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la optimización de ambas redes, es sescoge el algoritmo *Adam*. *Adam* se ha convertido en el optimizador para la mayoría de las implementaciones de GAN porque se ha demostrado que en la práctica tiene un rendimiento superior a otros métodos de optimización en este tipo de redes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuXySZBahFjt"
   },
   "source": [
    "## Entrenamiento con la API de bajo nivel de TensorFlow\n",
    "\n",
    "Anteriormente se ha utilizado el objeto ``tf.keras.Model``, a través de sus métodos ``fit()`` y ``compile()``, para entrenar a los modelos.\n",
    "* Muy útil, ya que permite ahorrar escribir el código de bucle de entrenamiento \n",
    "* Da suficiente control con *callbacks*, *métricas*, etc.\n",
    "\n",
    "**¿Cómo se puede especificar con el método ``fit()`` que esta red neuronal tiene dos funciones de pérdida y dos optimizadores?** La respuesta es ¡no se puede!\n",
    "\n",
    "En **TensorFlow 2.0** se puede utilizar la API de bajo nivel para escribir bucles de entrenamiento personalizados. Se utilizará el ``GradientTape`` de la API de bajo nivel, que  permite más control para personalizar el bucle de entrenamiento:\n",
    "* Entrenar a la vez las dos redes neuronales que se requieren para una GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, los códigos utilizarán mayormente las API de alto nivel (especialmente ``tf.keras`` y ``tf.data``), pero cuando se necesita más flexibilidad, se utiliza la API de Python de nivel inferior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "### Entrenamiento de las redes GAN \n",
    "\n",
    "Es necesario crear un bucle de entrenamiento personalizado utilizando la API de bajo nivel de TensorFlow. Se recreará una función ``train()`` a ala cual se le pasarán en los argumentos los datos de entrenamiento y el número de epochs que se quieren ejecutar para entrenar simultaneamente el Generador y el Discriminador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función ``train_step`` llamada dentro de ``train()`` representa un paso del bucle de entrenamiento (en sustitución del método ``fit()`` usando la API de bajo nivel de TensorFlow 2). Se define en 4 pasos:\n",
    "1. Creación de un conjunto de semillas de ruido con el que el Generador pueda generar las imágenes fake correspondientes (recordemos que estamos procesando las imágenes por lotes de tamaño BATCH_SIZE y que, por tanto, genera un vector de semillas, no una sola semilla)\n",
    "```Python\n",
    "noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "```\n",
    "Con este vector de ruido el Generador genera un batch de imágenes fake:\n",
    "```Python\n",
    "generated_images = generator(noise, training=True)\n",
    "```\n",
    "Se usa el Discriminador para clasificar un batch de imágenes reales extraídas del conjunto MNIST (recibidas como argumento) y un batch de imágenes fake acabadas de producir por el Generador:\n",
    "```Python\n",
    "real_output = discriminator(images, training=True)\n",
    "fake_output = discriminator(generated_images, training=True)\n",
    "```\n",
    "2. Cuando ya se tienen los valores obtenidos por el Generador y el Discriminador, se calcula la loss de ambos modelos con las funciones que se han definido anteriormente\n",
    "```Python\n",
    "gen_loss = generator_loss(fake_output)\n",
    "disc_loss = discriminator_loss(real_output, fake_output)\n",
    "```\n",
    "    * Los pasos anteriores se ejecutan dentro del contexto (context) de ``tf.GradientTape`` indicados por ``with``.\n",
    "    * En concreto, se están considerando dos contextos, uno para la información del Generador (``gen_tape``) y otro para la información del Discriminador (``disc_tape``).\n",
    "    * ``tf.GradientTape`` permite que se *«graben»* en un objeto las operaciones ejecutadas en el contexto para permitir obtener los gradientes con respecto a la loss\n",
    "3. Se debe propagar hacia atrás la loss para que llegue a todas las variables que conforman los parámetros (entrenables) para cada una de las dos redes neuronales. Esto es fácil una vez grabadas las operaciones en los respectivos contextos ``gen_tape`` y ``disc_tape``, aplicando el método ``gradient()`` para obtener los gradientes con respecto a la función de pérdida para las dos redes:\n",
    "```Python\n",
    "gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "```\n",
    "4. Utilizar la información de los gradientes propagada para actualizar con el algoritmo de descenso del gradiente las variables correspondientes a los parámetros entrenables de cada una de las redes neuronales. Para ello simplemente hace falta usar el método ``apply_gradients()`` de los optimizadores de ambas redes\n",
    "```Python\n",
    "generator_optimizer.apply_gradients(zip(gradients_of_generator,\n",
    "                                        generator.trainable_variables))\n",
    "discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,\n",
    "                                            discriminator.trainable_variables))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "@tf.function # Decorador: timizada a nivel interno para poder ser acelerada en el hardware disponible.\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nts43kLUdPG-"
   },
   "source": [
    "#### Training loop\n",
    "\n",
    "Este método ejecuta un doble bucle, como se ve en el siguiente código:\n",
    "* El primer bucle tiene tantas iteraciones como epochs hemos indicado en el argumento, y el segundo itera para todos los batch del dataset.\n",
    "\n",
    "* El cuerpo del bucle simplemente llama al método ``train_step``,que realiza todo el trabajo requerido para calcular las loss y actualizar los parámetros de las dos redes, para todas las imágenes de un batch en una epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "grid_size_x= 10\n",
    "grid_size_y= 10\n",
    "seed = tf.random.normal([grid_size_x*grid_size_y , noise_dim])\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch)\n",
    "\n",
    "    generate_images(generator,seed)\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    \n",
    "    generate_images(generator, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de cada epoch se invoca a la función ``generate_images`` que visualiza por pantalla predicciones generadas por el Generador, y para ello usa las variables ``seed``, ``grid_size_x`` y ``grid_size_y``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "#### Visualización de las imagenes \n",
    "Función auxiliar para visualizar las imagenes que genera el Generador para ver que va aprendiendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    \n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(grid_size_x,grid_size_y))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(grid_size_x, grid_size_y, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l",
    "outputId": "e3cec2a8-6616-473f-c6d4-a12e3eb418d1"
   },
   "outputs": [],
   "source": [
    "## %%time\n",
    "EPOCHS = 12000\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de fraudes usando autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código fuente muestra cómo detectar transacciones fraudulentas en tarjetas débito y crédito usando un autoencoder.\n",
    "El set de datos (creditcard.csv) se puede descargar de este [enlace](https://drive.google.com/file/d/1Lf4tMOt45IFARFO-dNl4-Df8x-gjUMu5/view).\n",
    "    \n",
    "Contiene $284,315$ registros con transacciones normales y $492$ fraudulentas. Una vez entrenado el autoencoder se logrará un recall igual a 0.92.\n",
    "Este código está basado en el post de David Ellison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA DEL SET DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datos = pd.read_csv(\"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\")\n",
    "print(datos.head())\n",
    "\n",
    "nr_clases = datos['Class'].value_counts(sort=True)\n",
    "print(nr_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANÁLISIS EXPLORATORIO DE LOS DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de registros normales vs. fraudulentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_clases.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(2), ['Normales', 'Fraudulentos'])\n",
    "plt.title(\"Distribución de los datos\")\n",
    "plt.xlabel(\"Clase\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Monto de las transacciones vs. tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normales = datos[datos.Class==0]\n",
    "fraudulentos = datos[datos.Class==1]\n",
    "plt.scatter(normales.Time/3600, normales.Amount,\n",
    "            alpha = 0.5, c='#19323C', label='Normales', s=3)\n",
    "plt.scatter(fraudulentos.Time/3600, fraudulentos.Amount,\n",
    "            alpha = 0.5, c='#F2545B', label='Fraudulentos', s=3)\n",
    "plt.xlabel('Tiempo desde la primera transacción (h)')\n",
    "plt.ylabel('Monto (Euros)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución de las características V1 a V28 en normales y fraudulentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "v_1_28 = datos.iloc[:,1:29].columns\n",
    "gs = gridspec.GridSpec(28, 1)\n",
    "for i, cn in enumerate(datos[v_1_28]):\n",
    "    sns.distplot(datos[cn][datos.Class == 1], bins=50, \n",
    "                 label='Fraudulentos', color='#F2545B')\n",
    "    sns.distplot(datos[cn][datos.Class == 0], bins=50,\n",
    "                 label='Normales', color='#19323C')\n",
    "    plt.xlabel('')\n",
    "    plt.title('Histograma característica: ' + str(cn))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La variable \"Tiempo\" no aporta información. La eliminaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "datos.drop(['Time'], axis=1, inplace=True)\n",
    "datos['Amount'] = StandardScaler().fit_transform(datos['Amount'].values.reshape(-1,1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(datos, test_size=0.2, random_state=42)\n",
    "X_train = X_train[X_train.Class == 0]\n",
    "X_train = X_train.drop(['Class'], axis=1)\n",
    "X_train = X_train.values\n",
    "\n",
    "Y_test = X_test['Class']\n",
    "X_test = X_test.drop(['Class'], axis=1)\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOENCODER: 29-20-14-20-29, tanh-relu-tanh-relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(5)\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_entrada = X_train.shape[1]          # 29\n",
    "capa_entrada = Input(shape=(dim_entrada,))\n",
    "\n",
    "encoder = Dense(20, activation='tanh')(capa_entrada)\n",
    "encoder = Dense(14, activation='relu')(encoder)\n",
    "\n",
    "decoder = Dense(20, activation='tanh')(encoder)\n",
    "decoder = Dense(29, activation='relu')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=capa_entrada, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.01)\n",
    "autoencoder.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "nits = 100\n",
    "tam_lote = 32\n",
    "autoencoder.fit(X_train, X_train, epochs=nits, batch_size=tam_lote, shuffle=True, validation_data=(X_test,X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción X_test -> Autoencoder -> X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = autoencoder.predict(X_test)\n",
    "ecm = np.mean(np.power(X_test-X_pred,2), axis=1)\n",
    "print(X_pred.shape)\n",
    "\n",
    "# Gráfica precision-recall para determinar el umbral\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "precision, recall, umbral = precision_recall_curve(Y_test, ecm)\n",
    "\n",
    "plt.plot(umbral, precision[1:], label=\"Precision\",linewidth=5)\n",
    "plt.plot(umbral, recall[1:], label=\"Recall\",linewidth=5)\n",
    "plt.title('Precision y Recall para diferentes umbrales')\n",
    "plt.xlabel('Umbral')\n",
    "plt.ylabel('Precision/Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_fijo = 0.75\n",
    "Y_pred = [1 if e > umbral_fijo else 0 for e in ecm]\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "¡Todo bien! ¡Es todo por hoy! 😀"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "14-Generative-Adversarial-Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
