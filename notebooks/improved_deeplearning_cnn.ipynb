{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/3.3_deeplearning_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/3.3_deeplearning_cnn.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Código: Sesión 09\n",
    "## Redes Neuronales Convolucionales (CNN) para Deep Learning y Series de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autor:** Marco Teran\n",
    "Correo Electrónico: marco.tulio.teran@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Librerías Esenciales\n",
    "Se inicia con la importación de librerías estándar requeridas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#import mlutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "#importlib.reload(mlutils)\n",
    "#reload(mlutils) Python2\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set()  # for plot styling\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "%matplotlib inline\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN\n",
    "from IPython.display import HTML\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import pairwise_distances_argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Convolucionales (CNN)\n",
    "Una CNN es una categoría de red neuronal diseñada para reconocer patrones en un conjunto de datos multidimensional. Emula la manera en que el cerebro humano percibe y reconoce visualmente patrones. Las CNN son particularmente útiles en tareas de visión artificial, tales como clasificación y segmentación de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1: Clasificación de Dígitos con el Conjunto de Datos MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este segmento ofrece un tutorial práctico de Deep Learning utilizando Keras para clasificar dígitos mediante el conjunto de datos MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Reshape\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del Conjunto de Datos MNIST\n",
    "El conjunto de datos MNIST es ampliamente reconocido y utilizado. Existen scripts predefinidos que facilitan su descarga, descompresión y segmentación en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para descargar la base de datos MNIST\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"Tamaño de:\")\n",
    "print (train_images.shape)\n",
    "print (train_labels.shape)\n",
    "\n",
    "print(\"Tamaño de:\")\n",
    "print(\"- Set de entranamiento:\\t{}\".format(len(train_images)))\n",
    "print(\"- Set de testeo:\\t\\t{}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Clasificación con el Conjunto de Datos Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo demuestra la clasificación de prendas de vestir utilizando el conjunto de datos Fashion-MNIST, que contiene imágenes de 10 categorías distintas de prendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picnumber=25\n",
    "plt.imshow(train_images[picnumber], cmap=plt.cm.binary)\n",
    "# Ver la etiqueta\n",
    "print(train_labels[picnumber])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos de Fashion-MNIST\n",
    "El conjunto de datos Fashion-MNIST está disponible directamente en el API de tf.keras. Se puede cargar de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Cambio a variables categoricas\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "print (train_images.shape)\n",
    "print (train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar `load_data` se obtienen dos conjuntos de listas, correspondientes a los datos de entrenamiento y prueba, cada uno con las imágenes y sus etiquetas respectivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Base para Fashion-MNIST\n",
    "Se presenta un modelo base de red neuronal convolucional para la clasificación de imágenes en el conjunto de datos Fashion-MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos al constructor del modelo sequential\n",
    "model = Sequential()\n",
    "\n",
    "# Capa convolucional con funcion de activacion ReLU y max-pooling.\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Mejorado con Más Neuronas\n",
    "Este modelo mejora el anterior duplicando el número de neuronas y añadiendo una capa densa de 64 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con Optimizador 'Adam'\n",
    "En este modelo se introduce el optimizador 'Adam' para mejorar la convergencia durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Avanzado con BatchNormalization y Dropout\n",
    "Se presenta un modelo más complejo y robusto que incorpora capas de BatchNormalization y Dropout para mejorar la generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de Función para Crear CNN\n",
    "Se define una función que facilita la creación y configuración de redes neuronales convolucionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con Más Epochs (10)\n",
    "Se entrena el modelo avanzado durante 10 epochs para observar su comportamiento y rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con Más Epochs (30)\n",
    "Este modelo se entrena durante 30 epochs para evaluar su rendimiento con un mayor número de iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con Hyperparámetros Ajustados\n",
    "Se ajustan los hiperparámetros del optimizador Adam y se entrena el modelo durante 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- [Wikipedia: Redes Neuronales Convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales)\n",
    "- [TensorFlow: CNN Tutorial](https://www.tensorflow.org/tutorials/images/cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "¡Fin del Notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels,\n",
    "          batch_size=100,\n",
    "          epochs=5,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación de la red\n",
    "Para ver si la red ha aprendido a clasificar bien los números manuscritos hay que comprobar la precisión que obtiene en el conjunto de datos de test. Para este conjunto no ha sido entrenada la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámtro ``test_acc`` es la precisión que ha obtenido la red para el conjunto de entreno.\n",
    "Ahora hay que comprobar si clasifica bien las imágenes del conjunto de test. Estas imágenes aún no las ha visto la red y no tiene información de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar el modelo\n",
    "Es útil gurdar un modelo que ha sido entrenado satisfactoriamente para su posterior uso. De esta manera no hay que entrenar de nuevo la red y se pueden realizar prediciones con el modelo guardado.\n",
    "\n",
    "* **NOTA:** Será necesario instalar el paquete h5py para poder guardar modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la carpeta donde se guarda el modelo y su nombre.\n",
    "# En este caso se guarda en el mismo directorio que contiene este script\n",
    "nombre_model = 'modelo.h5'\n",
    "\n",
    "# Guardamos el modelo y todos los pesos entrenados\n",
    "model.save(nombre_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Conjunto de datos Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a un escenario en el que podemos reconocer diferentes prendas de vestir, entrenadas a partir de un conjunto de datos que contiene 10 tipos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Datos Fashion-MNIST](https://www.researchgate.net/profile/Greeshma_K_V/publication/340299295/figure/fig1/AS:875121904476163@1585656729996/Fashion-MNIST-Dataset-Images-with-Labels-and-Description-II-LITERATURE-REVIEW-In-image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Los datos del MNIST de la moda están disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a ``load_data`` en el objeto le dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo son estos valores? Imprimamos una imagen de entrenamiento, y una etiqueta de entrenamiento para ver... Experimentemos con diferentes índices en la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picnumber=42\n",
    "plt.imshow(train_images[picnumber], cmap=plt.cm.binary)\n",
    "# Ver la etiqueta\n",
    "print(train_labels[picnumber])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: modelo de base basado en el mismo modelo que el usado para el conjunto datos digits MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)    \n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]),\n",
    "               color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#00FF00\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28))\n",
    "test_images = test_images.reshape((10000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejoramiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 7\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)     \n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Duplicando las neuronas de modelo base y añadiendo una capa densa de 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (7, 7), activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: modelo 3 cambiando al optimizador 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (7, 7), activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4: Buscando un modelo más complejo que usa capas BatchNormalization y Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una función que permita recrear una red convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', input_shape=(28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 5: Modelo anterior añadiendo más epochs (10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 6: Modelo anterior añadiendo más epochs (30 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=30)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 7: Modelo anterior añadiendo más epochs (30 epochs) y diferentes hiperparámetros al optimizador Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam (lr=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=30, callbacks=[reduce_lr])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28))\n",
    "test_images = test_images.reshape((10000, 28, 28))\n",
    "\n",
    "\n",
    "num_rows = 7\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)     \n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias generales\n",
    "\n",
    "- [Redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales)\n",
    "- [Convolutional Neural Network (CNN) with TensorFlow](https://www.tensorflow.org/tutorials/images/cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "¡Todo bien! ¡Es todo por hoy! 😀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
